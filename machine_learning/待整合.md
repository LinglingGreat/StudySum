**有监督算法**

1.逻辑回归——二分类，softmax

2.树模型，ID3，C45，CART，DT——并行：RandomForest, 串行：GBDT，xgboost, lightgbm

NB——贝叶斯



**无监督算法**

聚类：K-means（EM算法）——k怎么确定(百面机器学习)，缺点？初始值的影响——改进？sklearn

降维：PCA



**损失函数**

回归：L2 loss

分类：log loss, cross-entropy, hinge loss



**评估方法**：K-Fold，Hold-out, bootstrap, A-B-test

**评估准则**：precision, recall, Confusion matrix, auc-roc, KS, mae, mse, r2, mape, macro, micro



**面试**

原理型：

1.各类模型原理知识

2.模型评估

应用型：

1.数据处理、清洗方式，异常点，格式组织(csv, libsvm, libFM)，缺失值(ffill, bfill, fillna)

2.特征工程，连续性、离散型、时间型，embedding

3.特征选择

4.模型选择

5.模型优化



**LR**

损失函数——与极大似然的关系——GD/二阶/学习率

LR与SVM、DT、KNN对比

决策边界：LR是一条直线，DT的决策边界是锯齿状的，KNN垂直平分线？

LR与SVM的差别：画图，LR是计算所有样本的loss，求和优化，而SVM只关心支持向量。

![1573961353602](img/1573961353602.png)



![1573961451962](img/1573961451962.png)

KNN和K-means不要弄混

LR是分类算法，overfitting，正则化

L1——阶段性效应，可以产生稀疏解

L2——压缩性效应，

百面机器学习，prml

贝叶斯角度理解L1和L2正则化：L1加了个拉普拉斯先验，L2加了个高斯先验



**SVM**

核函数：linear kernel, 多项式，rbf——映射到无穷多维(泰勒展开)

对缺失值/异常值敏感性？对缺失值敏感，需要提前填充，对异常值不太敏感



**DT**

ID3、C4.5、CART的差异

DT对于缺失值怎么处理？sklearn如果有缺失值会报错，xgb/lgb库不会，内部处理

DT泛化——RF(并行)——boosting, GBDT, xgboost, Adaboost，他们的区别？

SVM把原始问题转为对偶问题的目的

LR和SVM、SVM的kernel分别在什么场景用

GBDT和xgboost, xgboost(level-wise)和lightgbm(leaf-wise，深度优先)的差异，调参：重要参数(树深，叶子最大数，学习率，轮次)

xgboost控制树深，lightgbm控制叶子数量，最大叶子数更有效

xgboost和lightgbm如何控制过拟合的？正则化，采样，

RF——并行，xgboost——并行化在哪里？选取属性，属性的分裂层面

xgboost的二分类：score——logloss，多分类——one vs rest思想，构建多棵树

xgboost 近似算法是怎么做的？

串行算法，每次生成1棵树，score，乘以系数，为什么要乘以系数，不直接相加？shrinkage



**过拟合和欠拟合**

怎么评估模型状态？overfitting/underfitting

train, valid之间的diff

缓解overfitting：

1.加数据；2.正则化(L1, dropout)；3.集成学习(工业界不常用)；4.xgb/lgb/DL，early stopping；5.RF采样



**数据不均衡**

imbalanced data，比如点击/不点击，病人/正常人

比如GridSearchCV不起作用，原因可能是：

1.scoring是不是用default，不均衡的时候不能用accuracy，用auc或F1

2.数据分层采样，k-fold， stratifiedCV

如果有100亿样本，怎么计算auc？

快速估算，并行计算

auc的物理含义是你预估的正样本概率大于你预估的负样本概率的概率

如果陷入overfitting，缓解，提高效果？

1.采样，欠采样(要考虑样本本身的数量大小)

2.过采样，直接重复；SMOTE

3.cost-sensitive learning 

4.把大的数据拆成很多份，构建多个模型，集成



**特征工程与特征选择**

离散化的作用，为什么？

比如给LR这样的线性模型带来非线性

DT是非线性模型，不需要做离散化,scaling,xgb/lgb缺失值

特征选择

xgb/lgb——feature importance，比如基于特征分裂次数



**如何系统化、高效的学习AI算法**

编程——数据分析/处理/可视化——大数据——算法原理——机器学习DL动手

项目



**NLP工程师的职责、工作内容**

![1573975161450](img/1573975161450.png)

![1573975242127](img/1573975242127.png)



**推荐算法工程师面试**

![1573985974145](img/1573985974145.png)

![1573986005342](img/1573986005342.png)

![1573986034442](img/1573986034442.png)



![1573985318998](img/1573985318998.png)

![1573985413866](img/1573985413866.png)

![1573985571819](img/1573985571819.png)

![1573985921954](img/1573985921954.png)

