## SVD

矩阵分解：将矩阵分解为一个方阵、一个对角矩阵和另一个方阵

![1538874361321](../img/1538874361321.png)

一个矩阵乘以一个向量相当于对这个向量做了线性变换

![1538874473498](../img/1538874473498.png)

![1538874513912](../img/1538874513912.png)

这其实是在平面上对一个轴进行的拉伸变换（如蓝色的箭头所示），在图中，蓝色的箭头是一个最主要的变化方向（变化方向可能有不止一个），如果我们想要描述好一个变换，那我们就描述好这个变换主要的变化方向就好了。反过头来看看之前特征值分解的式子，分解得到的Σ矩阵是一个对角阵，里面的特征值是由大到小排列的，**这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）**

如果我们想提取矩阵的r个主要特征，就可以只保留它的最大的r个特征值对应的特征向量。

![1538874559211](../img/1538874559211.png)

看一个例子，左边矩阵分解为右边三个矩阵

![1538874944281](../img/1538874944281.png)

SVD就是对原始矩阵的一个特征压缩，压缩成了特征向量。可以用在推荐上。

![1538874961406](../img/1538874961406.png)

对角矩阵2×2，只保留最重要的两个特征。将U和V画在坐标轴中，U呈现了物体之间的关系，V呈现了人之间的关系。

![1538874976628](../img/1538874976628.png)



![1538874991274](../img/1538874991274.png)

画到坐标轴中

![1538875006625](../img/1538875006625.png)