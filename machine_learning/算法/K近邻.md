给定测试样本，基于某种度量距离找出训练样本集中最靠近的k个训练样本。然后基于这k个训练样本（称为近邻）的标签信息来进行预测：
**分类任务**用投票法：选择k个近邻中出现最多的类别标签作为预测标签
**回归任务**用平均法：将k个近邻的标签的平均值作为预测标签

k近邻是一种**“懒惰学习lazy learning”**算法。
它没有显式的训练过程。在训练阶段仅仅是把样本保存起来，训练时间开销为零，等接收到测试样本后在进行处理。

KNN 分类的计算复杂度和训练集中的文档数目成正比，也就是说，如果训练集中文档总数为n，那么KNN 的分类时间复杂度为O(n)。

K 值的选择，距离度量和分类决策规则是该算法的三个基本要素

问题：该算法在分类时有个主要的不足是，当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K 个邻居中大容量类的样本占多数

解决：不同的样本给予不同权重项