 

##其它

**鞍点上的Hessian矩阵是正定的？负定的？**

鞍点：梯度等于零，在其附近Hessian矩阵有正的和负的特征值，行列式小于0，即是不定的。 

鞍点和局部极值的区别： 

鞍点和局部极小值相同的是，在该点处的梯度都等于零，不同在于在鞍点附近Hessian矩阵是不定的，非正定，非负定，非半正定(行列式小于0)，而在局部极值附近的Hessian矩阵是正定的。

**已知一组数据的协方差矩阵P,下面关于主分量说法错误的是()**

```
主分量分析的最佳准则是对一组数据进行按一组正交基分解, 在只取相同数量分量的条件下,以均方误差计算截尾误差最小
在经主分量分解后,协方差矩阵成为对角矩阵
主分量分析就是K-L变换
主分量是通过求协方差矩阵的特征值得到
```

C，K-L变换与PCA变换是不同的概念，PCA的变换矩阵是协方差矩阵，K-L变换的变换矩阵可以有很多种（二阶矩阵、协方差矩阵、总类内离散度矩阵等等）。当K-L变换矩阵为协方差矩阵时，等同于PCA。

**位势函数法的积累势函数K(x)的作用相当于Bayes判决中的()**

```
后验概率
先验概率
类概率密度
类概率密度与先验概率的乘积
```

AD

**统计模式分类问题中，当先验概率未知时，可以使用()**

```
最小最大损失准则
最小误判概率准则
最小损失准则
N-P判决
```

AD，

A. 考虑p(wi)变化的条件下，是风险最小

B. 最小误判概率准则， 就是判断p(w1|x)和p(w2|x)哪个大，x为特征向量，w1和w2为两分类，根据贝叶斯公式，需要用到先验知识

C. 最小损失准则，在B的基础之上，还要求出p(w1|x)和p(w2|x)的期望损失，因为B需要先验概率，所以C也需要先验概率

D. N-P判决，即限定一类错误率条件下使另一类错误率为最小的两类别决策，即在一类错误率固定的条件下，求另一类错误率的极小值的问题，直接计算p(x|w1)和p(x|w2)的比值，不需要用到贝叶斯公式_

**基于二次准则函数的H-K算法较之于感知器算法的优点是()?**

```
计算量小
可以判别问题是否线性可分
其解完全适用于非线性可分的情况
其解的适应性更好
```

BD，HK算法思想很朴实,就是在最小均方误差准则下求得权矢量.
他相对于感知器算法的优点在于,他适用于线性可分和非线性可分得情况,对于线性可分的情况,给出最优权矢量,对于非线性可分得情况,能够判别出来,以退出迭代过程.