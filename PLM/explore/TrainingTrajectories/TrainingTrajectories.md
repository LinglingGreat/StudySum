---
title: TrainingTrajectories
created: 2024-02-08
tags:
  - ppl
type: 论文
papername: Training Trajectories of Language Models Across Scales
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2023
institution:
  - MetaAI
---

## 论文基本信息

标题：Training Trajectories of Language Models Across Scales

作者：

链接：

代码：

框架图：


## 背景
**A**: 这篇论文试图解决的问题主要围绕以下几个方面：

1. **模型规模对预训练语言模型学习动态的影响**：随着模型规模的增大，预训练过程中模型的学习行为如何变化？特别是，不同大小的语言模型在预训练期间是如何学习生成文本和解决下游任务的？
    
2. **验证困惑度（Perplexity）与模型行为的关系**：在给定的困惑度水平下，不同规模的模型是否表现出相似的学习行为？困惑度是否比模型规模更能预测模型的行为？
    
3. **序列级生成的分布变化**：在训练过程中，模型倾向于生成哪些类型的序列？特别是，较小模型相对于较大模型更倾向于生成哪些类型的序列？
    
4. **下游任务性能与预训练目标的关联**：预训练过程中的困惑度如何预测模型在下游任务上的性能？不同规模的模型在下游任务上的表现有何差异？
    
5. **模型训练轨迹的分析**：通过分析不同规模的OPT模型（Open Pre-trained Transformer Language Models）在预训练过程中的中间检查点，研究者试图理解模型在训练过程中如何逐步学习新的语言现象。
    
6. **双下降现象（Double Descent）**：在某些特定类型的上下文中，模型的困惑度在训练初期下降，随后上升，最后再次下降。这种现象在不同规模的模型中如何表现？
    

通过这些研究问题，论文旨在深入理解大规模语言模型的训练过程，以及模型规模如何影响其学习行为和最终性能


## 相关研究
**A**: 这篇论文的相关研究主要集中在以下几个领域：

1. **模型规模与性能的关系**：研究者们探讨了模型规模如何影响语言模型的性能，包括困惑度（Perplexity）和下游任务的准确性。例如，Kaplan et al. (2020) 和 Hernandez et al. (2022) 的工作展示了模型规模增加时，语言建模性能的提升。
    
2. **训练动态分析**：一些研究专注于分析小型模型的训练轨迹，如Liu et al. (2021)、Choshen et al. (2022) 和 Blevins et al. (2022)。这些工作通常关注模型在预训练过程中的行为变化。
    
3. **困惑度与下游任务性能的关联**：研究者们研究了困惑度与模型在下游任务上的性能之间的关系。例如，Saunshi et al. (2020) 提出了语言模型在下游任务上的表现与其在语言建模任务上的表现之间的数学联系。
    
4. **模型架构与训练方法**：Tay et al. (2022a) 和 Artetxe et al. (2022b) 探讨了模型架构和训练方法对模型性能的影响，以及如何有效地扩展模型规模。
    
5. **语言模型的可解释性**：Olsson et al. (2022) 和 Nanda and Lieberum (2022) 通过研究模型的诱导头（induction heads）来理解模型如何在预训练过程中形成上下文学习能力。
    
6. **逆向缩放现象（Inverse Scaling）**：Perez and McKenzie 提出了逆向缩放的概念，即在某些情况下，模型规模的增加可能导致下游任务性能的下降。
    
7. **模型训练轨迹的连续性**：Schaeffer et al. (2023) 发现，尽管在最终检查点上模型性能可能表现出突破性改进，但在训练过程中，任务性能的增长趋势通常是平滑的。
    

这些相关研究为理解大规模语言模型的训练过程、性能提升以及如何有效地扩展模型规模提供了理论基础和实证分析。



## 核心亮点
**A**: 论文通过以下方法来解决上述问题：

1. **分析不同规模的OPT模型**：研究者们分析了从125M到175B参数的OPT模型的中间训练检查点。这些模型在预训练过程中使用了相同的数据和训练程序，这为比较不同规模模型的学习动态提供了一个统一的框架。
    
2. **困惑度作为主要评估指标**：论文使用困惑度（Perplexity）作为衡量模型性能的主要指标，因为它与语言模型评估紧密相关。通过研究困惑度随训练进度的变化，研究者们能够观察到模型在预训练过程中的行为变化。
    
3. **分类分析预测轨迹**：对于下一个词的预测，研究者们将每个词的预测轨迹分为停滞（Stagnated）、上升趋势（Upward trend）和下降趋势（Downward trend）三类，以理解模型是如何逐步学习新的语言现象。
    
4. **序列级生成分析**：研究者们扩展了分析范围，从单个词的预测扩展到整个序列（50-500个词）的生成。他们研究了模型在不同规模下对人类文本的建模能力，并尝试生成小模型相对于大模型更倾向于生成的序列。
    
5. **下游任务性能评估**：通过在BIG-Bench数据集上的74个多项选择任务上评估模型，研究者们探讨了困惑度与模型在下游任务上的性能之间的关系。他们发现困惑度是模型在这些任务上表现的一个强预测因子。
    
6. **双下降现象的观察**：论文首次观察到在语言模型训练过程中，某些类型的上下文（context-token pairs）在较小模型中困惑度上升，而在较大模型中先上升后下降的双下降现象。这表明大型模型在训练过程中能够更好地泛化这些特定的上下文。
    
7. **模型分布的比较**：通过对比不同规模模型在相同困惑度水平下的预测，研究者们发现模型在达到相似困惑度时，其行为趋于一致。这表明困惑度是预测模型行为的一个更可靠的指标，而不是模型规模或训练计算量。
    

通过这些方法，论文提供了对大规模语言模型训练轨迹的全面分析，并揭示了困惑度在理解模型行为和性能方面的重要性。


## 实验
**A**: 论文进行了一系列的实验来分析不同规模的语言模型在预训练过程中的行为和性能。以下是主要的实验内容：

1. **模型检查点分析**：
    
    - 收集了不同规模的OPT模型（从125M到175B参数）的中间检查点。
        
    - 分析了这些模型在预训练过程中的困惑度（Perplexity）变化。
        
2. **下一个词预测分析**：
    
    - 对验证数据集上的每个上下文-词对（context-token pair）进行分类，根据其困惑度趋势分为停滞、上升趋势和下降趋势。
        
    - 研究了这些分类在不同模型规模和训练阶段的表现。
    - 总体而言，停滞令牌的百分比增加，而其他两类令牌的百分比下降，这表明需要学习的令牌越来越多，仍在学习的令牌越来越少
    - 在小模型 (1.3B) 中训练 10% 后停滞的token在较大的模型中也会停滞。然而，大模型（175B）选择的停滞token在较小模型中仍然呈现下降趋势。这表明较大模型的停滞token大致是较小模型的超集。在手动检查中，停滞的token主要是非内容词，例如介词、限定词和标点符号。
    - 对于在小模型（1.3B）训练 10％ 后呈现上升趋势的标记，我们观察到较大模型轨迹中的逐步双下降（Nakkiran 等人，2020）趋势，其中困惑度先增加然后减少。我们是第一个在语言模型训练期间观察到这种现象的人，它表明具有更多计算量和更大容量的较大模型首先会过度拟合该标记子集，并进一步更好地概括它们。
    - 大型模型首先在同一代币子集上复制小型模型的行为，并在更多计算的推动下进一步解锁排他现象。
        
3. **序列级生成分析**：
    
    - 研究了模型在生成50-500个词的序列时的行为。
        
    - 使用了一种解码方法，通过结合小型和大型模型的分布来生成文本，以探索小模型相对于大模型更倾向于生成的序列。
    - 较大的语言模型在对维基百科等人类文本进行建模时始终获得更好的困惑度，随着模型大小和训练计算量的增加，困惑度会降低
    - 即使上下文是纯噪声，较大的模型也比较小的模型更擅长根据上下文分布进行预测。 
    - 我们无法手动构建在较小模型中比在较大模型中更有可能出现的文本。
        
4. **下游任务性能评估**：
    
    - 在BIG-Bench数据集上的74个多项选择任务上评估了模型的中间检查点。
        
    - 分析了困惑度与模型在这些任务上的零样本（zero-shot）和少量样本（few-shot）学习性能之间的关系。
    - 下游准确性的提高通常不是由模型学习为不正确的候选者分配较低的概率驱动的，而是由正确和不正确选项的困惑度差异驱动的。
    - 随着模型规模的增加，指标会导致性能逐渐变化，而不是突然和意外的变化。
        
5. **双下降现象的观察**：
    
    - 在预训练过程中，观察了某些类型的上下文在不同模型规模下的困惑度变化，特别是那些在小型模型中困惑度上升而在大型模型中先上升后下降的现象。
6. **模型分布的比较**：
    
    - 对比了在相同困惑度水平下，不同规模模型对特定文本的预测分布。当小模型和大模型被训练到相同的困惑度水平时，它们会实现可比的下游任务性能。
        
    - 使用了线性回归来估计困惑度趋势，并根据趋势对上下文-词对进行分类。
        
7. **生成文本的质量评估**：
    
    - 使用MAUVE分数（一种评估文本质量的指标）来评估生成序列的质量。
        
    - 对比了不同解码策略（如贪婪搜索和核采样）在生成文本时的表现。
        

这些实验旨在全面理解语言模型在预训练过程中的学习动态，以及模型规模如何影响这些动态。通过这些实验，研究者们能够揭示困惑度在预测模型行为方面的重要性，并观察到模型在训练过程中如何逐步学习新的语言现象。



## 未来方向
**A**: 尽管论文提供了对大规模语言模型训练轨迹的深入分析，但仍有一些潜在的研究方向可以进一步探索：

1. **双下降现象的深入研究**：论文中观察到的双下降现象（在某些上下文中困惑度先上升后下降）是一个有趣的现象，值得进一步研究其背后的机制，以及它如何与自然语言的属性相关联。
    
2. **不同训练数据和目标的影响**：论文主要分析了使用相同数据和目标训练的模型。研究不同训练数据集、不同的预训练目标（如检索式语言模型）或不同的训练目标（如稀疏模型）对模型学习动态的影响。
    
3. **生成任务的评估**：论文主要关注了多项选择任务，而生成任务（如文本生成、摘要等）的评估更为复杂。探索在这些任务上模型性能与困惑度之间的关系。
    
4. **模型架构和训练方法的多样性**：研究不同架构（如Transformer的变体）和训练方法（如自适应学习率、不同的优化器）对模型学习轨迹的影响。
    
5. **模型可解释性和透明度**：提高模型的可解释性，以便更好地理解模型在预训练过程中学到的内容，以及如何将这些知识应用于下游任务。
    
6. **模型泛化能力的评估**：研究模型在面对未见过的数据或任务时的泛化能力，以及如何通过预训练过程提高这种能力。
    
7. **模型规模的经济效益**：在有限的计算资源下，如何有效地扩展模型规模以获得最佳性能，以及如何平衡模型规模与训练成本。
    
8. **模型的社会影响和伦理考量**：随着模型规模的增加，模型可能产生更复杂的行为，包括潜在的偏见和伦理问题。研究如何设计和训练模型以减少这些负面影响。


## 主要收获

**A**: 这篇论文主要研究了不同规模的语言模型在预训练过程中的学习轨迹。研究者们分析了从125M到175B参数的OPT模型，并关注了以下几个核心方面：

1. **训练动态**：研究者们发现，无论模型规模如何，所有模型在训练初期都会学习减少包含幻觉的语法序列的困惑度。小模型在这个次优分布上停滞，而大模型最终学会为这些序列分配更低的概率。
    
2. **困惑度与模型行为**：论文指出，困惑度是预测模型行为的一个强指标，比模型规模或训练计算量更能反映模型的性能。在训练过程中，模型在达到相似困惑度水平时，其行为趋于一致。
    
3. **序列级生成**：研究者们观察到，大型模型在生成人类文本方面表现更好，但在生成包含合成噪声和事实错误提示的文本方面，小型模型的表现更差。
    
4. **下游任务性能**：通过在BIG-Bench数据集上的多项选择任务评估，研究者们发现困惑度与模型在这些任务上的零样本学习性能有很强的相关性，这一关系在不同模型规模下都成立。
    
5. **双下降现象**：论文首次在语言模型训练过程中观察到双下降现象，即某些上下文在小型模型中困惑度上升，而在大型模型中先上升后下降。
    
6. **实验设置**：研究者们使用了OPT模型，并在相同的训练数据上进行了预训练。他们分析了模型在不同阶段的中间检查点，并使用困惑度作为主要评估指标。
    
7. **局限性**：论文指出，其研究结果可能受到模型训练数据、训练程序和语言建模目标相同的限制。此外，对于双下降现象的具体原因，以及在下游任务评估中只使用了多项选择任务，论文提出了未来研究的方向。
    

总的来说，这篇论文提供了对大规模语言模型训练过程的深入理解，并强调了困惑度在评估和预测模型性能方面的重要性。

## 参考资料
