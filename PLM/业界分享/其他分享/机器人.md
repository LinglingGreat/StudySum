---
title: 机器人
created: 2026-01-07
tags:
  - 机器人
---
[微信公众平台](https://mp.weixin.qq.com/s/mSn6CAaUiNsZ4-t2VWH73g)

以前的机器人没有大脑；有了大语言模型以后，你可以认为它现在有了大脑和认知，使得它可以做很多复杂的事情。

**强化学习相当于什么？**

这个有点像大脑和小脑。

大脑负责思维、推理和做计划，所以大语言模型更像大脑。而小脑负责执行，你要走路、控制平衡、控制双手做manipulation（操控），这部分是强化学习非常擅长的。可能大脑、小脑都需要。


从我的角度来说，我不得不承认，最近几年的机器人智能发展**主要还是依赖于多模态大模型**。它不仅仅是语言模型，它是一个多模态模型。

但多模态模型缺什么呢？它缺少robot action的输出。

多模态模型可以输入图像、语言，输出可能是文本，但它不能输出对机器人的控制。于是我们经常做的事情，是拿大语言模型作为一个基底模型，加上一些机器人动作的数据，让它能够输出机器人的动作，控制机器人。

所以从我的角度来说，我做的很多工作还是在补全现在的多模态模型，使它可以输出机器人动作，控制机器人。

它到底是不是一个非常独立的学科？So far, not yet。

我觉得未来，当你碰到各种瓶颈，需要不一样的data format（数据格式），或者需要一个更完善的world model（世界模型）时，它可能会变成一个更加独立的学科。但现在，我觉得绝大多数在做VLA（Vision-Language-Action）、在做机器人大模型的，其实还是在大语言模型或多模态语言模型上做一些fine-tuning（微调）。

**张小珺：今天你觉得robotics发展到哪个阶段了？**

**谭捷：**我觉得它的progress非常快，最近一年的进展非常impressed或者surprised。

但要解决具身智能或让机器人有真正的应用，我觉得那个gap还是很大的。的确，现在你可以让机器人模型把一件事情做得非常好。你看到很多网上的video，包括你可能在CoRL上看到Dyna折衣服的那个demo，它在做一个比较窄的领域的操作时，可以做得非常好。

**张小珺：这是因为强化学习吗？**

**谭捷：**大家号称是强化学习，但我觉得肯定不止强化学习。我相信Dyna也是VLA加上强化学习的方案，但它依靠了多少VLA、依靠了多少强化学习？这可能只有问他们才知道了。

所以如果你是做一个任务，或者一系列非常接近的任务，现在可以做得挺好了。但如果你要真正的generalization，也就是泛化能力，希望有一个人形机器人能做好多事情，现在还差得很远。

比如像我们最新的Gimini Robotics这样的模型，它非常强调泛化能力，可以做很多事情。你可以用自然语言说“打开这个水瓶盖子”或者“把这个包整理好”，但是它的成功率还不是很高。

对于非常简单的pick-and-place（抓取并放置），比如把东西抓起来放到某个地方，也许成功率有90%多甚至100%。但对于很多需要精细操作的东西，比如把这个拉链拉上——这个就非常难，你要抓到对的地方，然后往一个特定的方向拉——像这种任务成功率可能就是30-40%。30-40%的成功率在现实生活中是不可用的。

所以我觉得，虽然我们的进展非常快，但gap也还非常大，还需要好几年的时间，才能让机器人足够完善，进入各行各业来帮助我们。

**张小珺：如果用一个GPT那样的标尺来定义，大概到了哪个阶段？**

**谭捷：**这个其实很难做对应。我是这么想的：现在大家看到了足够的sign of life（生命迹象），表明我们scale up现在的training recipe（训练配方）是会work的。但可能还需要两三年时间，才能达到一个GPT-3、GPT-4那样的水平，让你真正觉得“哇，这东西真的会有用”。

然后我觉得可能还需要额外的5到10年时间，才能让它真正落地。

**张小珺：落地的时间更长。**

**谭捷：**一般做research是这样，你有一个想法，从想法到一个prototype（原型），这个过程很快，因为做完prototype就可以写一篇论文，周期可能是6个月到一年。

但从你写完论文，到你有胆量拿出来做live demo（现场演示），而不仅仅是录一段视频，可能需要一两年时间。因为你在写论文时有很多assumption（假设），所以它可能只在一个非常小的区间内工作。

然后从live demo到真正落地，那可能又是5到10年。

你就想自动驾驶。从最开始，比如在DARPA的Robotics Challenge上，你说我可以开好二十几公里；到后来每个厂商都能在一个固定的园区里做demo；再到今天，也许算落地了，因为Waymo和Tesla都有自己的自驾产品。这中间确实隔了十年。

从demo到真正落地，隔十年并不是一个非常夸张的事情。

**张小珺：所以我就在想，你看自动驾驶的动作输出是一个这么有限的领域，都需要花费这么多年。那机器人就让它一个领域、一个领域地做就好了，为什么要去追求足够的泛化性呢？——我们为什么需要一个足够通用的机器人大脑来做人形机器人？**

**谭捷：**这是一个很好的问题，这里面的很多争论都比较philosophical（形而上的）。

我的感觉是两条途径都是有可能的：先做非常专业化的事情，在一个领域落地；versus你做一个最general的、通用的人形机器人。

我觉得并没有对错，但这个世界的发展无关乎对錯。

这两条路可能都可行，但最后会发生什么呢？——可能会有一个大佬，他可能是Elon Musk，可能是Steve Jobs，一个visionary（有远见）的人，他灌输了一个概念，说“通用人形机器人是最终局的解决方案”。当一个大佬发话以后，就会有很多follower（追随者）、很多钱和很多talent（人才）进来，最后就促使这一条路径成了真正被解决的路径。

所以说，并不是说做specialized（专用）的机器人，然后一个一个domain（领域）去solve（解决）是错的。只是可能现在因为硅谷的发展，因为有大佬特别提倡这个方向；

同时，大语言模型也证明了，如果你做specialized model（专有模型）——以前的语言模型通常都是specialized model，比如你做英到中的翻译是一个model，做VQA（Visual Question Answering，视觉问答）是另外一个model——但后来你发现，当你真正有一个generalist model（通用模型）的时候，那些specialized model（专有模型）就完全不能与之竞争。

这也是另一个例子来解释，为什么大家更相信通用的机器人。

**张小珺：你刚才提到过去一年进展非常快，可能超出预期，它的进展快来自于哪些变量？**

**谭捷：**一个是VLM模型的发展，比如Gemini的发展，GPT的发展。还有很多技术的变革，比如现在很多model是所谓的“thinking model”（思考模型），它在inference time（推理阶段）可以用很多的token budget（token预算）来提高最终答案的准确性。这是一个从技术角度的变革，这也使得robot can think as well（机器人也能思考）。

我们最新的Gimini Robotics 1.5，有一个比较重要的突破，就是利用了这个thinking的能力。这是技术上的。

第二个是从重视程度上，我觉得在硅谷，大家都觉得机器人可能是即将发生的最重要的变革之一。所有的公司都投入巨资去攒他们的机器人团队，去做机器人大模型。如果CEO们都重视了，那么分配的资源、算力都会增长，这也从另一个角度加速了机器人的发展。

第三点，这也使得硅谷现在非常卷。以前大家觉得996是中国特色，现在硅谷也是996了。

至少做AI、做机器人的肯定是996。为什么会996呢？因为没有人想输在这场competition（竞赛）里。所有人都希望自己的公司或团队是世界第一。如果你是世界第二，你团队里最优秀的人就会觉得要去那个世界第一的团队，因为在那里能做成事。

为了防止那个发生，你就只能加速工作、加倍工作，使得你永远保持在第一梯队，或者整个行业的最前列。这使得大家花了更多的精力、更多的时间在科研上，这也是我觉得最近发展特别快的原因之一。

**张小珺：你刚才说未来有两个关键阶段，一个是要先到达GPT-3的时刻，再去落地。你觉得从现在这个节点到GPT-3，中间差的是哪几步？有哪些关键问题解决了，可能就到了？**

**谭捷：**我觉得一个最大的问题还是数据问题。

对语言模型来说，数据是free的，网上有那么多的语言数据，你可以抓取PDF，可以digitalize（数字化）很多书本，互联网数据太多了。而且语言相对来说也是一个narrow domain compared to robotics。

但是robotics是在一个非常复杂的unstructured environment（非结构化环境）里，可以发生任何事情。所以它需要极大量的、非常diverse（多元）的数据，但这些数据现在是不存在的。

现在有很多startup叫data factory（数据工厂），他们通过比如遥操作的方式来collect（收集）很多数据，通过simulation的方式来collect数据，然后把数据卖给做模型的大厂。所以，数据还是一个从根本上制约发展的bottleneck（瓶颈）。

**谭捷：**我现在看到最明显的就是数据。我确信，现在的数据量完全没有办法saturate（喂饱）模型的能力。所以当你数据大到一定程度上，我肯定会发现第二个瓶颈，可能是模型的architecture（架构）或者是其他的。

但是因为现在数据如此之少，所以你还没有发现第二个瓶颈是什么。

**张小珺：到底需要什么样的数据？怎么定义一个好数据？——真实世界的数据太变幻莫测了。**

**谭捷：**对，所以需要很多很多不一样的数据。

机器人领域经常会聊：“数据金字塔”。

这个金字塔是这样，最底层是量非常大、非常scalable的数据，这可能是互联网上已有的数据。

上面一层可能是video数据，这video数据有可能是我们叫egocentric video data（第一人称视角的视频数据），就是从人的第一视角看到你做事情的那种数据。

这种数据也很多，YouTube上有海量这样的数据，而且也很容易采集，因为你做事情无非就是额外戴一个眼镜或camera。所以它量也非常大。但是因为人和robot的形态很不一样，所以这个数据也不是特别有用，至少大家还不知道怎么用。

再往上可能是simulation数据，这个数据和robot形态可能更接近了，也包含了很多robot action的标注，但是有一个sim-to-real gap（仿真到现实的差距），就是你在simulation里做的数据，和真实世界的物理毕竟还是不一样的，它只是一个数学简化。

再往上，可能就是robot-specific（机器人专有）数据，你通过遥操或其他方式获得的机器人数据。

所以大家一般认为有这样一个金字塔，你每一个level的数据都需要，但是需要的量不一样，采集不同level数据的cost（成本）也不一样，但这些数据都很重要。

底层的数据，需要很大的量，但它的质量可能不是特别高，因为它跟机器人有很大的gap。通常大家说，在训练机器人模型时，有预训练和后训练，也就是pre-training and post-training。

在预训练阶段，你可以用各种各样海量的数据。在预训练阶段，它需要学会的只是一个intuition（直觉）或对物理的理解，并不一定要对自我形态或者对任务的认知，但它需要学会物理，所以你只需要很大量的数据。

但在金字塔最顶端的时候，你需要知道这个机器人是这样一个夹爪、这样一个构型，然后你做这一个任务，比如打开这个瓶盖，它就需要非常精细、高质量的数据，但那个数据量可能不需要很大。

整个金字塔都非常重要。

**我们现在聊聊你们最近的工作吧。你们刚发布了Gemini Robotics 1.5，将AI agents带入了物理世界。在这个工作中，你觉得最重要的发现是什么？**

**谭捷：**我们有两个比较重要的发现。

第一个是我们把“thinking”加入了VLA模型。以前的VLA模型，输入是图像和用语言表达的任务，输出就是马达的角度，直接对机器人进行控制。现在我们把“thinking trace”，也就是机器人是怎么想的，也作为输出。

比如说一个任务是“把我的衣服按照颜色分类”。机器人得先想，因为这个任务挺复杂的，它得想“这是红色的，所以要扔到红色那一堆里；这件衣服是白色的，所以要扔到白色那一堆里”。这里面有很多很小的步骤。

上一代的机器人模型是没有办法想这么细致的东西，做一个multi-step task（多步骤任务）。现在这一代模型能想：“这是什么颜色？如果我知道它是什么颜色，那么下一步应该做什么？”

所以它的输出是，先输出一些文本来思考这个问题怎么解决，然后基于这个文本输出一堆action来做这件事；接着继续输出一些文本来想下一步该干什么，再输出一些action。

这使得一个非常复杂的、需要很多步的任务可以被分解。这是第一点，非常难的任务现在可以做了。

第二个好处是，机器人可以向人表达“我下一步想干什么，为什么我想这么干？”这在人机交互时增加了很多透明度。无论是从安全性的角度，还是从人机交互的角度，都让人更安心一些，因为你知道这机器人是怎么想的。这是我觉得一个比较重要的突破。

第二个非常重要的突破，我们叫cross-embodiment transfer（跨具身迁移）。

什么意思呢？我刚刚说了，机器人数据非常稀缺，尤其是你用机器人A采的数据，只能用来学习机器人A上的task和skill。当机器人A升级了，可能camera换了新的，或者mount（安装）在一个不同的位置，或者手臂多了一个自由度，那么以前采的数据都没有用了。

而且还有其他机器人，比如人形机器人或者机器人B、机器人C，它们因为构型不一样，数据是不能放在一起互用的。这就导致你的数据量更少了。因为你对每一个单一的机器人都得单独采集数据。

在Gemini Robotics 1.5中我们发现，不管你用什么样的机器人——至少我们测试的那三个，一个是Aloha，一个非常简单的双臂机器人；一个是bi-arm Franka，一个更工业级、更powerful的机器人；还有一个是Apptronik的人形机器人。

当我们把所有数据放在一起，并且开发了一个新技术叫motion transfer（运动迁移），它能更好地利用这种cross-embodiment的数据——使得在机器人A上见过的任务，机器人B也能够执行。

举个例子，假设你学会了开车，我从来没有学过开车这个任务，但我也学会了开车，它可以跨本体。这个从根本上解决了一个问题，就是数据量不够的问题。因为任何机器人采集的任务数据都可以被其他机器人利用。

**张小珺：在大语言模型里加入thinking和在机器人里加入thinking，不同是什么？核心难点是什么？**

**谭捷：**大语言模型其实比较大，而机器人模型没有那么大。为什么呢？

因为机器人模型要做很快的inference（推理），它不能等5秒钟再做下一个动作，所以它的inference budget（推理资源预算）非常小。你还是希望比如每0.5秒或每一秒，它能做出一些动作。所以它的thinking长度和大语言模型是非常不一样的。

**张小珺：Thinking更短。**

**谭捷：**要短很多。大语言模型为了解决一个问题，可以想20秒，然后给你一个答案，只要那个答案是对的，大家一般都很高兴。但如果你交给机器人一个任务，它每一步都要想20秒，你就崩溃了。所以它可能每一步只想0.5秒，它们的budget非常不一样。

**张小珺：能处理的最复杂的问题会是什么？**

**谭捷：**我们在VLA上的thinking还是相对比较弱的thinking，因为它有很多限制。我发觉一般如果一个task只需要几步分解，比如“sort the fruits by color”（按颜色分类水果）或者“sort the clothes by color”（按颜色分类衣服）——它可能第一步是认清楚颜色是什么，第二步是认清楚另外几堆东西里对应的颜色是什么，第三步是把它放到对应的堆里。

这种比较简单的推理是可以的。但是如果你需要它额外地去获取信息，那个是做不了的。

比如我说“你帮我整理一下行李”，它可能会想：“那整理行李的话，我想知道你要去哪里旅行？去多久？那边的天气状况是什么？”它需要额外获取更多的信息，然后通过所有这些信息再做thinking，那个在VLA那一端是做不了的。

所以在我们Gemini Robotics 1.5的工作中，我们做了一个快慢模型的划分。

有一个比较慢的模型，它可以做这种非常长的thinking，做一些决策。比如你让它打包行李，它可以去搜Google Search，可以搜你的calendar，可以搜weather report，然后它可以先想20秒，come up with a plan（制定一个计划），然后问你这个plan是不是合理。

到了VLA那端执行这个plan的时候，它就可以说：“我可能需要把这一堆衣服放进来”，然后一件一件拿。

它们都是大脑，但是大脑也有分层。你很多大脑的事情是要做很多计算、很多planning的，那是比较慢的思考。很多大脑的决策是instinct（直觉），那个是比较快的思考。

**张小珺：你们是把它拆分成了一个ER和一个VLA两个模型。**

**谭捷：**ER其实叫Embodied Reasoning（具身推理），它更多是一个慢思考的过程。VLA是要输出robot action（机器人动作）的，所以它更多是在执行端，是一个非常快思考的过程。

**张小珺：也就是说，你们选择了一个双模型结构，不是一个端到端的统一模型。你觉得这会是一个过渡的方式，还是一个终极的方式？**

**谭捷：**我现在觉得它应该是个过渡的方式。

因为现在受制于很多限制，比如算力的限制、模型大小的限制。但我觉得可能再过几年，当算力不是很大问题的时候，如果有一个unified model（统一模型），那可能是最佳的。

因为你有两个模型，你总是要界定它们之间是怎么交流的。现在这个大模型和小模型之间是用语言来交流的，但语言并不是一个high-bandwidth（高带宽）的交流方式，它语音会丢掉很多信息。

所以你希望是一个模型，它内部不需要一个额外的interface（接口）来做交流，这样就没有信息损失。但同时，因为现在算力等等原因，使得这个实现非常困难。

**张小珺：它需要特别大的算力吗？**

**谭捷：**因为你要做reasoning，要用web search之类的，你是需要一个非常大的模型的。那个模型你很难做到real-time或者每秒做5到10次的决策。但小模型可以。

所以当你要一个unify model（统一模型）的时候，它必须非常大，因为它要做reasoning，而现在的算力不足以支持这样的大模型。

**张小珺：现在的快思考和慢思考分成两个步骤、两个阶段来完成，很大一个原因是因为算力还不够。有没有其他原因？**

**谭捷：**我觉得现在主要是算力原因。

**张小珺：这个也make sense，自动驾驶最后也过渡到了端到端。**

**谭捷：**但自动驾驶其实它不需要很多planning的过程，它的planning很多是通过传统方法做的。比如我有一个map，有A点，要去B点，怎么找到一个路径？这个都是用传统方法做的，它并不是真正的端到端把mapping和planning都做到和执行一起。

其实planning在自动驾驶里面是一个分开的步骤，是一个传统方法做的，就像Google Map或者百度地图。执行的话，对于自动驾驶它是一个非常快的决策，因为车速非常高，决策的速率得非常高，所以自动驾驶的端到端模型不会很大。

**张小珺：你们在做实验的时候，加入thinking容易出错的环节可能是什么？**

**谭捷：**我觉得一个可能是overfit（过拟合）。

当你加入thinking的时候，你需要标注很多它是怎么think的。在做training之前，你采了很多数据，采集数据的时候你得说：“我是这么想的，我下一步要干什么，这是我的动作。”但是如果你的这个标注非常单一，就非常容易出现overfit的状况，使得你只有在做这样一些事情的时候，它的thinking是make sense（合理）的。

如果你做一些没见过的任务，因为他没见过，所以他的thinking trace（思维轨迹）会非常奇怪，他会做完全不make sense的事情。

**张小珺：你刚才分享的第二点，是跨本体的数据运用，这个里面有没有更多可以分享的？**

**谭捷：**我给你举个例子，我第一次看到这个结果的时候，印象非常深刻，因为我觉得这真的是一个质变。

大家说跨本体已经说了很多年了，但我觉得这个概念有点oversell（过度推销）。哪怕早期，Google自己做了一篇paper叫RT-X，就是他跟二十几个不同的学校、不同的lab收集不同的机器人数据，混在一块训练一个大模型，然后说发现了这二十几个学校的数据放在一起是有优势的，有benefit。

但那个东西其实很难量化。包括最近看很多机器人大模型，他都会说：“我有五个不同的本体，我把数据混在一起，使得我们这个东西更general。”但这个也很难量化。

这次我们发现，比如说我们有一个Aloha，它是一个tabletop robot（桌面机器人），它做的事情都是在桌面上。我们所有data collection（数据收集）可能就是从桌面上抓一个东西放到别的地方，在这个桌面上开瓶盖、写字之类。它没有见过3D的场景，比如在一个垂直的平面上，或者一个有高低层次的橱柜里做事情，它没有见过这样的数据。

所以如果你给它一个有高低层次的书橱，然后说：“你把上面那一格的书给我拿下来”，它是做不到的。因为这完全在他的训练数据集之外，他还是会在桌面上磨磨蹭蹭地摸一些东西，虽然那个书架是垂直的。

但是我们有另外一个机器人，叫bi-arm Franka，他采集的很多数据都是在垂直的领域，比如他有很多工具，可以从一个垂直的workbench（工作台）上拿下来。当把数据放在一起训练，Aloha是从来没有见过这种垂直场景的，但是当你把Franka能做的事情放到Aloha这个场景里，Aloha突然间也能做这样的事情了。

**张小珺：具体是怎么做到的？**

**谭捷：**我们有一个方法叫motion transfer。它就是说，你不仅要把数据放在一块，同时你在模型的architecture上、在training recipe上也要做相应的改动。

**张小珺：这是一个能够泛化到很多领域的方法吗？除了你们实验的这三个机器人以外，它还能够有更广泛的泛化性吗？**

**谭捷：**首先，它并不代表我给你一个新的机器人，它不用任何训练就能做那些事情。不是这个意思。只是说，在我有训练数据的机器人里面，虽然我没有见过这个task，但这个task是别人见过的，我就能做那个任务。所以它有一定的泛化性，但它的泛化性是任务层面的，并不是机器人本体上的。

**张小珺：这个对于更接近跨形体的通用智能，是一个可行的路径，是吗？**

**谭捷：**我觉得是个可行的路径。

**张小珺：这个还挺本质的。**

**谭捷：**我非常同意。所以我们团队看到这个结果以后都觉得非常激动人心。

**张小珺：motion transfer怎么做的？**

**谭捷：**这是一个secret sauce（独门秘诀）。

这个问题我被问了很多遍，但真的很难评论。

**张小珺：研究者会提到，具身智能的难点不一定在算法，而是在反馈信号，因为它缺乏像语言模型那样清晰、可以验证的反馈。你怎么看这个问题？你们的robotics在系统设计上是如何获取和构造这种信号的？**

**谭捷：**我觉得当你有数据，并且用传统的，比如说imitation learning（模拟学习）的时候，你已经有了足够的信号，我并不理解说缺信号是什么意思。

但是如果你说的是用强化学习，强化学习需要一个reward signal（奖励信号），但很多任务你很难写一个reward function（奖励函数）。比如说“我要把这份菜放到冰箱里面”，这个怎么用一个数学来表达成功与否？这个reward function很难表达出来，我是同意的。

这个我觉得得分不同情况来解释。对于imitation learning来说，我不觉得信号是个问题。但对于强化学习来说，你怎么用reward function（奖励函数）来specify（具体说明）你的任务，的确是一个很难且并未解决的问题。

**张小珺：关于reward function，你们现在怎么解决这个问题？**

**谭捷：**我觉得这个问题并没有很好的解决方案。

这可以岔开讲一点——为什么强化学习解决了足式机器人走路的问题？是因为它的reward function相对来说比较straightforward（直接）。你只要向前走了，然后没有摔跤，就可以很容易地写一个数学表达。

但是对于manipulation来说，你有太多的不同任务了。比如我希望抓起一个筷子，你很难用数学表达式来表达“我是否抓起了筷子”。再比如我要把东西放进抽屉里，你也很难写一个数学表达式来表达“这个东西是不是在抽屉里”。

有成千上万个不同的这样的任务，你都要用reward signal来表征它，我觉得这是一个几乎不可能的事情。这就是为什么强化学习在manipulation（操控）里面并没有解决得很好的原因，就是这个reward function非常难以specify。

**张小珺：对于这种跨形体迁移的任务，怎么设计呢？**

**谭捷：**因为我们现在主要还是做imitation learning，不是通过强化学习。所以只要你学会了就行，因为你是有榜样的，imitation是有label（标签）的。你只要使得你的神经网络的输出和你的label尽可能接近就没有问题。

**张小珺：哪些因素有可能会决定迁移的上限？**

**谭捷：**对，这是个很好的问题。虽然我们有很多例子证明迁移是成功的，但也有很多例子证明在很多场景中，迁移并不是非常成功。

我觉得两个不同机器人它的形态到底差多少会有很大影响。比如说，我是从一个单臂夹爪机器人要迁移到一个双臂人形机器人，这肯定是一个非常非常难的问题。

你看我们实验的三个机器人都是双臂的，虽然它们构型很不一样，比如有的是6个自由度，有的是7个自由度，有的是更高自由度的，但它们都是双臂。如果你是从夹爪到五指灵巧手，它肯定也会比夹爪到夹爪要难一些。所以有一个embodiment gap（具身差距），如果那个gap非常大，这种跨构型的迁移就会比较难。这是一点。

第二点，我们发觉在不同的embodiment上，你收集的数据量也非常重要。

如果你已经收集了很大量的数据，那么其实不需要其他embodiment的迁移，它做事情就已经做得非常好了，所以其他embodiment给你的那个正向的delta（增量）会非常小。但是如果说有一些机器人，比如人形机器人，你采集数据非常困难，但你可能在Aloha上有非常非常多的数据，这样这个迁移就会非常有效。

**张小珺：你们这篇论文的标题是“将AI agents带入物理世界”，你们在AI agents上借鉴了哪些？**

**谭捷：**首先，robot就是一个physical agent（物理智能体）。对agent的定义就是说它能够做决策，并能够execute actions（执行动作）。

这篇文章其实强调了一点，就是有一个非常重要的agent feature，就是它可以use tools（使用工具）。现在我们的embodied reasoning model（具身推理模型），它可以写code，可以查阅网站，就是它可以用这些tools来做决策。

我们有好几个video的例子是，比如说你让它做垃圾分拣，它会根据不同的地点，比如说在San Francisco，它可以search Google Maps找到你的地点，然后根据当地的法律法规决定应该如何做垃圾分拣。

这些都是use digital tool（使用数字工具）的例子，这使得机器人的knowledge base（知识库）宽广了很多。

它不只有大模型已经capture的common sense，它可以通过web search和其他tools，使得机器人的functionality（功能）和capability（能力）有很大的扩展。

**张小珺：沿着Gemini Robotics 1.5 往后发展，下一步的关键突破口会是什么？**

**谭捷：**这个问题非常好。其实有很多很多方向可以发展，我们在论文的最后一章也讲了一些未来的方向。

我觉得可能我们比较重视的一点还是数据——数据、数据、数据。

我觉得遥操作还是一个非常难以获取的数据。有什么办法可以让我们利用越来越少的遥操作数据，和越来越多我们可以快速获得的数据来训练这样的大模型，可能是非常重要的一步。

所以我们会花更多的精力，比如利用simulation数据；利用human video（人类视频），比如YouTube上的一些数据；利用甚至是现在模型生成的数据，比如VEO生成的一些数据。这种数据因为你可以大量获得，所以我觉得这是一种更经济、更有效的获得机器人数据的方式。

如果我们能在这方面有些突破，那我觉得解决机器人问题就指日可待了。

**张小珺：你们现阶段用真实数据用多少？**

**谭捷：**我们现在主要是用真实数据。

**张小珺：所以成本会很高。**

**谭捷：**成本非常高。

**张小珺：国内在数据问题上有很多争论：王鹤就是仿真数据的代表派，但好像除了他以外，大家更倾向于依靠真实数据，因为真实数据的泛化性更好。**

**谭捷：**真实数据没有sim-to-real gap（仿真到现实差距），但是泛化性是由数据的coverage（覆盖）导致的，并不是因为它本身是真实数据还是虚拟数据。

如果你从来没有采集过在厨房烧饭的数据，你的模型就很难泛化到厨房烧饭。

所以说它是coverage问题，并不是真实还是虚拟数据的问题。

**张小珺：过去几年，从大语言模型里应用到机器人领域了很多研究思想，对比一下机器人基座模型和大语言基座模型，它的研究范式有什么不一样吗？**

**谭捷：**我觉得还是很不一样的。它们其实并不是两个独立的学科，更多的是A利用了B。

在大语言模型上，你有很多问题，比如多模态怎么训练？预训练应该怎么样？后训练应该怎么样？RL应该怎么用？

但机器人现在对大语言模型的应用，还是说我加一些更多的data，在已有的大语言模型基础上增加一些新的输出。所以做法上还是很不一样。

很少有公司真正从头开始去pre-train一个机器人的大模型。

**张小珺：为什么呀？**

**谭捷：**因为cost和data。你pre-train一个大模型非常贵，可能需要好几万张卡跑好几个月。同时你也没有那么多的机器人数据。

所以基本上大家还是因为数据局限和预训练的成本，在一个预训练好的大语言模型上，加上机器人数据进行一些微调。这就使得整个范式非常不一样。所以两边有相互借鉴的点，但它们并不是两个平行的学科，可以完全一一对应地相互借鉴。

**国内有一个非常鲜明的仿真数据驱动派，就是王鹤。他的观点跟你类似，就是说雇人遥操采集真实数据的成本非常高。**

**他当时给我算了一笔简单的账，说一台人形机器人制造成本最少10万，买1万台用于数据采集，意味着10个亿。每台两班倒雇人遥操需要4个人，一个月可能就是小几万。此外还需要标注和质检，每个月维护1万台机器人的成本在数亿到十亿。**

**你觉得他这个账算得对吗？**

**谭捷：**你刚刚说的那些数字比较快，我没有仔细算。但是in general，我是同意他的。遥操需要机器人成本、运营成本、质检成本，这些东西加起来是非常非常贵的。

虽然我没有算那个账的具体数字对不对，但我觉得这肯定是一个不是很scalable（可扩展）的方式。而且，我会非常诧异，如果最终大家是通过完全遥操的数据来解决机器人问题的，我觉得这个可能性非常低。

**张小珺：在这个背景之下，仿真数据就是一个可行的方案？**

**谭捷：**对，但“仿真”这个定义现在越来越模糊了。

以前的仿真是指物理仿真，大家说的可能是Bullet、MuJoCo、Isaac Gym这些，它其实是在计算机里面解物理方程，计算运动轨迹。

但现在因为video generation model（视频生成模型），比如VEO、Sora 2的兴起，很多人认为仿真其实就是生成一段视频。如果这个视频看上去物理是正确的，它也是一种新意义上的仿真。

**张小珺：是生成式AI带来的一种新的仿真形式。**

**谭捷：**对，而且我觉得在不远的将来，传统物理模拟仿真会慢慢地被生成式模型的仿真所取代。

**张小珺：这个生成式模型的仿真现在发展到什么阶段了？**

**谭捷：**刚开始。

真的经济吗？它可能不经济，因为你要生成视频其实更贵。

它需要更多的算力成本。但是你其实解决了很多问题。比如我要生成任意场景，在传统的仿真里面，你需要有人建模，建完模以后就像做游戏一样，需要很多designer把所有的场景、所有的资产拼在一块。

我要500个家庭场景，你就得一个个手建，这就非常困难。但是我要500个家庭场景的视频，你只要500个不同的prompt，你说：“我要有一个粉色的床，加上两个床头柜。”另一个你说：“我想要一个很大的白色的床。”

你只是输入的语言不同，就可以瞬间生成两个完全不同的视频或仿真。但以前在传统的仿真里面，你就得手工一个一个地把这个场景给建出来。

**张小珺：他们这个行业确实能帮助到你们的数据问题，视频生成的进展让机器人领域的人很兴奋，是吗？**

**谭捷：**我觉得所有的视频生成模型的进展都会让机器人领域感到非常兴奋，因为这就是一个新的仿真或者新的world model。

世界模型的定义是：如果给上前一帧，再给上机器人的动作，你可以预测下一帧。

现在绝大多数的视频生成模型，都不是说我可以通过输入一个机器人或人的动作来改变下一帧的结果。所以现在我还不会称之为世界模型，但是感觉从现有的视频生成模型到世界模型不是很遥远。

或者从另外一个角度，VEO它是一个视频生成模型，但是Genie它更像一个世界模型。因为Genie是你可以玩的，你可以通过按键来改变你生成的下一帧是什么样子的。你可以驾驶着一只龙，然后说我要左转、右转，看到完全不同的世界。

所以当你在每一帧的时候，可以有一个输入来改变你的下一帧，那个感觉就是世界模型。但是如果它是一个已经生成好的、几秒钟的静态视频，那就不是。

**张小珺：现在谁做得最好？在硅谷。**

**谭捷：**Google DeepMind。我觉得OpenAI的Sora做得也不错。还有很多小公司也在做。

**张小珺：真实数据和仿真数据，可能的优劣势是什么？怎么弥补仿真数据的缺点？**

**谭捷：**生成极大量的仿真数据，是弥补它缺点的一个很重要的手段。

仿真数据它不够真实，但是如果你在仿真的时候不断地变化它的一些参数，同时生成极大量的数据，那么从平均的意义上，它可能也足够cover真实世界的物理了。所以说有一种方法是用compute来解决精度问题。

**张小珺：用算力来换精度。**

**谭捷：**对，你没有那样的精度，但是你可以生成极大量的数据。这样当你做平均、当你学习的时候，因为数据量大，其实你是取了个均值。这可能就和真实世界的物理比较接近了。

**张小珺：用视频生成来做仿真，现在的瓶颈在哪？**

**谭捷：**第一个是它有很多幻觉，第二个是它有很多非物理现象。

有很多人经常测视频生成模型是通过生成做体操的视频。如果你生成一段做体操的视频，在整个过程中那个人还是两条腿，说明这个模型还不错。但很多时候，这个人在翻滚的过程中，就不知道有多少条腿会被生成出来。有很多这种hallucination（幻觉）或者非物理的现象。

**张小珺：不相信仿真数据的真实数据派，**他们的逻辑是什么？

**谭捷：**我个人感觉是，仿真数据是需要一段基础研究的，它不是那么简单直接。

但是真实数据，现在已经证明，你有更多的数据，效果就会更好。所以它可能会有一个玻璃天花板。虽然它加速很快，因为你有数据就可以马上看到效果的提升，但是因为你最终的数据不可能无穷无尽。

**张小珺：它很快会达到这个领域的数据墙？**

**谭捷：**我不知道是不是很快，但是eventually它会有一个数据墙。

但如果是仿真数据，你现在因为有sim-to-real gap，所以可能开始的时候效果不是很好。你加数据，会觉得很多东西可能都在noise的范畴之内，你没有看到很明显的提升。但是一旦research有了突破，它就没有那个玻璃天花板。

**张小珺：**所以，**这是一个信仰问题。**

**谭捷：**绝大多数research都是信仰问题。

**张小珺：你信仰的是仿真那一派？**

**谭捷：**我信仰的是scalable data那一派。Scalable data包括仿真数据，包括人带着camera采集的数据，包括用视频生成模型生成的数据。这些东西都是可以用算力来给你无穷无尽数据的。

但真实的机器人数据是需要operation、需要cost、需要robot，那个我觉得不是一个很scalable的数据源。

**张小珺：不管怎么样，只要它scalable就可以。听起来仿真数据是一个更可能scalable的方案——这个是不是也可以用来解决大语言模型的数据墙问题？**

**谭捷：**现在其实很多大语言模型，感觉大家经常会说有一个“吃了吐、吐了吃”的问题。就是你先吃了internet-scale data（互联网规模数据），然后它开始生成各种各样新的文本、新的数据，然后它再吃回去，又生成新的。这也是一种解决data不够的方式。

**张小珺：在一个robotics团队里，做仿真数据的人多吗？**

**谭捷：**这完全看团队的信仰是什么。像Google DeepMind，它有一个叫MuJoCo的团队，是一个非常知名的仿真团队。

**张小珺：硅谷基本上都是仿真派吧？**

**谭捷：**那也不是。

硅谷的公司大家都会讲差不多的故事，区别只是他们数据mixture里仿真数据的比例问题。大家不会孤注一掷地只用一种数据源，都在不断探索。

但数据质量非常重要。如果数据质量非常差，越多的数据可能效果越差。

**张小珺：怎么评判数据质量？**

**谭捷：**这个领域其实没有评判数据质量的标准。大家还是凭researcher的经验，看着数据感觉“这个数据太抖了，不够smooth（平滑）”，或者“这个数据已经采集过了”。有很多这样人为的评判标准，并没有标准化。

这也使得一个新兴产业，叫data foundry，面临一个困难：data foundry采集了很多数据，但我们并不能告诉他们采的数据好不好。

所以我们拿来用，如果效果不好，我们就会说是data没采好，他们肯定会说是你们模型没训好。这里会有一个扯皮的过程，原因就是data quality没有很好的定义。这的确是一个科研问题，现在没有很好的定义。

**张小珺：如果具身智能机器人领域，只解决一个最重要的问题就能带来飞跃，你认为是数据问题？**

**谭捷：**我觉得是数据问题。

我觉得有的时候，你为了解决一些现实中的问题，或者希望在短期内取得更好的效果，你会采取一些shortcut（捷径），做一些分层的模型。但是至少从我过去的经验告诉我，也许你直接投入最终你相信的那个端到端的大模型或unified大模型，最后那个可能会胜出。

**张小珺：你们现在投入了吗？**

**谭捷：**我们现在基本上都是端到端的。除了那个短期的，给你做一个proof of concept，说ER和VLA可以interact，短期内你可以用这个模型。但同时，我们也是大量投入在端到端的unified模型上。

**张小珺：VLA会是一种终极架构吗？或者VLA+RL？**

**谭捷：**VLA是现在我觉得效果最好的模型。但大家也在讨论，language可能在描述机器人，尤其是非常复杂的行为时是不够的。因为language就像我说的，它是一种有信息损失的表达方式。

所以大家经常说，也许下一代是world model（世界模型）。因为world model生成的是visual，是下一帧。

你可以看到，比如说我在转笔的过程中，我的每个手指是怎么动的。但是假设我在转笔或者用筷子的时候，你要用语言来表达我下一步应该干什么，那是很困难的。

所以说，很多好的表达方式可能是visual的。所以world model现在在硅谷非常流行，被认为是可能下一个新的范式。

**张小珺：它是替换VLA的吗？**

**谭捷：**它不一定替换VLA，可能会跟VLA共存。可能VLA会变成……我不知道，创造一个新的名词，就是VLVA，你的vision进去，你的language进去，它可以生成下一帧的image或者vision，然后再基于这个生成下一步的action。

**张小珺：世界模型跟它的关系是什么？**

**谭捷：**世界模型其实就是Vision-Language-Vision，vision和language in，然后它可以生成下一帧的图像。

**张小珺：我们在讨论一个机器人大脑的时候，国内叫具身智能，它这个“智”的定义是什么？**

**谭捷：**它聪明，它知道该干什么，它能够思考、决策和行动。

**张小珺：它有一个非常确切的定义吗？是让它更灵活，还是让它大脑更聪明？**

**谭捷：**两点都有，大脑小脑都有。

大脑需要有common sense，需要有解决问题的能力，需要能够根据现有状况给出一个很好的规划，这是“智”的一个体现。

在小脑方面，或者在运动控制方面，你需要能够dexterous（灵巧的），比如用五指解决很多manipulation（控制）问题；你可以用双足很敏捷地做跑跳这种运动相关的任务。所以我觉得“智”是包含大脑和小脑的。

**张小珺：机器人的大脑需要增加更多的模态吗？——除了我们说的视觉、语言、动作，还需要增加触觉、力觉、嗅觉这些吗？**

**谭捷：**这个到底应该在大脑端还是在小脑端是不一定的，但我觉得机器人的发展肯定是需要增加更多模态的。

这里有个小故事可以分享一下，是我的心路历程。

大家一直都说tactile sensing（触觉）非常重要，我也是一直相信的，因为intuitively（直觉上），你每天都有皮肤感受着触摸到的世界。

但是在Stanford有一篇论文叫Aloha，那是我第一次看到人可以通过纯视觉遥操一个Aloha机器人做非常复杂的事情，包括从皮包里拿出一张信用卡，一个非常薄的东西。

我以为这种事情只有触觉才能做成，但是Aloha的出现狠狠地打了我的脸，我意识到其实很多东西用视觉也是可以解决的。于是我hold这个belief for a while，觉得可能视觉就够了，或者说视觉可以做95%的事情，剩余5%才需要触觉。

直到最近，灵巧手开始变得越来越普及，我开始去一些地方用遥操的手段来控制灵巧手。有一个例子是用灵巧手使用剪刀。

用剪刀是一件非常简单的事情，你把手往两个环里一套就可以用。但那个时候他是没有触觉反馈的，我完全通过视觉把被控制的灵巧手往剪刀那两个环里套，然后我这边开合我的手。但因为没有触觉，我不知道什么时候开，什么时候关。因为那两个环非常大，所以有的时候你在不恰当的时间开关，手只是在两个环里面动，但并没有控制整个剪刀的开合。

这时候让我意识到，如果你有灵巧手，触觉就非常重要。

之所以我前面觉得触觉不重要，是因为它其实受限于当时的硬件。如果你只是一个夹爪，那么你可能远远地看到夹爪是开着还是关着，就能做很好的判断。但是当你有一个灵巧手，有五个手指，要做很复杂的行为和任务时，那么触觉感觉是必不可少的。

**张小珺：当你觉得触觉不重要的时候，可能是当时的发展阶段还没有到。加入更多模态是必然的，只是今天觉得它不必须，是因为可能硬件水平还不够。**

**谭捷：**对，而且我们还在解决一些非常简单的问题。

**张小珺：视觉可以解决95%的问题？**

**谭捷：**在那个夹爪时代。

**张小珺：现在你觉得视觉能解决多少问题？**

**谭捷：**现在还在夹爪时代。所以在夹爪时代，在所有夹爪能完成的任务里面，我还是觉得视觉可能可以解决95%的问题。

视觉是对于现在已有硬件最重要的模态。

**张小珺：马斯克的一个观点是，Optimus系统最终将通过观看YouTube视频学习执行任务，他觉得纯视觉就ok了。你不认可他这个观点？**

**谭捷：**我不知道马斯克的原话是不是这样，还是somehow经过了剪辑，把两句可以有非常不同含义的话贴在了一块。

机器人看YouTube视频学会任务，我觉得非常重要，这个其实印证了我前面一个观点，说你不需要遥操，需要的是video数据，因为它是一个scalable的数据。这个我完全没有任何异议，非常同意。

我以前在很多我自己的talk里也会说，希望有一天我们的机器人可以坐在电视机前看看Netflix，看看YouTube，就学会了各种技能。这个我没有任何反对意见。

但下一句话说“它可以完全通过视觉解决所有的问题”，这个我是不同意的，而且这句话跟前面一句话是没有任何关系的。因为你通过视觉学习东西和通过视觉解决问题是两个不同的问题。

**张小珺：自动驾驶还是通过纯视觉在解决问题吗？**

**谭捷：**自动驾驶是通过纯视觉在解决问题，至少Tesla选了一条纯视觉的道路。

**张小珺：但你觉得机器人不行。**

**谭捷：**对，因为manipulation是一个非常复杂的问题。

**张小珺：它需要跟现实世界有反复的互动，而且每一个互动的形式可能是不一样的。**

**谭捷：**是的。当我们说是一个通用人形机器人，它有五指灵巧手，能做人能做的所有任务的时候，那个时候触觉就必不可少。

**张小珺：现在的硬件没有收敛，未来出现的硬件有没有可能不适配今天的大脑？**

**谭捷：**这个就说明cross-embodiment（跨本体）非常重要，说明我们做的这个研究方向还是非常重要的。

但是我个人还是觉得，在未来，人形机器人会成为一个主流的形态。它不会成为唯一的形态，但一定是个主流的形态。

如果你只能bet on一种embodiment，我还是会bet on人形。

**张小珺：也就是说，如果只bet一种架构，它是端到端的；如果只bet一种形态，它是人形的——不要去做那些比较现实的那种分支，因为它可能会浪费很多时间。**

**谭捷：**这个其实有很多可以聊的地方，完全取决于你是在一个大公司做事，还是在做一个startup；也可能取决于你是在硅谷做事，还是在中国做类似的问题。

因为我觉得每个人的目标是不一样的。如果你的目标是solve AGI in the physical world（在物理世界实现AGI）——这也是我个人倾向于做的事情——那么我会非常聚焦于最终的形态是什么样子，最终的模型是什么样子，所有其他的东西可能都是distraction（干扰）。

但是如果你是一个创业公司，资本对你的生存或者盈利有期待，那么你其实很难撇开所有的，我就是不盈利，说“我要做20年以后的最终模型”。于是你可能想的是，我能够在短期内有一些落地，然后把数据飞轮转起来，慢慢地来把这个问题解决。

这个其实有一个对比，可能不一定非常恰当，就是Waymo和Tesla采取了非常不同的策略。他们都想解决自动驾驶。

Waymo是看到最后，我要L4，我要在任何地方都没有人驾驶，我连方向盘都不要。所以他做的很多决策都是为了达到L4。

但是Tesla就说，我们不急，我们反正卖车，可以从L2、L2.5一点点往上做，把数据飞轮转起来，eventually我们可能也会达到L4。所以我觉得这两条路没有对和错。

我也并不是鼓励大家一定要做端到端、一定要做人形，只是大家殊途同归，用不同的方式解决同样的问题。

**张小珺：你举的这个例子非常有意思，但是今天大家会觉得特斯拉是一个更正确的道路？**

**谭捷：**这很难评判。Waymo也有非常成功的，在旧金山或者好几个地方运营的案例。而且我觉得Waymo有一点特别伟大的地方，是他真的把驾驶员从车里拿走了。

我自己也是Tesla用户，我觉得FSD非常非常厉害，我经常用，但是这个和你有勇气把驾驶员拿走，我觉得是一个从0到1的突破。

现在我觉得在大公司是一个非常不错的选择，主要原因还是现在很多事情感觉只有在大公司能做。因为大公司有资源、有算力，聚集了一大批和你一样有着使命感、非常聪明的人。像这种大模型时代，尤其是当你的使命是solve AGI in the physical world的时候，我觉得其实并没有太多其他的选择。

这再岔开讲一下，从宏观上来讲，当一个技术越来越容易用的时候，它很快就会普及。比如步态控制，人形机器人走路，如果像我开始说的用MPC，那你需要一个PhD才能真正理解那个数学，解那个方程。那么这个算法或技术离普及就还差好远。

后来强化学习出来了，我觉得现在很多高中生都可以网上下载一个强化学习的包，比如PPO，从NVIDIA拿一个Isaac Gym，把它放在一起，train一下，deploy一下，很多高中生都能做这个事情了。于是这个东西说明马上会变得非常卷，因为很多人能够进入这个领域来做贡献。

的确，强化学习瞬间就解决了所有的locomotion问题。

同时，在未来你可以看到，prompt engineering是几乎所有人都能做的，因为是自然语言。你可以用各种方式让模型帮你做事。所以大语言模型的出现可能很快会解决很多问题，不仅是robotics，是各个行业的问题。

所以，当我会做一个阶段以后，我发觉强化学习已经普及了，不管是在美国还是在中国，大家都开始用强化学习解决机器人步态问题的时候，那时候我觉得I should move on，去解决一个更难的、还不是全民都可以解决的问题。于是那个时候我就开始做机器人大模型，也就是基础模型。那是21、22年的时候。

那个时候Google发了好几篇相关的论文：SayCan是用语言模型让机器人有了common sense，可以一步步分解一个很复杂的任务；RT-1是说我们可以用一个transformer架构吸收很多很多数据，使得它的performance越来越好；RT-2是说，我本来就有一个VLM，它经过了internet-scale data的训练，我可以加上一些action的训练，使得它可以借用所有internet上的知识来做很多事情。再到后来就是Gemini Robotics 1.5 ，有一个非常强大的基座模型Gemini。

By the way，Gemini非常非常的强大。

我们发现，如果你的基础模型非常强，那么你在加入action data的时候就不需要那么费力，而且你的泛化性等方面都会变得更好。

可能根据你实际在做的事情，你的认知也会非常不一样。

比如如果我跟一年前的自己聊，或者跟很多在学校做机器人的老师、学生聊，大家会觉得泛化能力非常重要且很难做，那个叫visual generalization（视觉泛化）。当光照、布景、颜色变化的时候，机器人本来能做的事情可能突然间就做不了了。因为你可能没有收集过这类的数据。

但是因为我们训练Gemini，它有一个非常强的vision encoder（视觉编码器），那个vision encoder已经见过了全世界所有互联网上的数据（假设），我们就发觉visual generalization comes for free。我们不需要做任何的研究，它的visual generalization就已经特别好。

所以当你有一个已经非常强的基座模型，和你没有这个，或者你用一个开源模型，或者你从头开始train一个模型，我觉得大家的认知会不太一样。


Google可能会更耐心一点，文化也稍微好一点。因为每个人都有自己的priority，有生活中各种各样的状况，所以哪怕你在一个performance review里面表现不是很好，you will have a second chance to prove yourself（你将有第二次机会证明自己。）。

**张小珺：Meta对于最近硅谷的人才流动有带来什么变化？**

**谭捷：**变化非常大。

我觉得Meta做了好几件事情。第一，他把AI人才的价格炒高了，非常高。

AI人才是不是真的值这么多钱？我其实不知道。有很多种说法。

第一种是说这是供求导致的，所有的大公司都希望AI first，所以有大量的需求，但是AI人才的供给，尤其是最优质的AI人才供给是非常有限的。所以因为供需关系，使得价格非常高。

第二种说法是AI人才的确值这个价。因为算力非常贵，如果你把算力浪费了，那个钱也是很多的，不如花钱招一些好的人，好好利用这些算力创造价值，因为那个价值远大于这些人的cost。这是第二种说法，value is there。

还有第三种说法，就是挖这些人和买类似的公司比，挖人还是便宜的，所以这个价格还是值的。我不知道，其实很难判断是不是一个人值一亿美金，但是我觉得Meta最近的一系列操作的确扰动了整个硅谷对AI人才的价格。

**张小珺：基于所有读过的书，推荐两本必读书。**

**谭捷：**有一本书叫《Start with Why》，那本书彻底改变了我的communication skill。第二个叫……我记不起确切的名字了，《The 7 Habits of Highly Effective People》。

**张小珺：基于你当下的认知，一个关键的、重要的bet是什么？**

**谭捷：**对机器人领域重要的bet就是，你得相信synthetic data（仿真数据）的价值。光靠real data是解决不了机器人问题的。

