---
title: 听姚顺雨&闫俊杰的访谈有感
created: 2025-12-29
tags:
  - 个人思考
---
# 姚顺雨

来自张小珺商业访谈录，和姚顺雨的那一期。记录一下我认为的关键信息。

## 数据飞轮

大多数公司还没有形成数据飞轮；他们依赖模型变好，利用模型变好的溢出能力。

如果你要有数据飞轮，首先你要能自己去训模型，并且能通过交互有很好的reward，使你能把好的数据和不好的数据分开。

比较成功的是Midjourney，有非常清晰的reward——人更喜欢哪张图，这个reward和应用是对齐的，reward做得更好，公司就更成功，模型也更好——一切都对齐。有了这种情况，才能自己训练模型，做数据飞轮。

这个过程必须比较非主线。因为如果很主线，我也可以通过Pre-Training或RL提升能力，靠泛化或其他方式。

## 创业公司的机会


**对于创业公司，最好的机会是：你做新的交互方式，并且模型不停有新的溢出能力，让你能够赋能这些新的交互方式****——****两者缺一不可。**

当你已经有了一个交互方式，你必然形成路径依赖。就像2020年Google有无限多资源和钱，有Transformer，但它最自然的想法是：我怎么用这东西提升搜索引擎？

当你有像ChatGPT这样的Super App，很自然你的研究就会center around（围绕）这个Super App，会center around这个交互方式。

你会探索新的产品，但即使是大厂，即使是谷歌，即使是OpenAI，大部分资源还是会围绕你Super App的交互方式——所以，这是创业公司的机会。

传统大家认为发生的事情是：我大厂先做出来一个东西，创业公司就可以开始抄。比如做出ChatGPT，我可以去抄一下ChatGPT，做一个类似的事情。

但现在，似乎反过来也可以成立。可以先小厂做一个事情，它创造出来一个交互的创新或者产品的创新，做模型的公司也可以去借鉴或者应用。

这点还是挺有意思。很多时候大家会说，模型做得越来越好了，是给创业公司做嫁衣了。因为你创造很好的模型，如果没有自己运用特别好，这些创业公司就用好了。

但也可以反过来，如果你创造一个非常好的交互，但没有能力把模型或底层能力做特别好，大公司也可以借鉴你的交互，再加上它的模型能力，做得也特别好。

**这世界是个相互抄的关系，而不是一个单向抄的关系。**


## Agent如何scale up

张小珺：有一个Agent创业者想问你：Agent如何scale up？现在的主要瓶颈是算力，Agent的token用量非常可怕，单个用户消耗可能是Chatbot的500到1000倍，再叠加几百万个用户，成本非常高。这种情况下，Agent应该怎么扩展？

姚顺雨：**最重要的点是——你得先找到一个好的应用。**

Cost（成本）本身不是最大问题，问题是你的成本并不能证明你的performance（性能）或value（价值）是合理的。

如果这是一个很有价值的事，我花500美元，但可以赚1000美元——根本不是问题。这不是technical bottleneck（技术瓶颈），而是product-market fit（产品与市场契合度）的问题。

所以，现在最关键的，是要找到真正有价值的应用。模型的cost会下降，能力会提升，这个方向是确定的。但能不能找到那个有value的点，是最本质的问题。

当然，不同的应用，做法可能会很不一样：

- 如果是一个相对简单的任务，我可以训练一个小模型，让它更快、更便宜、更针对这个任务。
    
- 但如果你要做的是更复杂的事，比如投资、Deep Research，就需要更大的模型，在cost和value之间寻找新的平衡。
    

总的来说，**第一步永远是：找到一个真正有价值的场景。**

一旦你找到它，cost的问题总是有办法解决。

## 未来的Agent

张小珺：在你脑海中，最强的Agent应该是什么样？

**姚顺雨：** 对于不同的任务和交互，需要不同的Agent系统去解决。

模型是可以share（共享）的，但如果你讨论的是整个系统，那就不一样了。就像你问，这个世界上最强的互联网网站是什么？最强的互联网公司是什么？很难回答。它是一个multiface（多面向）的系统，有很多不同侧面。

AI可能也会变成这样的结构。OpenAI可能会成为一个类似Google的公司，成为新世界里非常重要的一环——**但这并不代表，这个世界就会被这样一个单极系统垄断。**

如果真是那样，这个世界就会变得很灰暗。大多数人也就没什么价值了。

张小珺：你对未来Agent生态的构想会是什么样？现在有点像，当年大家都在创业做App的时候，如果再往后推演几年，这个世界会是什么样？

**姚顺雨：** 很难说。**但肯定会有很多不同的交互方式，创造出不同的系统。**

OpenAI这样的公司，会想继续推进一个中心化的助手系统，有更多环境、更强能力，做更多事情。

也会有不同的生态系统，有不同的交互方式，会训练完全不同的模型。甚至从Pre-Training开始，所需要的能力和很多东西都不同。

**比如，另一种交互方式可能是，我想造一个朋友。这个朋友不需要数学、物理特别强，数学太强反而不自然。它记忆不一定特别好，会犯错，有感情，也不是特别rational（理性）。但这也是有价值的——可能有人会做这种事。

这类东西很难和ChatGPT比强弱，它们是不同应用，有不同价值。

**也可能出现一个由****Agent****组成的社会。

为什么这个世界上很多人有价值？不是因为他们的数学或编码能力强，而是因为他们拥有别人没有的信息。

中间商本质是拥有信息差。拥有信息差的人会想维护自己的权利和资源。这样的人会发明出更Multi-Agent（多智能体）或更 Distributed Network（分布式网络）。

在交易世界里，信息很重要，每个人只拥有信息的一小部分，这种情况会出现新的不同形态。可能是Multi-Agent，每个人有自己的Agent，Agent之间可以与百万甚至更多人交换信息，达成交易或某些目的。

根本上，现在非常强的巨头和重要节点，有动力继续推动中心化。但在中心化之外的力量，也有动力做一些非中心化的事情。

**这个世界可能不会是单方压倒另一方，双方都会有自己的力量。**

**而这个世界智能的边界、研究的边界，可能不是由一家机构定义，而是由不同****Super App****共同定义的。


李广密：Pre-Training和RL未来的关系会是怎样的？会不会更多先验知识被放到Pre-Training里？

**姚顺雨：我一个不成熟的想法是：不同应用需要不同形态的Agent，构造方式可能不一样。**

如果我只需要下围棋，我直接做AlphaGo就可以了，不需要Pre-Training，也不需要其他。

如果我有一个非常垂直的场景，这个场景价值足够大，我又有很多数据，可以形成闭环，我也许基于一个主要由RL驱动的系统就能work。

像Google的广告系统或TikTok的推荐系统，有点类似这样的系统——我找到了一个足够封闭的环境，做类似RL的事，就可以带来足够多价值，那这个路径是合理的。

但这个世界上还有很多长尾任务，它们需要泛化，需要构建一个更像人的系统。你虽然不是无所不知，但你可以学习，你可以通过在线学习进入一个新的公司、适应环境、完成新的任务。在这些地方，Pre-Training重要性会更高，因为它带来更强的泛化性。

所以不同应用会有不同技术路线。但技术路线毕竟是工具，只要你的value大于cost，技术上的选择是flexible（灵活）的。

没有哪种技术路线一定会胜出。只要它在经济上成立，就有可能性。

## 聊聊OpenAI

张小珺：我想聊聊OpenAI。我记得你提到OpenAI的几次尝试很有意思。

它最初的计划是构建Gym，一个用于各种游戏的标准强化学习环境。后来是World of Bits和Universe项目，试图把整个互联网或计算机交互编程成一个游戏。一旦能把整个数字世界变成一个环境，用聪明的强化学习算法解决它，就拥有了AGI。

但这套思路并没有奏效。直到GPT-2和GPT-3出现，人们才意识到，之前缺失的是先验知识。你需要一个强大的语言预训练过程，把一般常识和语言知识提炼进模型中。再通过微调，让它成为一个能浏览网页的或能对话的智能体。

你能不能更详细讲讲，OpenAI探索过程背后的思路演化？从Gym到Universe到GPT这一整条路径的尝试中，转折点是怎么发生的？

**姚顺雨：** 这是我自己的总结和揣测。

OpenAI是一个比较bottom-up（自下而上）的公司。在最初7、8年里，它更像是一个research lab（研究实验室），每个人有各种各样的想法，做各种各样的尝试。可能每个人想法都不一样。

但客观看，一开始大家的重点还是聚焦强化学习，当时最火的方向是这个，对吧？

DeepMind大概2015年刚成立，那时AI领域最受关注的公司是DeepMind，它最成功的成果也是强化学习。GPT出现前，最成功的AI项目是AlphaGo。很自然，OpenAI也做强化学习。

**但问题在于，如果你没有一个different bet（不同的下注方向），很难超越前面的霸主。如果OpenAI一直做强化学习，可能很难超过DeepMind。即使你在某些任务上做得比它好，人们提到强化学习，想到的还是DeepMind。**

你要想超越之前的霸主，就必须有一个different bet。而GPT是那个不同的赌注——但这个选择在当时是一个非共识的事情。

我可以讲个例子：我导师是GPT‑1第二作者，他在OpenAI待了一年，然后去普林斯顿当教授。**他对这件事是有点怀疑的。

他觉得GPT‑1的结果也不是特别好，在排行榜上也不是分数最高，而且训练花了很多算力。当时已经有Scaling Law初步雏形。2017年，Ilya就跟我导师说：”Language is basically solved, and we just need to scale up." 语言模型的问题已经被解决了，现在只需要扩展规模就行了。

但即使你在OpenAI，即使你是GPT作者，你也可能没有形成共识。所以OpenAI当时做的是一个非常反共识的决定。现在已经变成了共识。但接下来，你还需要寻找下一个反共识的方向。

**张小珺：当时其他人对你导师的看法是怎样的？**

**姚顺雨：** 我说实话，当时OpenAI内部绝大多数人也不认为scale-up（扩大模型规模）是最promising（有前景）的方向，我觉得这是有可能的。

Ilya最大贡献并不是他做了GPT‑1，或者他具体参与了什么技术工作；而是，他是那个号召大家all in（全力投入）这个方向的人。

Dario（Anthropic联合创始人兼 CEO，曾是OpenAI研究副总裁）也是。他最大贡献不是提出某个具体技术，而是：作为一个创始人，我敢赌。我敢赌这个方向，把所有钱砸进去。

李广密：有人愿意去做GPT‑3是特别关键的。像Dario也好，Tom Brown（Anthropic联合创始人）也好，他们敢于把GPT‑3做出来，这件事让人看到了更大希望，也泛化了。

**姚顺雨：对，** 当然好处在于，你并不需要所有人达成共识。只需要有足够多人达成共识，就可以把它做出来。

张小珺：对于OpenAI内部来说，强化学习在什么时候开始变得特别重要？

**姚顺雨：** 强化学习一直很重要。即使我在做GPT的时候，John Schulman（OpenAI联合创始人之一，强化学习领军人物）还是在继续做强化学习。并不是我做了GPT就把强化学习扔掉了。而是公司70%、80%的资源在做强化学习，一些别的东西还在做。

后来证明，ChatGPT成功，强化学习也很关键。没有RLHF，没有Alignment（对齐）技术，它也没办法形成一个产品。

**历史并不是说我把强化学习彻底抛弃，转而走另一条路，再返回来走强化学习，而是更soft（柔和）的过程。**

## 如果你是xxx创始人


李广密：如果你是Manus创始人、CEO，你今天要走向垂直方向吗？

**姚顺雨：** Manus的一个价值是，它给人非常general（通用）的感觉。但我觉得，**有一个非常通用感觉交互方式的Agent，和你有一些Killer App（爆款应用），是不矛盾的。**

一个比较理想的情况，你有一个非常通用的交互方式，这个交互方式想象力足够大。比如Cursor，虽然它是IDE（集成开发环境），如果它只做 IDE，想象空间是有上限的，就在IDE里面。但如果你做一个非常general的产品形态，比如Manus，想象空间是很高的。

但并不矛盾的是，你可以有每个阶段的Killer App。比如它做PPT特别好，做Deep Research特别好，或者做其他东西特别好。

iPhone或iPad是非常通用的产品形态，但它一开始，都有一些Killer App支持它有momentum（增长动能）。包括ChatGPT，包括微信，很多伟大产品都这样。

你有一个足够通用、简单，或第一性的交互方式，它有很多想象空间。但你去维护它，或者设计路径的时候，你能有各种各样的应用，使它不停地增长。


李广密：顺雨，如果你是一个全球超大互联网或科技公司的CEO，今天这个公司还没有自己的模型，没有好的研究文化，甚至没有好的AI战略，你作为CEO会怎么做？

**姚顺雨：** **首先，我肯定会学习，我会想弄清楚这个事情到底是什么。如果你作为CEO不懂这个事情，所有事情会变得很难。**

很多时候，一个公司的bottleneck（瓶颈）就在于，CEO 对这个事理解不够。如果你不理解，去招一些很好的人、做一些事情，你很可能被他们忽悠。所以，首先要自己学习。

**然后要从创造新的价值来思考问题。** 毕竟你不是技术专家，而是一个CEO，你有一些场景、一些资源、一些优势。从第一性原理看，一个新的技术产生了，你要思考的是，怎么用这些新技术结合你现在的资源去创造新的价值。

当然，你可以尝试做一个和当前业务完全不一样、但价值非常大的事情，比如ChatGPT，但对大多数公司来说，即使很有钱、很强，也不一定make sense（合理）。

所以，第一是自己要学习技术；第二是要思考怎么创造新的价值。


李广密：如果你成为了伯克希尔的CEO，未来要拿出500亿美金allocate（分配）到AGI行业，你会怎么allocate这笔钱？——既能体现回报，也能体现对人类的贡献。

**姚顺雨：这是个很好的问题。取决于你有多少精力，或者有多少资源分配颗粒度。

当然现在OpenAI、Anthropic，这些模型层公司，大概率会有更大价值。

还有一类很有价值的，是能积累User Context（用户上下文），或者能构建特殊Environment（环境）的公司。最终如果AI或AGI是一个系统，它需要有Intelligence（智能），需要有Environment，还需要有User Context，或者对用户的理解。

现在有很多User Data（用户数据）或User Context 的公司，有点像发明车之前的煤炭、煤矿，或者像发明汽车之前的石油公司。

从这个角度，微信或大平台，还是一个易守难攻的好平台，它积攒大量的Context。

如果Intelligence是一个可以逐渐民主化、逐渐变得便宜、逐渐普及，拥有这样的平台，拥有这样的Environment，拥有这样的Context，可能会是一个很强的壁垒。它可能还是一个很好的投资。

李广密：如果你是Cursor的CEO，你会去做Pre-Training的事情吗？

**姚顺雨：我肯定会训练模型，或者尝试训练模型，但做不做Pre-Training看情况。

Coding是非常主线的任务，所有大厂都会把模型的coding做好。所有的Pre-Training、Post-Training、RL，都会考虑到这一点。

这个情况下，要不要做可能取决于，首先这些闭源模型做得有多好，其次开源模型做得有多好，中间有多少gap，你能填补多少这样的gap。

但当然，如果你有很多钱，有很多资源，想把这事情做了，也是合理的。

张小珺：今天顺雨当了很多公司的CEO，那我再问一个：如果你是微信的一号位，你会怎么在微信里做Agent？

**姚顺雨：我可能会不急，先观望观望。

我好像没有理由要急。我会观察，我会学习 AI，会观察有没有什么新的交互方式很有意思。但我不会急着去做很多事——我有易守难攻的地方，为什么要急着进攻？

比较危险的是一个颠覆性的创新。**真正的危险，不是说一个类似于微信的东西打败了微信，而是一个很不一样的东西打败了微信。**

就像微信打败了QQ。当时担心的并不是一个类似QQ的东西打败了QQ，而是一个很不一样的产品去打败这个东西。需要对颠覆性创新有所警惕。

但如果是这些incremental（渐进式的）创新，这种小的创新，早做晚做可能区别没有那么大，也不用太担心。

## 姚顺雨个人相关的

张小珺：在你成长路上，对你启发大的是什么？是书、电影、音乐？哪些东西塑造了你的mindset？

**姚顺雨：看书挺有帮助，我是一个喜欢看杂书的人。什么书都看，什么电影都看，什么地方都想去。

我从小是一个比较_general_的人——我想试图变得很通用，试图了解很多不同的学科，做很多不同的事情。

但后来我发现，一个人即使再聪明、再有精力，他能理解的知识或能做的事情，也只是人类社会积累的知识的很小一部分。更好的是，你去创造一个比你更通用、更_general_的事情。

**我好像一直对于通用性，有一种执念或追求。**

张小珺：通用性意味着什么呢？——可以足够简洁？

**姚顺雨：我不知道，但我从小就是想学习很多不同学科，都很有意思。

我在姚班很多同学，他们是那种很deep（深度的）、很focus（专注的）同学——我去做竞赛，我就把这个事做到极致，不停刷题，做到世界金牌。

但我好像不是那种性格，我是那种——我会看很多数学，也会看很多历史，会看各种各样乱七八糟的东西。

**张小珺：基于你所有读过的书，推荐两本必读书。**

**姚顺雨：**《智能简史》这本书很有意思，是我去年读的。

我会推荐各种各样的自传。传记很有意思，好像你在体验别人的生活。


# 闫俊杰

来自罗永浩对谈闫俊杰那一期。很喜欢！

## AI领域的人才需求

中国的AI能够快速和美国缩小差距的原因是什么？为什么研发投入比美国小很多？

- 主要是人才优势，大量优秀年轻人的投入
- AI 不是玄学，而是可以被第一性原理拆解的工程问题，比如算法该怎么设计，数据的链路该怎么搭建，训练效率该怎么优化，每个东西都有非常明确的目标。
- 中国算力与美国有差距，这种限制倒逼我们必须做创新，而不是照搬美国的技术路线。

AI领域的人才需要三个关键能力：**足够聪明、数学与编程功底扎实、长期专注积累**
- 数学决定对底层原理的理解深度，编程决定实验效率。

## 在商汤工作的启发——团队配合很重要

刚开始做人脸识别时，测试成绩一直倒数，顶着公司最多的资源却持续落后。这段低谷期持续了一年半，每天都要面对“投入产出不成正比”的质疑，经常加班到凌晨三点，早上八点又要开会。

突破的关键是做了两个取舍：**一是放弃“一个场景一个模型”的思路，集中所有资源做一个通用模型，把算力、人才、数据都聚焦到一处，提升迭代效率；二是放弃短期修补，专注长期根本性突破。**

一年多后我们第一次在测试中拿第一，之后就一直保持领先。这段经历让我明白，**管理不是管人，而是凝聚优秀的人一起坚持长期价值，遇到挫折时带头扛住压力**。

要做好一个技术产品，需要算法、工程、优化、数据等多团队配合。

## 能把C端产品做好的秘诀

**一是我们认为C端产品的逻辑也能通过第一性原理拆解，不是靠盲目试错；二是大模型时代，产品本身就是模型—AI提供的智能，无论是文字、视频还是声音，本质都是模型计算的结果。**

传统意义上的产品更像渠道，我们自己做C端产品相当于“开直营店”，合作伙伴用我们的模型做产品就是“分销渠道”，核心还是把模型这个“核心产品”做好。

我们有优秀的产品经理，但资深的产品经理在我们这儿未必成功，真正做出成绩的是一些年轻的、自己培养的产品人才。**他们有两个特点：一是对技术理解很深，二是有产品天分。**

技术驱动不代表不懂产品，反而在AI时代，产品本身就是模型，AI提供的智能本质是模型计算的结果。只要技术能跟上产品想法，产品经理的创意就能落地，这在传统互联网公司是很难实现的。

**Talkie的成功核心在于坚持用更智能的模型驱动产品升级—我们没有把模型停留在产品里，而是持续迭代模型，再用更优的模型升级产品体验。**

而有些同行做了产品后，公司的智能水平就被产品限制住了，没能抓住模型进步的最大红利。

Talkie加入了很多游戏元素，让对话变成“对话游戏”，这也是优势之一。得益于中国游戏行业的成熟，**我们团队里有游戏背景的人才，能把娱乐化体验做得更好。**

**但根本原因还是技术优势，我们的模型支持图片、语言、声音等多模态交互，而Character AI初期只有文字交互，即便后来跟进，我们的模型迭代速度也始终领先。**


用户量大对于模型训练有帮助吗？

- 在推荐领域，比如视频号、抖音，用户量越大，内容越多，推荐地越精准。**但是在AI领域，本质上还是模型的智力水平，这个跟用户量没什么太大关系（或者说帮助不是最大的），本质上还是对智能的定义是什么，应该是什么样的分布，应该怎么样来评测。核心不是用户数据。**


## 公司的三条原则

创业初期定了三条原则，至今仍在坚守；**第一个原则是一定要直接服务用户，绝对不做一单一单接项目的生意；第二个是必须做国际化；第三个是坚持技术驱动，这也是最让我们挣扎的选择。**

国际化一是因为中国用户软件付费意愿低，二是一旦AI行业受到大众关注，国内大概率会先陷入纯免费模式，这种模式下创业公司根本无法生存。

挣扎是否坚持技术驱动的核心原因是我们认为公司不能靠纯烧钱存活，实现通用人工智能（AGI）也必须通过可商业化的方式，这是基于可持续性算出来的经济账。

AGI的实现需要漫长时间，且成本远高于传统互联网公司，只有商业化才能支撑长期发展。一开始我们想，有AI人才再加上互联网人才就能成功，但后来发现，靠模型能力驱动产品和复制移动互联网的经典模式，这两种路径无法共存，后者变现虽易，却不符合我们的核心价值。

## 公司/未来的工作模式

**一是产品经理现在能自己用AI做原型，不再是写好PRD等开发排期，而是带着几个demo来讨论，只有确定方向后开发才介入优化；二是工程师也能借助AI做设计和需求分析，岗位边界在模糊。**

未来更合理的模式是，不同阶段有不同角色主导—算法阶段算法同学牵头，脑暴阶段产品经理主导，开发阶段工程师负责，但所有人都能参与创意，这会让效率更高。

不要把AI行业当成互联网的延续，分工逻辑已经完全不同了

**我们内部就有个特别受欢迎的“AI实习生”，能看内部代码库、对接线上环境，线上出问题的时候，在飞书里跟它聊几句，简单的问题它直接改代码上线，根本不用打开电脑。**

晚上两点服务挂了这种事，以前得爬起来debug，现在全靠它，真是把“实习生”用出了新高度。

非技术人员占1/3，**但其实界限变得模糊了**，比如To B里有个售前工程师/解决方案，传统的做法是做PPT去讲，我们是直接做个demo，需要写代码。比如我们的产品经理对Agent非常懂。比如模型更新的时候，社群运营需要去回答一些开发者的问题，也需要对模型非常懂。

公司非技术岗，比如HR、行政这些，日常工作中AI工具用得越来越多了。比如HR找简历、跟候选人打招呼，很多都是“AI实习生”在做；面试完之后，AI会分析不同面试官的标准，归纳通过者的核心特质，帮我们对齐面试尺度，这在以前根本做不到。

现在agent技术成熟了，定制工具也没那么难。不需要代码基础，**只要说清楚AI需要的技能、上下文和可用工具**，它就能完成任务，甚至写脚本都能靠AI生成。


## 团队士气低迷时用什么方式提振信心

**用第一性原理拆解问题，把困难转化为可执行的原则和目标，通过充分讨论达成共识。**

大家都是理性的人，只要从逻辑上确认方向可行，信心自然就回来了。当然，还有一个实际办法—给大家发更多的钱。要说明原因，核心是传递两个信息：一是肯定大家之前的付出，二是告知接下来还要继续努力。

我们的薪酬在行业内属于高水平，但未必是最高的，真正留住人的是事业本身的价值—大家一起有希望做成更有意义的事。

只要让大家明白，虽然遇到挫折，但我们具备克服困难的条件，只要智商在线，总有一天能成功，钱就会成为信心的加持而非质疑的焦点。

意识到：**算法和基础设施必须是一体的，所有人都要聚焦一个共同目标，而不是各自有各自的优化方向。**

我们深刻体会到，**AI行业不是互联网行业的延伸，是全新的行业—我们试过OKR，行不通；KPI更不行，现在等于没有现成的管理工具，全靠自己摸索。**

## 如何留住核心人才

**罗永浩**：大厂用两三倍薪资挖人的时候，你们是怎么留住核心人才的？

**闫俊杰**：**首先钱要到位，但对最优秀的人来说，钱可能排在第二位。第一位的是他们能否做成让自己骄傲的事，以及在其中能否发挥重要作用。**

还有一点很重要，中国不缺有潜质的人才，但缺乏像OpenAI伊利亚那样的顶尖天才，我们能提供一个让人才成长为天才的环境，这对年轻人的吸引力远超短期高薪。


**至今为止，我们公司所有算法同学的最后一轮面试都由我负责，我最看重三个特质：一是足够聪明，主要指悟性，能自我学习、主动发现问题；二是对AI领域有真正的热情，这种热情没法伪装，有热情的人和没热情的人差距巨大；三是协作能力，AI不是个人英雄主义的领域，必须靠团队合作。专业背景只是参考，这三个特质才是核心。** 

**我发现做优秀的AI模型和打造优秀组织有相通之处，都需要多样性。很多公司要么所有人都是一个模板，要么岗位划分得极其细致。我们更倾向于打造几种不同画像的人才，让他们在共同的底层原则下协作，通过排列组合产生更大的价值。**

比如产品经理、开发、算法同学，在不同阶段承担的职责不是固定的，而是根据项目需求动态调整，这种灵活的组织方式能释放巨大潜力。 

我其实不太喜欢做管理，因为管理带来的杠杆太低，而技术突破的杠杆非常高。

**但我特别喜欢研究组织，很多管理问题本质上是组织不顺导致的。**

在AI原生的公司里，岗位定义不应该照搬互联网公司，不同阶段人与人之间的关系也很微妙，把组织理顺了，很多模型突破才能实现。

至少现在四百多人的规模，组织建设比单纯的管理更重要。

## 公司决策

为什么要同时做四个模态？怎么做到400多个人就能把四个模态都做到第一梯队的？
- **不同模态的底层方法相通，看似四个方向，核心算法逻辑几乎一致，这就降低了人才复用的难度。**
- 相信随着模型融合，这四个市场最终会融为一体，所以从一开始就布局全模态，只是有些领域成熟得早，有些晚。而且我们发现，把技术能力做到行业必需的程度，商业化自然会水到渠成，融资和变现是结果而非原因。

创业过程中公司内部有什么争议的决定？

**最典型的争议是语言模型—有两年时间，它对公司业务没有直接贡献，却占用了最多的算力和人才，当时至少一半人觉得该停掉。还有国内业务，它的ROI比海外低很多，很多人建议只做国际化，但我们觉得中国是最大的单一市场，技术价值终会显现，必须坚持到那一天。**

**处理分歧的关键是“理性讨论、逻辑说服”。我们会用第一性原理拆解问题，不是我拍板说了算，而是互相说服。公司变好的一个标志，就是越来越多人的认知在某些点上比我还深，这时候不管谁说服谁，都是公司的进步。**

当然也有拍板的时候，比如语言模型连续失败时，只能靠信念坚持—因为那是最核心的技术底座。


## DeepSeek在春节期间爆火时的触动？

反思我们自己：为什么没有做得更好？最后发现，是我们对一些本应做好的东西降低了要求，思考不够深入，在选择上不够坚定。不过好在，我们团队的特质是能在打击中变得更好，这些挑战最终都转化成了提升自身能力的动力。


我们选择开源，核心有两个原因。

**第一，这跟手机操作系统的逻辑类似，苹果闭源，安卓开源，第二名及以后的玩家，必须靠开源建立独特定位和生态，中国大模型比美国落后，开源能让客户建立技术信任，愿意深度合作。**

**第二，对我们来说，闭源的意义不大—真正的竞争对手都会有自己的模型，不会依赖我们的闭源产品；而普通用户本来也不是我们的竞争对手，开源反而能扩大生态。**

语言模型都开源了，视频和音频相关的还没有，后续会不会开源，核心看我们的战略目标。

开源和闭源只是手段，不是目的

## AI产品的Token消耗


**罗永浩**：很多人觉得AI产品的成本太高，Token消耗是个大问题。你之前提到，虽然Token成本在下降，但超轮对话会让需求暴涨，甚至需求增长超过成本下降速度，这会不会影响商业化？

**闫俊杰**：这确实是挑战，但也有解决路径，**以前AI的回答只服务于单个用户，Token消耗是单向的；现在AI能生成高质量内容，不管是有趣的视频还是深度研究报告，都值得被很多人观看。**

这样一来，虽然单条内容的Token成本变高了，但消费场景变多了，摊薄了单位成本，AI原生软件的未来，应该是用可控成本产出优质内容，让大家反复消费，而不是每个人都生成一次，这是我们正在探索的方向。

## 闫俊杰个人相关的


**罗永浩**：你之前跟媒体聊过，去年学会了取舍，之后就不再痛苦了。能说说舍掉了什么吗？怎么判断这些取舍，为什么舍的时候不痛苦？

**闫俊杰**：**核心就是想明白“不能啥都想要”。把一小部分事做好、做到最好，已经非常不容易了。我们不该纠结“所有事都要做到第一”，而是要基于当前能力，判断“什么事我们能做到最好、有机会实现，并且能持续积累”。**

想通这一点，至少会轻松很多，这虽然是阶段性策略，但和我们做AGI的终极目标不冲突—AGI要解决全人类的问题，但得一步一步来。

**罗永浩**：这么忙，有时间看论文吗？

**闫俊杰**：看论文跟看短视频一样，除了部分需要精读的，大部分论文花2分钟就可以。每天花1个小时看X上大家关注的，以及Arxiv上新的论文。

**罗永浩**：创业过程中最大的苦和乐是什么

**闫俊杰**：最大的乐是认识了很多优秀的人，能够跟他们一起合作一起共事。最大的苦是觉得自己认知不够，辜负了很多人。明明能够做的更好，但是由于自己太懒了，或者认知不够，没有做到。

