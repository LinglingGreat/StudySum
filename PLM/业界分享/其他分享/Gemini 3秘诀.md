---
title: Gemini 3秘诀
created: 2026-01-08
tags:
  - Google
---
[mp.weixin.qq.com/s/e4jEHVsyz8hcHHsStnS5WQ?click\_id=89](https://mp.weixin.qq.com/s/e4jEHVsyz8hcHHsStnS5WQ?click_id=89)

Oriol 是 Google DeepMind 研究与深度学习副总裁，也是 Gemini 联合负责人。他在 Gemini 3 发布时说，模型背后的秘密非常简单：更好的预训练和更好的后训练。

**Gemini 3 预训练负责人之一、开创性论文 RETRO 的合著者 Sebastian Borgeaud** 首次现身播客，深度拆解了这款顶级模型背后的实验室逻辑。在他看来，Gemini 3 的飞跃绝非单一环节的突破，而是无数细节持续优化的结果：“我们几乎每天都能找到让模型变更好的地方，整个团队都在加速前进。”

Sebastian Borgeaud 点出了一个核心转变：**谷歌已经不再是单纯“做模型”，而是转向“做系统”。** 这一观点恰好与 DeepMind 联合创始人兼 CEO 戴密斯·哈萨比斯不谋而合。哈萨比斯此前就公开表示，Gemini 3 的强大，根源在于“研究、工程和基础设施”的深度融合。

Gemini 3 的秘诀，其实侧面反映了当下行业的深刻变革：**AI 已经从“无限数据”的规模化时代，正式迈入“数据有限”的新阶段。** 这一趋势不可逆转，也倒逼整个行业重新思考创新方向。在 Sebastian Borgeaud 看来，合成数据、推理轨迹、长上下文、持续学习、端到端检索训练，再加上靠谱的评估体系，这些将共同构成 AI 行业未来的进化路径。

其实早在经典的 Chinchilla 项目中，DeepMind 团队就已经摸到了关键规律：**在训练计算量固定的前提下，与其盲目扩大模型规模，不如更快地扩展数据规模，这样能训练出更优的模型。** 这一结论放到现在依然极具现实意义，它直接决定了模型训练后的推理服务效率和使用成本，是企业落地 AI 的核心考量之一。

针对行业内 **“预训练 Scaling Law 已死”** 的争议，Sebastian Borgeaud 给出了明确回应：“规模依然重要，但架构创新和数据创新的权重已经显著提升，甚至变得更为关键。”

那么，在数据受限的大背景下，如何实现更好的模型效果？**合成数据** 成了行业追捧的热门方案，但 Sebastian Borgeaud 的态度却相当审慎：“这确实是个有意思的方向，但必须极度谨慎。”

在他看来，合成数据的核心风险不是“没效果”，而是“用错了还浑然不觉”。一旦数据分布发生偏移，模型看似答题能力提升，但可能会陷入“自嗨”的闭环里。为此，他给出了一套稳妥方案：用强模型生成合成数据后，必须通过小规模的可控消融实验，验证其带来的收益和潜在副作用。

但即便如此，一个核心疑问仍未解决：**“用合成数据训练出的模型，能否超越它的‘老师’？”**

值得一提的是，谷歌的模型训练一开始融合了多种来源的数据，这也为 Gemini 3 的多模态优势打下了基础。

Sebastian Borgeaud 还透露，DeepMind 正在推进 **“后 Transformer 架构”** 的创新，同时十分看好 **“原生态模型”**。尽管这种模型的研发成本高昂，但长期价值值得投入。此外，今年兴起的 **强化学习规模化趋势**，他们也有丰厚的预训练阶的经验可以复用，形成了技术协同效应。

## 下一轮预训练的热点

他认为，预训练不会再沿着“更大、更长、更贵”的单一路线走下去，重点会转向架构创新：

**长上下文和注意力机制是其中的关键变量**。如果上下文越长，模型推理时可携带的信息越多，模型能力边界也就越宽。

更长期的方向，是把检索与搜索更深地融入训练，做端到端、可微的学习，让模型把“会检索”变成内生能力，而不是上线后再外挂工具。他判断，强化学习的规模化可能推动这一进程，但要沉淀为稳定的架构与训练范式，不是一时之功，还需要数年。

另一条主线是 **持续学习**。Sebastian Borgeaud 直言，基础模型一旦预训练结束，知识就基本定格：明天出了新论文、新发现，模型不会自己更新。眼下行业更可行的办法主要发生在产品推理侧——接入检索，把最新信息实时拉进上下文，再基于这些材料完成推理，从而避免频繁重训底座、缓解知识过期。

这与他参与的 **RETRO 项目** 思路一致，将知识放在外部库，模型负责推理。他认为检索增强这套方法近年才走向成熟，未来几年有望更深地进入 Gemini 这类头部模型。更远的目标则是改变训练方式，让模型能在真实世界的数据流上持续训练，实现真正意义上的“持续更新”。

Sebastian Borgeaud 还单独拎出来 **评估** 这件事，将其视为预训练阶段的核心难题。“如果评估体系跟不上，很容易陷入‘看似提升’的假象内耗，根本分不清是模型改对了，还是数据出了问题。”也正因为如此，谷歌内部搭建了专属的评估体系。毕竟外部基准很容易被污染，保留内部的评估阵地才是关键。

他认为评估需要跨越两道鸿沟：一是在小模型上验证有效的改进，能否顺利迁移到大规模模型上；二是预训练阶段的优势，能否在后训练之后转化为真实可用的能力。

最后，**服务成本** 也是绕不开的现实约束。随着用户规模不断扩大，推理预算变得越来越敏感，预训练环节也必须为“上线落地”负责，在提升模型能力的同时，还要降低成本、节省资源。

对于 Gemini 3 目前的表现，**Sebastian Borgeaud 直言“超出预期”**。他认为，模型是真的越来越聪明了，这种进步不仅体现在基准测试的屠榜成绩上，更反映在真实工作场景的使用体验中。