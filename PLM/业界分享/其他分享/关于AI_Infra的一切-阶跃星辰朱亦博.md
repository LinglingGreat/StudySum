---
title: 关于AI_Infra的一切-阶跃星辰朱亦博
created: 2025-08-03
tags:
  - 播客
  - infra
---
[关于 AI Infra 的一切 | 对谈阶跃星辰联创朱亦博 - 42章经 | 小宇宙 - 听播客，上小宇宙](https://www.xiaoyuzhoufm.com/episode/688cc1cc8e06fe8de7d920cd)

> 从微软、字节 AI Infra 负责人到谷歌、再到阶跃联创，他的职业经历几乎和 AI Infra 的发展并行，如他所说，贾扬清、李沐等人可能是 AI Infra 的开路者，而他则是紧随其后的第二批从业者。
> 
> 在这期播客中，亦博不仅分享了 AI Infra 的底层认知，也讲了很多行业的内幕故事与实战细节。我们从最基础的 AI Infra 定义聊起，解答了其在模型表现中的作用、重要性，也揭示了“优化指标”的意义与评判标准，并讨论了行业现状和未来发展等等内容。
> 
> 听完这期，你可能会意识到：在大模型时代，AI Infra 不只是「降本」的后台支持，也是决定一家 AI 公司能走多远的核心战斗力。

## Infra的重要性

大模型时代想做最优秀的事情就要用最好的Infra。

算法比较依赖年轻的人，聪明劲（算法只有两年保质期？）；Infra比较强调积累，但是也需要年轻血液新想法。

	作为算法从业者也一直在思考这个问题，自己的核心竞争力在哪里？如何能不被更年轻的人替代？
	聪明确实是很重要的一个点，这意味着你比别人学的更快理解的更快，能够学的更多；在一个场景任务上，你能提出更好的解决方案。这其实也是我的前leader在招聘过程中强调的一点。
	另外就是工程能力，不过这点感觉很快会被AI取代，现在用AI写代码真是太方便了，不过有时候它的设计不怎么好，需要你设计一个好的方案，让它实现是可以的。所以工程上怎么设计也很重要。
	还有数据工程。算法中最核心的是数据、算法、Infra。Infra没做过，算法也很难去创新，直接开源的训练框架拿来一训练就行，这谁都会做。至于数据，如何构造、清洗得到高质量的数据确实是个很重要的点，经验积累在这里也是有作用的。
	还有什么？问了问DeepSeek，他给我的答案中我认可的是洞察算法本质的能力、复杂系统设计能力、技术判断力与折中艺术、垂直领域的深度认知与业务翻译能力以及软实力。人不是机器，人与人之间的不同还是很多的。

衡量Infra的好坏的方法？
- 推理侧：首token延迟，后续token延迟等
- 训练侧：比较像大数据的hadoop、spark处理数据，Infra则是GPU去处理很多数据

只有量很大的公司需要Infra？
- 其实都需要，取决于你愿不愿意投入去做出领先水平，做出领先水平对你的产品有多重要。Infra在每个公司都很挣钱（因为可以省钱），这是很确定性的。

Infra对模型效果有多大的影响？
- 比如目标是给定算力，怎么训练出最好的模型？Infra对此有很大的影响。效率提高，能够学习更多的数据。
- 不同的优化目标会走向不同的路径，比如DeepSeek的目标是给定推理成本，怎么设计训练出最好的模型？所以训练出来了R1，刚好选对了优化目标，火起来了。
- 认为现在首要的目标是decoding，输出的速度。现在还关注MMFU的话，是有问题的。

有关组织架构的心得体会
- Infra在大厂主要是一个支持性的角色，对模型没有太大的影响力。创业公司不同，大家会坐在一起讨论，可以影响模型效果。模型结构的设计其实可以由Infra的人设计，因为会影响到训练效率、推理效率等。

做Infra最大的阻碍是什么？
- 一类是能看到一条路，路上如何优化
- 一类是看不到清晰的路，只能走一步看一步。比如怎么真正做到模型和硬件的co-design，大家都是针对英伟达的卡去优化的。想象一种新的芯片和英伟达很不一样，有人利用这种芯片做出了高所有人一档的模型，这种事情非常革命性，但是非常困难。

国内外的Infra水平有差距。
- 一是规模，一万卡和十万卡遇到的问题是不一样的。
- 二是对上下游的影响，国外比如谷歌、OpenAI想自研芯片，有资金和人才，更容易做硬件和模型的co-design，国内比较少有公司有条件做。

要把Infra做好：
- 对Infra本身的知识要理解，也要对模型有理解，对硬件有理解。对这个有兴趣。
- 千万DAU的公司需要Infra，需要做GPU的优化。
- 未来的需求会越来越多，不做Infra的人也应该了解一下。
- DeepSeek做得好，就是因为Infra。

## 第三方公司的机会在哪里

面对云厂商和模型公司的挤压，第三方公司的突破口是？
- Infra是夹在硬件和模型之间，两边都会吃你的份额，都会越来越卷。现在是一个模型和硬件都在追求极致的时刻，**Infra可以更多地偏向某一侧，和某一侧去融合**，比如偏向模型侧的Infra，比硬件的人更懂模型，比模型的人更懂硬件，能够影响模型/硬件的走向。

第三方AI Infra的创业机会在哪里
- 主要还是做推理
- 很难做训练，因为训练是一个公司的核心竞争力，不会交给第三方。

## 业内真实的踩坑案例

最近一个不小的公司开源的一个模型很小（所以是哪个模型，很好奇），但是能达到较大模型的效果。实际运行不是这个效果，模型架构设计的问题导致在硬件上运行的效率很低，甚至比那个大的模型效率更低。体现出做算法的不了解Infra，只看参数量，但是参数量不等于推理效率，还要看模型结构设计等。

在一个公司如果MOE模型做的早，说明Infra团队影响力越大。在算法人员来看，MOE是一个降本的结构，不是提升效果的结构。比如DeepSeek，传言Infra人数比算法人数多，梁文锋也是Infra人才。

## 未来会如何发展

阶跃的新模型要发布
- 几百B，规模较大的视觉推理模型，比如拍照解题。不需要转成文字，直接输入图片，端到端推理。
- 走迷宫问题，很难解。试图解决这个问题。
- 给所有国产芯片免费商用授权使用模型，适配国产芯片，通过模型架构设计能够在国产芯片上降低推理成本，让国产芯片相比英伟达的卡是有竞争力的，反过来也能帮助自己推广模型。
- 之前说到一些开源模型还是基于英伟达的卡优化的，用国产芯片推理效率没有英伟达的卡高。

怎么看未来模型的发展？
- 模型范式的革新不会那么快，上一次是2022年的instruct-gpt，这一次是24年o1, deepseek-R1，如果2年一次的话下一次就是26年。
- 未来多模态的发展可以期待一下，现在的状态还是之前语言模型的bert的状态，未来类似gpt3.5那样，把理解和生成统一到一个模型，都能做到很好。

未来代码、Agent、多模态是分别做，还是合在一起？
- 现在代码是一个差异化，Anthropic的强化学习不怎么强，但是他投入了大量的人力去构造和清洗数据、打磨模型，就能把代码做的非常好。这样做也不一定对，因为也有可能一个新的训练范式出来就替代了大量人力的效果。
- Agent和模型共生又互相杀伤。Agent做的东西，模型肯定本身就有这样的能力，是去激发的，所以模型公司可以在下一代把它做到模型能力中；但是模型没有那么快做出来，是Agent找到场景，用工程方法让模型踮起脚尖做到这件事情。


《The Bitter Lesson》的含金量还在上升。
- 摩尔定律的持续，英伟达的算力还在上升。
- Infra的人要思考怎么换取摩尔定律的持续，怎么设计能够把硬件的计算发挥出来

过去70年人工智能研究领域最重要的一堂课是，**只有通用计算方法最终是最有效的，而且优势巨大。**根本原因是[摩尔定律](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B&zhida_source=entity)，更确切地说是，每个计算单元的成本持续呈指数下降。大多数人工智能研究都是假设 Agent 可用的计算量是恒定的（在这种情况下，利用人类知识将是提高性能的唯一方法之一），但是，从较长的时间看，不可避免地会产生大量的计算量。为了在短期内获得有所作为的改善，研究人员试图利用该领域内的人类知识。**但长远来看，唯一重要的是利用算力**。这两者不必相互对立，但在实践中它们往往会相互对立。时间投入到一种方法上，就没办法投入到另一种方法上，这是对投入一种或另一种方法的心理承诺。而人类知识往往很复杂，不太适合利用好通用算力。有很多的例子表明人工智能研究人员迟迟未能学习这个苦涩的教训，回顾一些最突出的例子很有启发性。

在电脑国际象棋中，1997年击败世界冠军[卡斯帕罗夫](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BD%97%E5%A4%AB&zhida_source=entity)的方法基于大规模的[深度搜索](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=%E6%B7%B1%E5%BA%A6%E6%90%9C%E7%B4%A2&zhida_source=entity)。当时，大多数计算机国际象棋研究人员对此感到沮丧，他们一直致力于利用人类对国际象棋特殊结构的理解的方法，当一种**更简单的、基于搜索的、结合特殊的硬件和软件**的方法，被证明更有效时，这些基于人类知识的国际象棋研究人员没有虚心接受失败，他们反驳道，“蛮力”搜索可能这次赢了，但这不是一种通用的策略，而且也不是人们玩国际象棋的方式。这些研究人员希望基于人类的行棋思路能够获胜，当没有获胜时他们感到失望。

在电脑围棋中，也出现了类似的研究进展，只是比国际象棋晚了20年。最初的巨大努力是想办法利用人类知识（一千年的棋谱），或围棋游戏的特殊特征，避免用蛮力搜索，但是所有这些努力都被证明是无关紧要的。更糟糕的是，一旦有效地进行了大规模搜索，以及，使用自我对局来学习价值函数（就像在许多其他游戏中一样，在国际象棋中也是如此，尽管这种学习在1997年首次击败世界冠军的项目中并没有发挥重要作用），之前的努力都是负向的。**通过 自我对局 以及 通用学习 来学习，就像搜索一样，因为它能够进行大规模的计算。**在电脑围棋、电脑国际象棋中，研究人员最初的努力是利用人类的理解（更少的搜索），直到很久以后，**通过拥抱搜索和学习，才取得更大的成功**。

在**语音识别**方面，在1970年代，由[DARPA](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=DARPA&zhida_source=entity)（美国国防部高级研究计划局）赞助了一项早期的竞赛。参赛者包括许多利用人类知识的特殊方法——单词、音素、人类声道等等知识。另一方面是更具统计学意义的方法，基于[隐马尔可夫模型](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B&zhida_source=entity)（HMMs）进行了更多的计算。**再次，统计学方法战胜了基于人类知识的方法。**这导致了几十年来所有自然语言处理的重大变化，统计学和计算逐渐开始主导该领域。最近深度学习在语音识别领域的兴起是朝着这一方向迈出的最新一步。深度学习方法对人类知识的依赖程度更低，使用更多的计算，加上在巨大的训练集上的学习，以产生更好的语音识别系统。正如游戏中一样，研究人员总是试图让系统按照他们自己的大脑工作的方式工作 —— 他们试图将这些知识放入他们的系统中 —— 但事实证明，当大规模计算变得可用并找到了一种充分利用摩尔定律的方法时，这最终会适得其反，并且浪费了研究人员的时间。

在计算机视觉领域，也存在类似的模式。早期的方法把视觉想象成寻找边缘，或广义柱，或以[SIFT特征](https://zhida.zhihu.com/search?content_id=245581586&content_type=Article&match_order=1&q=SIFT%E7%89%B9%E5%BE%81&zhida_source=entity)的形式。但今天，这一切都被抛弃了。现代深度学习神经网络仅使用卷积和某些不变性的概念，并且表现得更好。

这是一个重要的教训。纵观整个人工智能领域，我们仍然没有彻底地吸取它，因为我们继续犯同样的错误。为了看到这一点，并有效地抵制它，我们必须理解这些错误的吸引力。我们必须吸取苦涩的教训，即把我们认为的思维方式构建到系统中是行不通的。

苦涩的教训是基于历史观察：

1）人工智能研究人员经常试图将知识构建到他们的 Agent 中；

2）这在短期内总是有帮助的，并且对研究人员来说是个人满意的；

3）但从长远来看，它总会达到一个瓶颈，甚至会阻碍进一步的进展；

4）突破性的进展最终是通过一种相反的方法实现的，这种方法基于**通过搜索和学习来扩展大规模计算。**

最终的成功中夹杂着一丝苦涩和消化不全，因为它比受青睐的、以人为本的方法更成功。

从苦涩的教训中学到的一件事是**通用方法的巨大力量，**即随着可用算力变得非常大，这些方法会随着计算量的增加可以继续扩展。可以以这种方式近乎无限扩展的两种方法是**搜索和学习**。

从苦涩的教训中学到的第二个普遍观点是，人类心灵的实际内容是极其复杂的，我们不应该再试图找到简单的方法来思考心灵的内容，比如简单地思考空间、物体、多重主体或对称性。所有这些都是任意的、内在复杂的外部世界的一部分。它们不应该被构建，因为它们的复杂性是无止境的；**相反，我们应该只构建可以找到和捕获这种任意复杂性的元方法。**这些方法的关键是它们可以找到很好的近似值，但算法应该是基于我们的方法，而不是我们已经学到的知识。我们**希望人工智能 Agent 能够像我们人类一样去发现**，而不是在系统里集成我们已经发现的东西。建立在我们已知发现之上只会让我们更难看到如何完成发现过程。

