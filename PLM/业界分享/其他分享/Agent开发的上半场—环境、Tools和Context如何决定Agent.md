---
title: Agent开发的上半场—环境、Tools和Context如何决定Agent
created: 2025-08-03
tags:
  - 播客
  - agent
---
[Agent 开发的上半场: 环境、Tools 和 Context 如何决定 Agent｜对谈 Sheet0 创始人王文锋 - 42章经 | 小宇宙 - 听播客，上小宇宙](https://www.xiaoyuzhoufm.com/episode/68032a401f1db84a563d5d83)


Agent被定义为一个“基于环境反馈进行决策和行动的程序”。它的基本组成包括三个核心要素：第一是模型（Model），它是Agent运行的基础逻辑系统；第二是环境反馈（Feedback），即外部信息的变化对其行为的影响；第三是工具使用（Tool Use），Agent通过工具与外界交互以完成目标。这三个维度共同构成Agent运行的核心机制。
Context是agent做出高质量决策的前提。它不仅包括用户输入、历史对话记录，还包括模型访问过的网页、读取的代码、点击记录等一切状态信息。用户在打开某个App的瞬间（如打开美团即暗示“点外卖”意图）就隐含了大量context，Agent需要能敏锐捕捉这些信号。真正高质量的数据不仅包括输入与结果，还包括“从输入到结果之间”的中间过程。例如点击流、交互记录、实时环境数据等。Google拥有完整的用户行为序列数据，这正是其在AI Native时代最具竞争力的优势。Context是Agent内部对“当前环境”的建模基础。Agent依赖上下文来理解用户意图、保持状态一致性并形成连续性的行动链。

Agent的底层逻辑源自强化学习，其三要素为：状态（State）、行动（Action）、激励信号（Reward）。其中：状态即Context，描述Agent所处的环境信息；行动即工具调用；激励信号则是Agent用于评估行为好坏的标准。要真正设计好Agent，必须构造出“一个可以反馈的环境”，让Agent的行为有明确收敛目标。创业公司设计Agent时，关键在于：（1）将产品本身设计成“环境”，让模型理解输入、输出与行为反馈；（2）明确界定“好行为”与“坏行为”，定义奖励机制；（3）允许用户参与Agent的行为澄清与反馈过程，提高可解释性与交互灵活度。Agent面临双重信任挑战： 1）开发者需信任大模型的泛化能力，否则容易人为“封闭”模型能力，降低Agent的智能利用率； 2）用户需信任Agent的行为过程与结果，这就要求系统设计中加入可解释性机制、逐步反馈系统。
Agent系统构建的两个核心变量：（1）Context的构建：工程实现上复杂度高，常需半年以上的积累；（2）LLM性能：未来以GPT-5为代表的大模型能力提升，以及推理成本（token消耗）的下降，将显著影响Agent可用性与普及速度。要构建可持续演进的Agent，必须明确什么样的行为是“好”的（应被鼓励），什么是“差”的（应被纠正）。这类激励机制不应仅依赖模型本身，而需产品系统提供明确的行为评估信号，从而引导Agent优化自身决策。