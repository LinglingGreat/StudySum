---
title: DPO
created: 2024-06-15
tags:
  - alignment
type: è®ºæ–‡
papername: 
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 
institution:
---

## è®ºæ–‡åŸºæœ¬ä¿¡æ¯

æ ‡é¢˜ï¼š

ä½œè€…ï¼š

é“¾æ¥ï¼š

ä»£ç ï¼š

æ¡†æ¶å›¾ï¼š


## æŸå¤±å‡½æ•°
å¯¹äºåŒä¸€ä¸ª propmtï¼Œç»™å®šä¸€ä¸ªå¥½çš„å›ç­”Â ğ‘¦ğ‘¤Â å’Œä¸€ä¸ªä¸å¥½çš„å›ç­”Â ğ‘¦ğ‘™ï¼Œ**é€šè¿‡é™ä½ä¸å¥½å›ç­”è¢«é‡‡æ ·çš„æ¦‚ç‡ï¼Œæå‡å¥½å›ç­”çš„æ¦‚ç‡**ï¼Œä»è€Œè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¿™ä¸ªæ•°æ®å’Œè®­ç»ƒ Reward Model çš„ pair æ•°æ®æ ¼å¼å®Œå…¨ä¸€è‡´ï¼Œéƒ½æ˜¯åŒä¸€ä¸ª prompt å¯¹åº”ä¸¤ä¸ªä¸åŒè´¨é‡çš„ responsesã€‚

![](img/Pasted%20image%2020240615170451.png)

[æºç ](https://link.zhihu.com/?target=https%3A//github.com/huggingface/trl/blob/main/trl/trainer/dpo_trainer.py) ä¸­è®¡ç®— loss çš„éƒ¨åˆ†ï¼ˆæœ€ç®€å•çš„sigmoidæŸå¤±å‡½æ•°ï¼‰ï¼š

```python
def dpo_loss(
        self,
        policy_chosen_logps,
        policy_rejected_logps,
        reference_chosen_logps,
        reference_rejected_logps,
    ):
        """Compute the DPO loss for a batch of policy and reference model log probabilities.

        Args:
            policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)
            policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)
            reference_chosen_logps: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)
            reference_rejected_logps: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)
        """
        pi_logratios = policy_chosen_logps - policy_rejected_logps
        ref_logratios = reference_chosen_logps - reference_rejected_logps

        pi_logratios = pi_logratios.to(self.accelerator.device)
        ref_logratios = ref_logratios.to(self.accelerator.device)
        logits = pi_logratios - ref_logratios

        losses = -F.logsigmoid(self.beta * logits)
        return losses
```

rewardsçš„è®¡ç®—æ–¹æ³•ã€‚æ‰€ä»¥DPOçš„lossä¹Ÿå¯ä»¥ç†è§£ä¸ºï¼š

`L_DPOâ€‹=âˆ’log(sigmoid(chosen_rewardsâˆ’rejected_rewards))`

```python
chosen_rewards = self.beta * (policy_chosen_logps - reference_chosen_logps).detach()
        rejected_rewards = self.beta * (policy_rejected_logps - reference_rejected_logps).detach()
```

è®¡ç®—logpsçš„å‡½æ•°

```python
def get_batch_logps(
        self, 
        logits: torch.FloatTensor,
        labels: torch.LongTensor,
        average_log_prob: bool = False,
        label_pad_token_id: int = -100,
        is_encoder_decoder: bool = False,
    ) -> torch.FloatTensor:
        """Compute the log probabilities of the given labels under the given logits.

        Args:
            logits: Logits of the model (unnormalized). Shape: (batch_size, sequence_length, vocab_size)
            labels: Labels for which to compute the log probabilities. Label tokens with a value of label_pad_token_id are ignored. Shape: (batch_size, sequence_length)
            average_log_prob: If True, return the average log probability per (non-masked) token. Otherwise, return the sum of the log probabilities of the (non-masked) tokens.

        Returns:
            A tensor of shape (batch_size,) containing the average/sum log probabilities of the given labels under the given logits.
        """

        if logits.shape[:-1] != labels.shape:
            logger.info(f"logits shape: {logits.shape}; label shape: {labels.shape}")
            raise ValueError("Logits (batch and sequence length dim) and labels must have the same shape.")

        if not is_encoder_decoder:
            labels = labels[:, 1:].clone()
            logits = logits[:, :-1, :]
        loss_mask = labels != label_pad_token_id

        # dummy token; we'll ignore the losses on these tokens later
        labels[labels == label_pad_token_id] = 0

        per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)

        if average_log_prob:
            return (per_token_logps * loss_mask).sum(-1) / loss_mask.sum(-1)
        else:
            return (per_token_logps * loss_mask).sum(-1)
```

### chosen_logitså’Œchosen_logpsçš„å…³ç³»

1.Â **`chosen_logits`**

- **å®šä¹‰**:
    - `chosen_logits`Â æ˜¯æ¨¡å‹å¯¹Â **chosen responses**Â çš„åŸå§‹è¾“å‡ºï¼ˆæœªå½’ä¸€åŒ–çš„ logitsï¼‰ã€‚
    - å½¢çŠ¶ä¸ºÂ `(batch_size, sequence_length, vocab_size)`ï¼Œå…¶ä¸­Â `vocab_size`Â æ˜¯è¯æ±‡è¡¨çš„å¤§å°ã€‚
- **å«ä¹‰**:
    - è¡¨ç¤ºæ¨¡å‹å¯¹æ¯ä¸ª token çš„é¢„æµ‹åˆ†æ•°ï¼ˆlogitsï¼‰ï¼Œå³æœªç»è¿‡ softmax å½’ä¸€åŒ–çš„åŸå§‹åˆ†æ•°ã€‚
    - è¿™äº› logits å¯ä»¥ç”¨äºè¿›ä¸€æ­¥è®¡ç®—æ¦‚ç‡åˆ†å¸ƒæˆ–æŸå¤±å‡½æ•°ã€‚
- **ç”¨é€”**:
    - é€šå¸¸ç”¨äºè®¡ç®—æ¨¡å‹çš„é¢„æµ‹åˆ†å¸ƒæˆ–ä¸å…¶ä»–æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œæ¯”è¾ƒã€‚
        

---

2.Â **`chosen_logps`**

- **å®šä¹‰**:
    - `chosen_logps`Â æ˜¯æ¨¡å‹å¯¹Â **chosen responses**Â çš„å¯¹æ•°æ¦‚ç‡ï¼ˆlog probabilitiesï¼‰ã€‚
    - å½¢çŠ¶ä¸ºÂ `(batch_size, sequence_length)`ï¼Œè¡¨ç¤ºæ¯ä¸ª token çš„å¯¹æ•°æ¦‚ç‡ã€‚
- **å«ä¹‰**:
    - è¡¨ç¤ºæ¨¡å‹å¯¹Â **chosen responses**Â ä¸­æ¯ä¸ª token çš„é¢„æµ‹æ¦‚ç‡çš„å¯¹æ•°å€¼ã€‚
    - è¿™äº›å€¼æ˜¯é€šè¿‡å¯¹Â `chosen_logits`Â è®¡ç®— log-softmax å¾—åˆ°çš„ã€‚
- **ç”¨é€”**:
    - é€šå¸¸ç”¨äºè®¡ç®—æŸå¤±å‡½æ•°ï¼ˆå¦‚è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼‰æˆ–è¯„ä¼°æ¨¡å‹çš„é¢„æµ‹è´¨é‡ã€‚


## DPO æ˜¯å¦‚ä½•ç®€åŒ– RLHF çš„

![](img/Pasted%20image%2020250126174234.png)

![](img/Pasted%20image%2020250126174250.png)

![](img/Pasted%20image%2020250126174303.png)

**DPOç®—æ³•çš„ç›®çš„æ˜¯æœ€å¤§åŒ–å¥–åŠ±æ¨¡å‹(æ­¤å¤„çš„å¥–åŠ±æ¨¡å‹å³ä¸ºè®­ç»ƒçš„ç­–ç•¥)ï¼Œä½¿å¾—å¥–åŠ±æ¨¡å‹å¯¹chosenå’Œrejectedæ•°æ®çš„å·®å€¼æœ€å¤§ï¼Œè¿›è€Œå­¦åˆ°äººç±»åå¥½ã€‚**

dpo ä»å¤´åˆ°å°¾éƒ½åœ¨ä»¥ reward_model çš„æ–¹å¼è®©æ¨¡å‹å­¦ä¹  evaluate èƒ½åŠ›ï¼Œä½†æ˜¯å´å¹¶æ²¡æœ‰è¯æ˜ä¸€ä¸ªé‡è¦å‡è®¾ï¼šâ€œ**æ¨¡å‹çš„ evaluate èƒ½åŠ›å’Œ generate èƒ½åŠ›åˆ°åº•æ˜¯ä¸æ˜¯ç›¸äº’ä¿ƒè¿›çš„ï¼Ÿ**â€ dpo åçš„æ¨¡å‹å…·æœ‰äº†æ›´å¼ºçš„ evaluate èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æå‡æ¨¡å‹çš„ generate èƒ½åŠ›å•Šã€‚å¦‚æœè¿™ä¸ªåŸºæœ¬å‡è®¾ä¸æˆç«‹ï¼Œé‚£ dpo çš„å­¦ä¹ è¿‡ç¨‹å°±æ²¡æœ‰ä»€ä¹ˆä»·å€¼ã€‚

ä¹Ÿæ­£æ˜¯å› ä¸º dpo æ˜¯åœ¨è®©æ¨¡å‹å…·æœ‰ reward_model çš„èƒ½åŠ›ï¼Œæ‰€ä»¥å®ƒå¹¶ä¸åœ¨ä¹æ¨¡å‹èƒ½ä¸èƒ½è¯´å‡ºä¸€ä¸ªå¥½çš„å¥å­ï¼Œåªåœ¨ä¹ loss margin æ˜¯å¦åœ¨å˜å¤§ã€‚å¤§å®¶è®­ç»ƒ dpo çš„æ—¶å€™ï¼ŒåŸºæœ¬éƒ½é‡åˆ°è¿‡ good_sentence å’Œ bad_sentence çš„ loss éƒ½ä¸Šå‡çš„å°´å°¬ç°è±¡ï¼Œå¾€å¾€éœ€è¦æˆ‘ä»¬åŠ ç³»æ•°å’Œè°ƒå‚æ•°æ‰èƒ½è§£å†³ã€‚

reward_model çš„è®­ç»ƒæ–¹å¼æ ¹æœ¬ä¸åœ¨ä¹æ¨¡å‹çš„ generate èƒ½åŠ›ï¼Œå› æ­¤ç¨³å®šè®­ç»ƒçš„ dpo éœ€è¦é­”æ”¹ loss å‡½æ•°ã€‚




Reference modelèµ·åˆ°çš„ç¬¬ä¸€ä¸ªä½œç”¨å°±æ˜¯**åœ¨KLæ•£åº¦ä¸­é™åˆ¶Policy Modelï¼Œè®©å®ƒä¸è¦åç¦»Reference Modelå¤ªè¿œ**ã€‚

![å›¾ç‰‡](https://mmbiz.qpic.cn/mmbiz_png/wAPfqDgY33pwmtfcFiajggichSFEpkmiapJSC3UIlJf1dc2JRRXctjgbDnAS0fibacvrVmz4lr4woaJrUnYOURxxBA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

å…¬å¼å·¦è¾¹æ˜¯DPOå¯¹äºç¬¬tä¸ªtokençš„æŸå¤±å‡½æ•°ï¼Œå³è¾¹å°±æ˜¯ä¸€ä¸ªéå¸¸æ ‡å‡†çš„Advantageå‡½æ•°å®šä¹‰ï¼ˆè¯¦è§Actor Critic)ã€‚è¿™ä¸ªç»“è®ºå°±éå¸¸åœ°å¼ºï¼Œæ„æ€å°±æ˜¯è¯´ï¼Œæˆ‘è™½ç„¶æ²¡æœ‰Value Modelï¼Œå¹¶ä¸”è®­ç»ƒè¿˜æ˜¯æ ·æœ¬çº§åˆ«çš„pair-wiseæ•°æ®ï¼Œä½†æ˜¯æˆ‘è¯æ˜äº†åŠ ä¸ŠReference Modelä¹‹åï¼Œç›¸å½“äºå¼•å…¥äº†ä¸€ä¸ª**ç»†ç²’åº¦çš„Value Model**å’Œä¸€ä¸ª**ç»†ç²’åº¦çš„Reward Model**ï¼Œç­‰ä»·äºPPOä¸­Advantageçš„è®¡ç®—ã€‚

## DPOè®­ç»ƒæ—¶ï¼Œä¸ºä»€ä¹ˆchosenå’Œrejectedçš„rewardä¸€èµ·ä¸‹é™

[ç™¾é¢LLM-7](https://zhuanlan.zhihu.com/p/686122806)

[ã€ä¸é è°±ã€‘æœ‰å…³DPOè®­ç»ƒæ—¶ï¼Œä¸ºä»€ä¹ˆchosenå’Œrejectedçš„rewardä¸€èµ·ä¸‹é™çš„çŒœæƒ³](https://zhuanlan.zhihu.com/p/694381064)

[DPOæ­£ä¾‹æ¦‚ç‡ä¸åº”è¯¥ä¸‹é™ï¼ŸDPOåœ¨å®è·µä¸­çš„åæ€ä¸æ”¹è¿›](https://zhuanlan.zhihu.com/p/698852522)

åœ¨ä»¥ä¸‹æƒ…å†µä¸­æ­£ä¾‹çš„æ¦‚ç‡å°±å¯èƒ½ä¸‹é™ï¼š

1. å¦‚æœæ­£ä¾‹å¹¶ä¸æ˜¯ä¸€ä¸ªç»å¯¹æ„ä¹‰ä¸Šå¥½çš„å›å¤è€Œä»…ä»…æ˜¯ç›¸å¯¹äºè´Ÿä¾‹è€Œè¨€æ›´å¥½ï¼Œæ­£ä¾‹çš„æ¦‚ç‡é™ä½æ‰æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸º**å½“å‰æ ·æœ¬çš„æ­£ä¾‹å¯èƒ½ä¹Ÿæ˜¯å…¶ä»–æ ·æœ¬ä¸­çš„è´Ÿä¾‹ï¼ˆå¦‚æœæ­£ä¾‹çš„æŸä¸ªæ¨¡å¼å‡ºç°åœ¨å…¶ä»–æ ·æœ¬çš„è´Ÿä¾‹ä¸­ä¹Ÿä¼šå¯¼è‡´è¯¥æ­£ä¾‹çš„æ¦‚ç‡ä¸‹é™ï¼‰**ã€‚
2. å³ä½¿æ•°æ®ä¸­çš„æ­£ä¾‹å¯ä»¥çœ‹ä½œæ˜¯ç»å¯¹æ„ä¹‰ä¸Šçš„å¥½çš„å›å¤ï¼Œ**ä½†å¦‚æœqueryå­˜åœ¨å¤šä¸ªç»å¯¹æ„ä¹‰ä¸Šå¥½çš„å›å¤ï¼Œè¯¥æ­£ä¾‹çš„æ¦‚ç‡ä¹Ÿå¯èƒ½å› ä¸ºå…¶ä»–å¥½å›å¤æ¦‚ç‡çš„ä¸Šå‡è€Œä¸‹é™**ï¼ˆå‚è€ƒç« èŠ‚ä¸‰æ€è€ƒ2ä¸­æåˆ°çš„åœºæ™¯ï¼‰ã€‚

æ­¤å¤–ï¼Œæ–‡æ— ç¬¬ä¸€ï¼Œ**å¯¹äºå¾ˆå¤šä»»åŠ¡è€Œè¨€ä¸å­˜åœ¨ç»å¯¹çš„æ­£ç¡®æ€§ï¼Œä¸åŒæ¨¡å‹çš„åå¥½å¯èƒ½ä¸åŒï¼Œå³ä½¿æŸä¸ªæ­£ä¾‹åœ¨æŸä¸ªè¯„ä¼°æ ‡å‡†ä¸‹æ²¡æœ‰æ­£ç¡®æ€§é—®é¢˜ï¼Œé€»è¾‘ä¹Ÿå¾ˆå¥½ï¼Œå®ƒçš„æ¦‚ç‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»ç„¶å¯èƒ½ä¼šè¢«é™ä½ï¼Œå› ä¸ºæ¨¡å‹å—åˆ°å…¶ä»–æ•°æ®çš„æ¿€å‘å¯èƒ½è®¤ä¸ºå…¶ä»–å½¢å¼çš„è¾“å‡ºæ›´å¥½ï¼ˆæ¯”å¦‚æŠŠè§£é‡Šæ”¾åœ¨åé¢è€Œä¸æ˜¯æ”¾åœ¨å‰é¢ï¼‰ï¼Œæå‡äº†å…¶ä»–å½¢å¼è¾“å‡ºçš„æ¦‚ç‡ï¼Œè¿›è€Œå¯¼è‡´è¯¥æ­£ä¾‹æ¦‚ç‡çš„ä¸‹é™**ã€‚æˆ‘ä»¬åœ¨å®éªŒä¸­è§‚å¯Ÿåˆ°ï¼Œæ­£ä¾‹æ¦‚ç‡çš„ä¸‹é™å¾ˆå¤šæ—¶å€™ä¸æ˜¯æ ¸å¿ƒç­”æ¡ˆæ¦‚ç‡ä¸‹é™å¯¼è‡´çš„ï¼Œè€Œæ˜¯æ¨¡å‹å€¾å‘çš„å›å¤è¯æœ¯æ”¹å˜äº†ï¼Œæ ‡æ³¨æ­£ä¾‹çš„å›å¤è¯æœ¯å’Œæ¨¡å‹å€¾å‘ä¸ä¸€è‡´å¯¼è‡´çš„æ¦‚ç‡ä¸‹é™ã€‚å¦‚æ ‡æ³¨æ­£ä¾‹æ˜¯ä»¥ã€è¿™å¥è¯ã€‚ã€‚ã€‚ã€å¼€å¤´ï¼Œè€Œé‡‡ç”¨greedy searchç­–ç•¥ï¼Œæ¨¡å‹å€¾å‘äºä»¥ã€æ ¹æ®æ–‡æœ¬å†…å®¹ã€‚ã€‚ã€‚ã€å¼€å¤´ï¼Œä¸”è¯¥è¯æœ¯åœ¨DPOä¸­ç›¸è¾ƒäº[SFT](https://zhida.zhihu.com/search?content_id=243430776&content_type=Article&match_order=1&q=SFT&zhida_source=entity)çš„æ¦‚ç‡æ˜¯æå‡çš„ï¼Œæ­¤æ—¶æ ‡æ³¨æ­£ä¾‹å¼€å¤´tokensçš„æ¦‚ç‡å¾ˆå¤šæ—¶å€™å°±ä¸‹é™äº†ï¼Œè€Œè¿™äº›tokenså¹¶ä¸ä¼šå½±å“æ ¸å¿ƒç­”æ¡ˆçš„æ­£ç¡®æ€§ã€‚


## ä¸»è¦æ”¶è·


## å‚è€ƒèµ„æ–™

[DPO æ˜¯å¦‚ä½•ç®€åŒ– RLHF çš„](https://zhuanlan.zhihu.com/p/671780768)

[dpo çš„å±€é™æ€§](https://zhuanlan.zhihu.com/p/1082394115)

[ç†è§£DPOçš„Reference Model](https://mp.weixin.qq.com/s/60jnAfy6AXA-mjwbB92JtQ)

