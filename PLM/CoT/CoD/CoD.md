---
title: CoD
created: 2025-03-05
tags:
  - cot
type: 论文
papername: 
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2025
institution:
  - zoom
---

## 论文基本信息

标题：Chain of Draft: Thinking Faster by Writing Less

作者：

链接：

代码：https://github.com/ sileix/chain-of-draft

框架图：


## 背景

这篇论文试图解决大型语言模型（LLMs）在解决复杂推理任务时面临的效率问题。具体来说，它关注于如何在保持高准确率的同时，减少模型推理过程中的计算成本和延迟。传统的链式思考（Chain of Thought, CoT）方法虽然能够有效提升模型在复杂任务上的表现，但其冗长的推理步骤导致了较高的计算资源消耗和响应延迟。相比之下，人类在解决类似问题时通常会采用更高效的方式，即通过简洁的草稿或笔记来捕捉关键信息，而不是详细阐述每一个步骤。

为了解决这一问题，论文提出了一个新的方法——链式草稿（Chain of Draft, CoD）。该方法受到人类认知过程的启发，鼓励LLMs在解决问题时生成简洁且信息密集的中间推理输出，从而在减少冗余的同时，保持推理的准确性和透明度。

![](img/Pasted%20image%2020250305190311.png)

## 相关研究

### 结构化推理框架

- **o1**：OpenAI开发的推理模型，展示了在复杂任务上的显著改进。
    
- **QwQ**：阿里巴巴开发的推理模型，提升了模型的推理能力。
    
- **R1**：DeepSeek开发的推理模型，增强了模型在复杂任务上的表现。
    
- **链式思考（CoT）**：由Wei等人提出，是LLMs推理的基础方法，通过分步探索问题来模拟人类的结构化推理过程。
    
- **树形和图形推理拓扑**：如Yao等人和Chen等人提出的树形结构，以及Besta等人和Lei等人提出的图结构，使LLMs能够处理更复杂的问题。
    
- **自一致性CoT**：Wang等人提出，通过引入验证和反思机制来增强推理的可靠性。
    
- **ReAct**：Yao等人提出，将工具使用整合到推理过程中，使LLMs能够访问外部资源和知识。
    

### LLM推理延迟降低

- **流式输出**：通过逐步提供部分输出来减少感知延迟，但无法完全减少整体延迟或计算成本。
    
- **Skeleton-of-Thought（SoT）**：Ning等人提出，先引导LLMs生成答案的大纲，然后通过并行解码来减少延迟。
    
- **Draft & Verify**：Zhang等人提出，先快速生成低质量的草稿，然后通过单次前向传递进行验证。
    
- **Coconut**：Hao等人提出，训练LLMs在连续的潜在空间中进行推理，而不是在传统的自然语言空间中，从而减少延迟和计算成本，但牺牲了复杂任务的准确性和自然语言推理的可解释性。
    
- **Concise Thoughts（CCoT）**：Nayab等人提出，为推理步骤设定固定的全局token预算，但这种方法可能不适用于不同任务，且模型可能无法严格遵守预算。
    
- **Token-budget-aware LLM reasoning（TALE）**：Han等人提出，根据推理复杂性动态估计全局token预算，但这种方法需要额外的LLM调用来估计预算，增加了延迟，并且假设模型能够准确预测请求的复杂性。
    

### 其他相关工作

- **BIG-bench**：一个用于评估语言模型能力的基准测试，提供了多种任务来评估模型的推理能力。
    
- **GSM8k**：一个用于评估语言模型算术推理能力的基准测试，包含8500个多样化的数学问题。
    
- **Coin Flip Tasks**：由CoT论文引入的任务，用于评估LLMs在符号推理方面的能力。


## 核心亮点

- **核心思想**：CoD受到人类解决问题时通常采用的简洁草稿或笔记的启发，鼓励LLMs在推理过程中生成简洁且信息密集的中间输出，而不是像传统的链式思考（CoT）那样详细阐述每一个步骤。
    
- **具体实现**：在CoD中，模型被要求在每一步推理中仅保留关键信息，限制每个推理步骤的单词数量（例如，最多5个单词），从而减少冗余和不必要的细节。



## 实验

- **任务类别**：选择了三种需要多步推理的任务类别进行评估：
    
    - **算术推理**：使用GSM8k数据集。包含8500个多样化的数学问题。
        
    - **常识推理**：使用BIG-bench中的日期理解和体育理解任务。
        
    - **符号推理**：合成一个包含250个样本的硬币翻转任务。预测一系列硬币翻转动作后硬币的正反面。
        
- **模型选择**：使用了两个流行的旗舰模型进行评估：
    
    - **GPT-4o**：来自OpenAI的模型。
        
    - **Claude 3.5 Sonnet**：来自Anthropic的模型。
        
- **提示策略对比**：对比了三种不同的提示策略：
    
    - **标准提示（Standard）**：直接回答问题，不提供任何推理或解释。
        
    - **链式思考（Chain of Thought, CoT）**：提供详细的推理过程。
        
    - **链式草稿（Chain of Draft, CoD）**：提供简洁的推理草稿，每步最多5个单词。

![](img/Pasted%20image%2020250305190450.png)

例子：

![](img/Pasted%20image%2020250305190339.png)

![](img/Pasted%20image%2020250305190329.png)


![](img/Pasted%20image%2020250305190354.png)





实验结果：

![](img/Pasted%20image%2020250305190427.png)

![](img/Pasted%20image%2020250305190510.png)

![](img/Pasted%20image%2020250305190519.png)

![](img/Pasted%20image%2020250305190540.png)




## 未来方向

1. ​**缺乏少样本示例时的不一致性**：在零样本设置下，CoD的效果显著下降，特别是Claude 3.5 Sonnet的准确率仅提高了3.6%。这表明CoD风格的推理模式在大型语言模型的训练数据中较为稀缺。
2. ​**在小模型上的性能下降**：在参数少于3B的小型语言模型上，CoD的性能与CoT相比差距更大。这可能是由于这些模型的训练过程中缺乏CoD风格的数据。未来可以通过使用额外的CoD格式数据进行微调来显著提升其推理准确性。
3. ​**未来工作方向**：可以探索将CoD与其他降延迟方法（如自适应并行推理或多遍验证）结合，以进一步优化不同应用领域的性能。此外，研究CoD紧凑推理背后的原理，可能会激发新的策略，通过训练紧凑推理数据来改进推理模型，同时保持解释性和效率。

![](img/Pasted%20image%2020250305190555.png)



![](img/Pasted%20image%2020250305190612.png)

## 主要收获


## 参考资料
