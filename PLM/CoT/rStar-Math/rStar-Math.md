---
title: rStar-Math
created: 2025-02-04
tags:
  - o1-related
type: 论文
papername: 
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2025
institution:
  - 微软
---

## 论文基本信息

标题：rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking

作者：

链接：http://arxiv.org/abs/2501.04519

代码：https://github.com/microsoft/rStar

框架图：

![](img/Pasted%20image%2020250204120051.png)


## 背景

这篇论文介绍了一个名为 rStar-Math 的方法，旨在解决以下问题：

1. **小型语言模型（SLMs）在数学推理能力上的局限**：论文指出，尽管大型语言模型（LLMs）已被证明能够处理数学问题，但是传统的让LLMs在单次推理中生成完整解答的方法（类似于系统1思考）往往快速但不准确。为了克服这一局限，论文提出了一种测试时计算扩展的范式转变，即通过更慢、更深入的思考过程来模拟人类的推理（类似于系统2思考）。
    
2. **高质量数学推理数据的稀缺性**：论文提到，现有的高质量数学推理数据非常稀缺，且合成高质量数学数据面临根本性挑战。对于策略模型来说，很难区分错误的推理步骤和正确的步骤，使得低质量数据难以排除；对于奖励模型，过程奖励建模（PRM）显示出巨大潜力，但由于训练数据更加稀缺，准确的步骤级反馈需要大量的人工标注努力，难以扩展。
    
3. **现有方法的局限性**：论文指出，依赖于先进LLMs进行数据合成的现有方法，其能力受限于教师模型，无法超过教师模型的能力；同时，训练可靠的数学推理PRMs仍是一个开放问题。
    

为了解决这些问题，rStar-Math通过以下三个创新点来提升SLMs的数学推理能力，使其达到或甚至超过OpenAI o1的水平：

1. **代码增强的CoT数据合成方法**：通过执行广泛的MCTS（蒙特卡洛树搜索）来生成逐步验证的推理轨迹，并自注解MCTS Q值。
    
2. **过程偏好模型（PPM）训练方法**：避免了直接使用Q值作为奖励标签的简单方法，通过构建基于Q值的步骤级偏好对来训练PPM，实现可靠的标注。
    
3. **自我进化策略**：通过迭代进化策略模型和PPM，从零开始并逐步提高推理能力。通过数百万合成解决方案的自我进化，rStar-Math将SLMs的数学推理能力提升到最先进的水平。

## 相关研究




## 核心亮点

论文通过提出 rStar-Math 方法解决了上述问题，具体解决方案包括以下几个关键点：

### 1. 代码增强的 CoT 数据合成方法

- **MCTS 驱动的深度思考**：rStar-Math 使用蒙特卡洛树搜索（MCTS）分解数学问题解决为多步骤生成任务，每一步由策略模型（SLM）生成候选节点，每个节点生成一步的 CoT（Chain of Thought）和对应的 Python 代码。
    
- **代码执行验证**：只有成功执行 Python 代码的节点才被保留，以减少中间步骤的错误。
    
- **Q值自标注**：通过广泛的 MCTS 模拟，基于对正确答案的贡献自动为每个中间步骤分配 Q 值，确保由 SLM 生成的推理轨迹包含正确、高质量的中间步骤。
    

### 2. 过程偏好模型（PPM）训练方法

- **基于 Q 值的偏好对构建**：PPM 利用 Q 值区分正（正确）步骤和负（不相关/错误）步骤，通过成对排名损失优化 PPM 的得分预测，避免了直接使用 Q 值作为奖励标签的噪声和不精确性。

### 3. 自我进化策略

- **四轮自我进化**：从零开始迭代构建前沿策略模型和 PPM，每一轮使用最新的策略模型和 PPM 进行 MCTS，生成更高质量的训练数据，逐步提高对更复杂数学问题的覆盖和训练数据的质量。
    
- **训练数据收集和过滤**：收集 747k 数学问题，并基于难度对问题进行分类，选择高 Q 值的轨迹作为训练数据。
    
- **监督式微调策略 SLM**：使用每步的 Q 值选择最优轨迹作为监督式微调（SFT）训练数据。
    
- **PPM 的训练**：PPM 从微调策略模型初始化，使用成对排名损失进行训练。
    

### 4. 实验验证

- **跨不同规模 SLMs 的广泛实验**：在不同规模的 SLMs 上验证 rStar-Math 的有效性，并在多个数学推理任务上达到或超越 OpenAI o1 的性能。
    
- **与现有方法的比较**：与现有的 System 1 和 System 2 方法进行比较，展示 rStar-Math 在各种挑战性数学基准测试中的优越性。
    

通过这些方法，rStar-Math 能够在不依赖于更大型模型的情况下，使小型语言模型在数学推理任务上达到最先进的性能水平。


## 实验




## 未来方向



## 主要收获


## 参考资料
