
[Anthropic官方2024.9 深入探讨prompt工程 | 中文脱水版 (重制)](https://mp.weixin.qq.com/s/KDxMHfiH4D8I2onyy7JW7g)
- 什么样的人是好的prompt工程师呢？首先是清晰的沟通能力，包括能够清楚地陈述事物、准确理解任务、深入思考并清晰描述概念，这些构成了写作能力的基础部分。
- 关键在于要有强大的迭代能力，要能分析出模型在哪里产生了误解，并且知道如何修正。同时，你需要思考prompt可能出错的各种情况。
- 你会看到这些评估用例都是理想化的完美用户输入，但真正重要的是要思考实际的聊天场景会是什么样子，用户实际会怎么使用。在机器学习领域，查看你的数据几乎已经成了陈词滥调。我觉得在prompt工程中，仔细阅读模型输出就相当于这个原则。
- 作为prompt工程师，我们需要考虑模型如何理解指令这个特殊的心智模型问题。说到心智模型，写任务指令真的特别难。要把你脑子里所有已知的东西都剥离开，然后清晰地写下Claude不知道的所有信息，这是个极具挑战性的任务。这也是区分优秀prompt工程师的关键之一。关键技能是能够跳出自己的认知框架，向这个知识虽然广博但并非无所不知的系统传达必要信息。
- 我在写初始prompt时会这样做：给出prompt后，我会说我不要你按这些指令做，我只想让你告诉我哪些地方不清晰、有什么歧义，或者你有什么不理解的地方。虽然模型不是每次都能完美识别所有问题，但这确实是个很有用的方法。
- 还有一点，当人们看到模型犯错时，经常忽略了一个简单的做法，就是直接问模型。你可以对模型说你这里做错了，能想想是为什么吗？能不能帮我重写一下这些指令，让你下次不会犯同样的错？很多时候，模型就能准确指出问题所在，说哦对，这里不够清楚，然后给出修改建议。把这些修改后的指令用上去，就能正常工作了。
- 当模型稍微偏离训练分布时会表现得很奇怪。即使是一些相对简单的任务，只要进入未训练过或不常见的领域，模型的可靠性就会大幅下降。
- 你们有什么方法来判断一个任务是否可能通过完美的prompt来实现？我通常会观察模型是否真正理解任务。对于那些prompt帮不上忙的任务，虽然需要一些反复尝试，但通常很快就能看出模型是否能接近目标。如果模型明显做不到，我就不会在上面浪费太多时间。我们可以通过询问模型它是如何思考的，为什么这样思考。这样可以判断它是否在正确的方向上——就像判断是否在对的邮编区域一样。有些任务你能感觉到在逐步接近正确答案，而有些任务每次调整都会偏离到完全不同的错误方向。对于后者，我就会放弃。
- 我其实想深入讨论一下这个问题，因为这是最著名的prompt技巧之一，就是告诉语言模型它们是某个特定角色或身份。我感觉看到的效果不一，可能这种方法在早期模型中效果更好，现在似乎没那么有效了。

