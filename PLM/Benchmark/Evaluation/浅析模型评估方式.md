---
title: 浅析模型评估方式
created: 2025-06-03
tags:
  - 李宏毅
  - 模型评估
---
如何评估模型的能力呢？首先需要准备评估数据集，该数据集有输入和标准答案。然后将输入给到不同的语言模型，分别得到不同的输出。最后将模型的输出和标准答案进行比较，就能知道哪个模型的正确率更高，也就代表模型的在这个数据集所代表的能力上更强。

![](img/浅析模型评估方式-20250603201925.png)

那么这里面有几个问题。第一个问题是，如何根据标准答案决定输出是否正确？因为语言模型的输出是没有限制的，所以评估它是否正确存在一定的挑战。

一种方案是考模型选择题，因为选择题是有标准答案的。比如我们常常看到的MMLU：

![](img/浅析模型评估方式-20250603202354.png)

然后你会发现不同的文献中对同一个模型测出来的MMLU分数是不一样的...这是为什么呢？

![](img/浅析模型评估方式-20250603202427.png)

一般来说，我们希望把选择题给到语言模型后，它只输出选项，不输出其他内容，这样我们就能够直接拿它的输出和正确答案做比较，就知道是否正确了。但实际上语言模型可能会说“答案是b”“根据计算，我认为是1”这种不符合我们预期的内容，前者还可以用正则表达式解析，后者就很难判断了。我们也可以告诉模型，“只可以输出选项，不可以输出其他内容”，但是这样做真的是在考察模型的做题能力吗？还是在考察它遵循给定指令的能力呢？

![](img/浅析模型评估方式-20250603202455.png)

另一种方法是，我们可以直接限制模型的输出，因为模型的输出是一个几率分布，选择几率最高的token作为答案即可。但是问题又来了，比如输出的概率分数是下图这样，算对还是错呢？似乎对有对的理由，错也有错的理由，没有标准答案。

![](img/浅析模型评估方式-20250603202519.png)

语言模型即使在选择题上的评估也是有不同可能性的。

来看一个有趣的实验，在原始的MMLU上，各个模型的分数是第一列Orig所示，当把所有正确选项都移到A之后，模型的分数发生了很大变化！llama-30B直接加了15分！移到其他字母上也有类似的情况。甚至选项的表示方式（大写、小写、1/2/3/4，选项加括号）也会影响正确率。惊不惊喜？意不意外？

![](img/浅析模型评估方式-20250603204100.png)

除了选择题之外，还有很多没有标准答案的问题类型，比如翻译和摘要，模型的输出和标准答案不同并不代表模型输出是错的。

![](img/浅析模型评估方式-20250603204237.png)

像翻译和摘要这种经典的任务，已经有可以比对模型输出和标准答案的方法，翻译用BLEU，摘要用ROUGE指标，原理都是做字面的比对，不需要和标准答案完全一致，只需要一部分一致即可。但是这种方法也不是完美的，像翻译中，“诙谐”和“幽默”，这种方法就会算做是全错，显然是不合理的。

![](img/浅析模型评估方式-20250603205247.png)

那还是让人来评估最准确吗？有一个Chatbot Arena的网站就是让人类来选择和评估。你可以输入一个问题，会返回两个不同模型的回复给你，你去选择其中更好的回复。

![](img/浅析模型评估方式-20250603205622.png)

被选择次数越多的模型（实际算法不是这么简单，后面会细说），排名就会越高，形成一个排行榜

![](img/浅析模型评估方式-20250603205818.png)

但是人来评估很耗时间，也耗人力，所以又想出让语言模型来评估的方法

![](img/浅析模型评估方式-20250603210106.png)

![](img/浅析模型评估方式-20250603210127.png)

![](img/浅析模型评估方式-20250603210135.png)



![](img/浅析模型评估方式-20250603210206.png)

![](img/浅析模型评估方式-20250603210214.png)


