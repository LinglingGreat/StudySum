查询关键字理解（Query Understanding）是排序问题中一个非常重要的部分。

我们希望通过查询关键字来了解用户种种行为背后的目的。查询关键字产生的特征（Feature）往往是很强的指导因素，也是个性化搜索结果非常重要的源泉。

## 分类

查询关键字理解最基本的一个步骤就是给查询关键字分类（Classification），看这些查询关键字有什么用户意图（Intent）。

从商业搜索引擎开始面世的第一天起，人们就发现，可以从查询关键字中得到很多用户的信息，特别是理解用户的意图。早在 1997 年，商业搜索引擎 Excite 就开始了百万级别查询关键字的研究工作。然而，真正对查询关键字分类进行系统阐述的是安德烈·布罗德（Andrei Broder）的论文《网页搜索分类》（A Taxonomy of Web Search）。

在网络搜索（Web Search）成为比较主流的咨询查询手段之前，传统的信息检索认为，查询的主要目的是完成一个抽象的“信息需求”（Information Needs）。在传统信息检索的世界里，最主要的应用应该是图书馆检索或者政府学校等企事业单位的检索。因此，在这样的场景下，假定每一个查询主要是满足某个“信息需求”就显得很有道理了。

然而，早在 2002 年，安德烈就认为这样的传统假定已经不适合网络时代了。他开始把查询关键字所代表的目的划分为三个大类：导航目的（Navigational）；信息目的（Informational）；交易目的（Transactional）。此后十多年里，查询关键字的这三大分类都是这个方向研究和实践的基石。

第一类，以导航为意图的查询关键字，这类查询关键字的目标是达到某个网站。这有可能是用户以前访问过这个网站，或者是用户假设有这么一个关于所提交查询关键字的网站。这一类查询关键字包括公司的名字（如“微软”）、人的名字（如“奥巴马”）或者某个服务的名字（如“联邦快递”）等。

此类查询关键字的一个重要特点就是，在大多数情况下，这些查询关键字都对应唯一的或者很少的“标准答案”网站。比如，搜索“微软公司”，希望能够找到的就是微软公司的官方网站。另一方面是说，某些“信息集成”网站也是可以接受的“答案”。比如，查询“奥巴马”，搜索返回的结果是一个列举了所有美国总统的网站。

第二类，以信息为意图的查询关键字，这类查询关键字的目标是搜集信息。这一类的查询和传统的信息检索非常接近。值得提及的是，从后面的研究结论来看，这一类查询关键字所包含的目标不仅仅是寻找到某类权威性质（Authority）的网页，还包括列举权威信息的俗称“结点”（Hub）的网站。

第三类，以交易为意图的查询关键字，这类查询关键字的目标是到达一个中间站点从而进一步完成“交易”（Transaction）。这一类查询关键字的主要对象就是“购物”。

这种把查询关键字进行分类的研究是对用户行为进行建模的必要步骤。

过去的研究反复证明，以下几类特征非常有效。

第一类特征就是查询关键字本身的信息。比如，查询关键字中已经包括了已知的人名或者公司名，这种时候，分类结果就不太可能是交易意图的类别。也就是说，查询关键字，特别是某些词或者词组和类别有某种关联信息，而这种关联很大程度上能被直接反映出来。

第二类特征是搜索引擎返回的查询关键字相关的页面本身的信息。你可以想象一下，假如搜索“奥巴马”这个关键字，返回的页面都是维基百科的页面以及奥巴马基金会的页面，那么这些页面上面的内容可能很难包含任何商业的购买信息。而对于“佳能相机”这个查询关键字而言，返回的页面很可能都是电子商务网站的商品信息，从而能够更加准确地判断“佳能相机”的分类。

第三类特征则是用户的行为信息，那就是用户在输入查询关键字以后会点击什么网站，会在哪些网站停留。一般来说，哪些网站点击率高、停留时间长，就表明这些网站在返回结果中可能更相关。于是，采用这些网站来作为查询关键字所代表的内容，就可能更加靠谱。

在实际的应用中，查询关键字的分类往往还是有很大难度的。因为在普通的现代搜索引擎上，每天可能有三分之一、甚至更多的关键字是之前没有出现过的。因此，如何处理从来没有出现过的关键字、如何处理长尾中的低频关键字，就成了让搜索结果的精度再上一个台阶的重要因素。

拓展阅读：[A taxonomy of web search](https://www.cis.upenn.edu/~nenkova/Courses/cis430/p3-broder.pdf)



## 解析

查询关键字解析（Query Parsing）

如果说查询关键字分类是对查询关键字的宏观把握，那么，对查询关键字的解析就是微观分析。

首先，让我们设想这么一个场景，在英文的搜索引擎中，如果一个用户输入的是“White House Opening”这个查询关键字，这个用户的意图（Intent）是什么呢？要想理解用户的意图，我们就得知道用户输入的单词的涵义。

那么，在上面这个查询关键字里，我们到底是分别理解每一个单词“White”、“House”和“Opening”呢，还是“White House”和“Opening”呢，还是有可能“White House Opening”是一个整体呢？这里说的其实就是“查询关键字分割”（Query Segmentation）这个概念。

在刚才的例子中，如何把“White House Opening”进行分割直接关系到搜索结果的质量。试想在一个比较标准的现代搜索引擎里，一般来说，都会有一个模块根据查询关键字来提取“倒排索引”（Inverted Index）中的文档。这个阶段的提取数目一般是几百到几千，这个过程常常被称为“检索流程”（Retrieval Phase）。

当有了这些文档以后，现代搜索引擎会利用比较复杂的排序算法，通常就是我们之前提到过的基于机器学习的排序学习模型，来对文档进行重新排序（Re-Rank）。

你可以看到，在这样两个阶段的流程里，如果好的文档没有在第一个阶段被提取出来，不管第二个阶段的功能有多强大，搜索的整体结果都不可能有多好。而对于“检索流程”而言，在“倒排索引”中进行查询的关键就是使用什么“单词”或者“词组”进行查找。

用刚才的例子来说，就是看文档究竟是符合“White House”，还是“White 或 House”，还是“White House Opening”。很明显，这三种情况得到的文档集合是不尽相同的。如果用户的真实意图是搜索美国总统府白宫的开放时间，那么把这个搜索关键字给分割成“White 或 House”，很明显就会影响提取的文档集合。

那究竟该怎样做查询关键字分割呢？

这里我介绍一篇论文《重新审视查询关键字分割》（Query Segmentation Revisited ）。在这篇论文里，作者们集中介绍了一些主流的“查询关键字分割”技术，文章非常值得精读。下面我为你归纳一下要点。

第一种技术就是尝试从查询关键字里面产生“N 元语法”（N-Grams）。所谓 N 元语法其实就是从一组词语中产生连续的子词语。比如刚才的“White House Opening”的例子，我们就可以从这个词组里面产生“White House”和“House Opening”两个二元语法。

而第一种基于 N 元语法的方法，就是通过这些 N 元语法在一个大语料中出现的词频来判断这个“分割”是否有意义。当然，直接采用词频可能会比较偏好短的单词，所以在论文中，作者们分别介绍了两种矫正词频的方法。

一种是基于词频本身的矫正，一种是基于维基百科，作为一个外部资源的矫正方式。两种方法的目的都是为了让长短语的打分（Scoring）有机会高于短的单词。文章中所需要的词频采用了谷歌 2005 年发布的“N 元语法”语料，也就是说，所有单词出现的频率都是直接在这个语料中获得的。

第二种技术是基于短语“互信息”（Mutual Information）的方法。“互信息”计算了两个随机事件的相关程度。在这里，就是计算查询关键字中每两个相邻短语的“互信息”。当这个“互信息”的取值大于某一个预设阈值的时候，我们就认为相邻的两个单词组成了短语。“互信息”的计算需要知道某个单词出现的概率，这些概率是从微软发布的一个“N 元语法”语料获得的。

第三种技术则是基于“条件随机场”（Conditional Random Field）。“条件随机场”是机器学习著名学者乔治·拉菲迪（John D. Lafferty）、安德鲁·麦卡伦（Andrew McCallum）和费尔南多·佩雷拉（Fernando Pereira）在 2001 年发表的“序列学习”模型（Sequence Model）中提出的。条件随机场的基本思想是对输出的复杂标签进行建模，尝试从特征空间建立到复杂标签的一个对应关系。

在“查询关键字分割”的场景下，我们其实可以把复杂标签看作是从一个查询关键字到多个短语的多个二元决策问题。这里的二元决策是指某一个备选短语是否可以作为分割的短语。条件随机场可以比较直观地对这类问题进行建模，而传统的二分分类器则很难对序列信息进行建模。

分割问题”是查询关键字理解的第一步。那么，下一步则是更细致地分析查询关键字。

回到刚才的例子“White House Opening”，我们其实不仅是想知道这个查询关键字可以分割为“White House”和“Opening”，而且希望知道“White House”是一个建筑物的名字或者一个地理位置的名字，而“Opening”则可能是一个名词，暗指“开门时间”。也就是说，我们希望为查询关键字中的词组进行“标注”（Annotation），来获取其“属性”（Attribute）信息。希望为查询关键字中分割出来的词组进行标注的组件就叫做“查询关键字标注”。

那么，标注信息又是怎样帮助搜索结果的呢？试想一下“苹果价格”这个查询关键字。这取决于用户搜索的场景，如果“苹果”代表“水果”这个属性，那么这个查询的结果是希望找到水果的价格，可能还需要搜索引擎返回附近超市的一些信息。但如果“苹果”其实代表的是“手机”，那这个查询的结果也许最好是返回苹果公司的官方销售网站。你看，“苹果”所代表的属性不同，最优的返回结果可能会有非常大的差别。

对查询关键字进行标注的方法也有很多。我这里再推荐一篇经典的论文《使用伪相关反馈针对搜索查询关键字进行结构化标注》（Structural annotation of search queries using pseudo-relevance feedback），这篇论文利用一个叫做 PRF（Pseudo-Relevance Feedback）的方法来进行标注。这里面的一个技术难点是，查询关键字的信息实在是太少，需要利用大量的辅助信息来进行标注，因此 PRF 作为一个技术在这里得到了应用。

另外一个主流的查询关键字标注的方法，依然是利用条件随机场。我前面讲了，条件随机场是很好的序列建模工具。那么，在这里，以“苹果价格”为例，条件随机场是需要预测标签是否是“手机名词”还是“水果名词”这样的组合输出结果。而传统的二分或者多类分类器很难捕捉到这里的序列信息，条件随机场就是解决这方面的利器。

于是，我们需要做的就是为查询关键字构建特征（Feature），然后直接放入条件随机场中。有一点需要注意，条件随机场的应用成功与否与数据的多少有很大关系。因此，构建一个有标注信息的数据集就变成了查询关键字标注的一个核心挑战。

Matthias Hagen, Martin Potthast, Benno Stein, and Christof Bräutigam. Query segmentation revisited. Proceedings of the 20th international conference on World wide web (WWW '11). ACM, New York, NY, USA, 97-106. 2011.

Michael Bendersky, W. Bruce Croft, and David A. Smith. Structural annotation of search queries using pseudo-relevance feedback. Proceedings of the 19th ACM international conference on Information and knowledge management (CIKM '10). ACM, New York, NY, USA, 1537-1540. 2010.

## 扩展

查询关键字扩展（Query Expansion）

为什么要提供查询关键字扩展？主要原因还是用户输入的查询关键字信息不足。还记得我们上次提到的“苹果价格”这个例子吗？在这个例子中，用户到底是希望查询“苹果”作为一种水果的价格，还是“苹果”作为手机的价格，其实无法真正从这个查询关键字中得出。因此，作为搜索引擎，如果为用户提供一些“扩展选项”，也就是一个被改写（Reformulated）过的查询关键字，会提供更加好的用户体验和更加精准的搜索结果。

查询关键字扩展除了显示出来能够让用户有更好的体验以外，还有一个作用是增加文档的“召回”（Recall），从而为提高搜索结果奠定基础。设想这样一个例子，用户搜索“iphone 6 backup”，希望了解如何备份 iPhone 6 的信息。因为苹果手机的绝大多数机型的备份流程都大同小异，因此，如果把“iphone 6”给扩展到“iphone”其他机型，然后看是否有比较好的介绍备份的网页可以显示。

值得注意的是，在扩展的过程中也有可能失去“精度”（Precision）。比如假设苹果对 iPhone 7 的备份流程做了很大的改进，那么其他机型的流程也许就不适用了，所以当用户搜索“iphone 7 backup”的时候，如果我们扩展到了其他机型，那让用户看到的很可能就是不那么相关的信息了。因此，对“精度”和“召回”的平衡，成了查询关键字扩展的一个重要的权衡点。

查询关键字扩展的另外一个重要应用就是对同义词和缩写的处理。比如，唐纳德·特朗普（Donald Trump）是美国现任总统。那么，如果用户在搜索“Donald Trump”、“Trump”、“US President”、“POTUS”（这是“President Of The United States”的简称）等类似词汇的时候，搜索引擎应该提供相似的结果。而从词汇的直接联系上，这些词汇在表面形式上可能有很大的差异（比如“Trump”和“POTUS”），因此需要其他手段学习到这些词语内涵的同义。

根据上面提供的一些例子，你可以看到，这里的核心就是找到搜索结果意义上的“同义词”。那么，在搜索中，如何挖掘“同义词”呢？

第一种思路，是根据查询关键字和查询结果之间的自然结合产生的同义效果。这需要对用户的搜索行为数据进行大规模挖掘。这里的基本假设是这样的，假设我们有两个搜索关键字，A 和 B。从 A 的搜索结果中，用户可能点击了一些网页，从 B 的结果中，用户可能点击了另外的一些网页。如果这些被点击的网页恰好非常类似，那么，我们就可以认为 A 和 B 其实是同义的查询关键字。

更加完整的做法是把查询关键字和网页分别表示成“图”（Graph）中的两类节点（Node）。每个关键字节点和多个网页节点建立联系（Edge）或者边（Link），象征这些网页对应这个关键字的相关页面。而从每个网页的角度上看，多个关键字节点又和同一个网页节点相连，表示这些关键字都有可能和某个网页相关。

拿上面提到的特朗普的例子来说，美国白宫的首页作为一个节点的话，就有可能会和“Trump”、“US President”以及“POTUS”这几个查询关键字相关。因此你可以看到，寻找同义词的工作就变成了如何在这个图上进行相似节点，特别是相似关键字节点的挖掘工作。

如果把查询关键字的节点放在一边，把网页节点放在一边，我们就看到了典型的“二分图”（Bipartite Graph）。二分图的特点是同边的节点之间没有连接（比如关键字和关键字之间没有连接），而所有的连接都发生在不同边的节点之间（关键字和网页之间）。

二分图的聚类问题（Clustering）是机器学习界的经典的问题。而利用二分图的聚类问题来做查询关键字的同义词挖掘也是很多研究人员尝试的方向。文末我列了几个参考文献，比如参考文献[2]就是利用二分图上的“随机游走”（Random Walk）以及随机游走所产生的“到达时间”（Hitting Time）来挖掘出类似的关键字。如果你有兴趣，可以查看这篇经典论文。

说了基于用户行为信息和关键字挖掘的思路以后，我们再来看看第二种思路。

第二种思路的核心是从海量的文本信息中分析出词语之间的相关度。这里面需要注意的是，这些词语的相关度有可能是语言本身带来的。比如，单词“Male”和“Man”。也可能是语境带来的，比如谈论手机的网页中对于“iPhone 6”和“iPhone 7”的谈论。

总之，这一个思路的想法就是如何为每一个词组都建一个“表达”（Representation），从而通过这个表达找到同义词。近年来流行的一个做法是为单词找到数值表达，也就是通常所说的“嵌入”（Embedding）。如果两个词在“嵌入空间”（Embedding Space），通常是“欧式空间”中距离相近，那么我们就可以认为这两个词是同义词。

如何为词组产生“嵌入”向量呢？这里面也有很多做法。比较通用的有算法 Word2Vec（参考文献[3]），目标是通过一个文档的每一句话中某一个词周围的词来预测这个词出现的概率。可以设想一下，在苹果手机的很多帮助文档或者帮助站点中，描述如何帮助 iPhone 6 或者 iPhone 7 来做数据备份的字句都是相似的，甚至，可能唯一的区别就是描述机型的名字。

因此在这样的情况下，通过文字周围的“上下文信息”（Contextual）来对单词本身的“嵌入向量”进行学习可以有效地学习到单词的语义。而通过语义，我们就能够找到其他的同义词。当然，要想真正应用到查询关键字扩展中，可能还需要有其他的调试，比如文末我列的参考文献[4]，就是其中的一种。如果你感兴趣，建议去精读。

最后我需要说明的是，第一种思路需要已经有不少的用户交互数据，而第二种思路可以通过其他的语料（比如维基百科）加以学习，并不需要用户数据。这也是另一个值得参考的信息点。

Claudio Carpineto and Giovanni Romano. A Survey of Automatic Query Expansion in Information Retrieval. ACM Computing Surveys. 44, 1, Article 1 (January 2012), 50 pages.2012.

Qiaozhu Mei, Dengyong Zhou, and Kenneth Church. Query suggestion using hitting time. Proceedings of the 17th ACM conference on Information and knowledge management (CIKM '08). ACM, New York, NY, USA, 469-478. 2008.

Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).

Diaz, Fernando, Bhaskar Mitra, and Nick Craswell. Query expansion with locally-trained word embeddings. arXiv preprint arXiv:1605.07891 (2016).

