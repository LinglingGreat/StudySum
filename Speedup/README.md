---
title: README
created: 2024-06-17
tags:
  - æ¨ç†åŠ é€Ÿ
---
## æ¨ç†åŠ é€Ÿ

[GitHub - microsoft/DeepSpeed-MII: MII makes low-latency and high-throughput inference possible, powered by DeepSpeed.](https://github.com/microsoft/DeepSpeed-MII)

[Break the Sequential Dependency of LLM Inference Using Lookahead Decoding | LMSYS Org](https://lmsys.org/blog/2023-11-21-lookahead-decoding/)

[GitHub - FasterDecoding/Medusa: Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Heads](https://github.com/FasterDecoding/Medusa)

[è¯­è¨€å¤§æ¨¡å‹æ¨ç†åŠ é€ŸæŒ‡å—](https://mp.weixin.qq.com/s/B3TD2p_5HKoYkzzupLoUxQ)

[è¿›æˆ‘çš„æ”¶è—å¤¹åƒç°å§ï¼šå¤§æ¨¡å‹åŠ é€Ÿè¶…å…¨æŒ‡å—æ¥äº†](https://mp.weixin.qq.com/s/4USwSMIiudFCdy9C5pN1dQ)


[[Prefillä¼˜åŒ–][ä¸‡å­—]ğŸ”¥åŸç†&å›¾è§£vLLM Automatic Prefix Cache(RadixAttention): é¦–Tokenæ—¶å»¶ä¼˜åŒ– - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/693556044)

[LLMåç«¯æ¨ç†å¼•æ“æ€§èƒ½å¤§æ¯”æ‹¼](https://mp.weixin.qq.com/s/dPd84P_VdKog8v2IcHDOrQ) å¯¹æ¯”äº†vLLMã€LMDeployã€MLC-LLMã€TensorRT-LLM å’Œ Hugging Face TGI.

[å¤§æ¨¡å‹å‹ç¼©é‡åŒ–æ–¹æ¡ˆæ€ä¹ˆé€‰ï¼Ÿæ— é—®èŠ¯ç©¹Qllm-Evalé‡åŒ–æ–¹æ¡ˆå…¨é¢è¯„ä¼°ï¼šå¤šæ¨¡å‹ã€å¤šå‚æ•°ã€å¤šç»´åº¦](https://mp.weixin.qq.com/s/BxMT1CZk35yMP8qnhoFNFw)
1. Weight-onlyé‡åŒ–å¯ä»¥æ˜¾è‘—åŠ é€Ÿdecodingé˜¶æ®µï¼Œä»è€Œæ”¹å–„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
    
2. å…³äºprefillé˜¶æ®µï¼ŒWeight-onlyé‡åŒ–å¯èƒ½å®é™…ä¸Šä¼šå¢åŠ å»¶è¿Ÿã€‚
    
3. éšç€æ‰¹é‡å¤§å°å’Œè¾“å…¥é•¿åº¦çš„å¢åŠ ï¼ŒWeight-onlyé‡åŒ–æ‰€å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœé€æ¸å‡å°ã€‚
    
4. å¯¹äºè¾ƒå¤§çš„æ¨¡å‹ï¼ŒWeight-onlyé‡åŒ–æä¾›äº†æ›´å¤§çš„ç›Šå¤„ï¼Œå› ä¸ºè¾ƒå¤§æ¨¡å‹å°ºå¯¸çš„å†…å­˜è®¿é—®å¼€é”€æ˜¾è‘—å¢åŠ ã€‚

[å¤§æ¨¡å‹è®­ç»ƒåŠæ¨ç†ç»å…¸å¿…è¯»ï¼šFP8çš„whatï¼Œwhyï¼ŒhowåŠå…¶å¸¦æ¥çš„æœºä¼šï¼Ÿ](https://mp.weixin.qq.com/s/Hyb04agEpGpwM4inn6CibA)


[æœˆä¹‹æš—é¢kimiåº•å±‚æ¨ç†ç³»ç»Ÿæ–¹æ¡ˆæ­ç§˜](https://mp.weixin.qq.com/s/To97I4bU30fQssqkESTOGA)

[Towards 100x Speedup: Full Stack Transformer Inference Optimization](https://yaofu.notion.site/Towards-100x-Speedup-Full-Stack-Transformer-Inference-Optimization-43124c3688e14cffaf2f1d6cbdf26c6c)

[OSDI 24 Serverless LLMï¼šæ€§èƒ½æå‡200å€](https://mp.weixin.qq.com/s/DoxSI5M-jcdlSg000VEIng)

[DeepSpeed Inferenceå…¨æ ˆä¼˜åŒ–ï¼Œå»¶è¿Ÿé™ä½7.3å€ï¼Œååæå‡1.5å€](https://mp.weixin.qq.com/s/fvJaREiR6FGuwWBRFafvbw)

[[TensorRT-LLM][5wå­—]ğŸ”¥TensorRT-LLM éƒ¨ç½²è°ƒä¼˜-æŒ‡åŒ—](https://zhuanlan.zhihu.com/p/699333691)

##  å‚æ•°é‡ã€è®¡ç®—é‡ã€æ˜¾å­˜ç­‰

[ã€Transformerã€‘å‚æ•°é‡ã€è®¡ç®—é‡ã€æ˜¾å­˜ç­‰åˆ†æ](https://mp.weixin.qq.com/s/zZh1CaeozXBffImxnBTPtg)

[è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ï¼šä»ä¼°ç®—åˆ° FLOPs æ¨å¯¼](https://zhuanlan.zhihu.com/p/646905171)

[å¤§æ¨¡å‹è®­ç»ƒéœ€è¦èŠ±è´¹å¤šé•¿æ—¶é—´ï¼šFLOPsçš„ç®€å•è®¡ç®—æ–¹æ³•åŠcalflopå¼€æºå®ç°](https://mp.weixin.qq.com/s/nB-ldVgWJTJhwI-f7rO7IQ)

https://huggingface.co/spaces/Jellyfish042/UncheatableEval
å‹ç¼©èƒ½åŠ›æ¦œå•

## è®­ç»ƒ


[ã€åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯åˆ†äº«ä¸ƒã€‘èŠèŠå­—èŠ‚ AML ä¸‡å¡å·¥ä½œ MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/684619370)

[OneFlow â€”â€” è®©æ¯ä¸€ä½ç®—æ³•å·¥ç¨‹å¸ˆéƒ½æœ‰èƒ½åŠ›è®­ç»ƒ GPT - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/371499074?utm_psn=1749361005107462144)



## DeepSeekå¼€æºé¡¹ç›®

[FlashMLA](FlashMLA/FlashMLA.md)

[DeepEP](DeepEP/DeepEP.md)

[DeepGEMM](DeepGEMM/DeepGEMM.md)

[DualPipe&EPLB](DualPipe/DualPipe&EPLB.md)

[DeepSeek-V3 / R1 æ¨ç†ç³»ç»Ÿæ¦‚è§ˆ](https://zhuanlan.zhihu.com/p/27181462601)

**ä¼˜åŒ–ç›®æ ‡æ˜¯ï¼šæ›´å¤§çš„ååï¼Œæ›´ä½çš„å»¶è¿Ÿã€‚**

