
åœ¨å¤§æ¨¡å‹è®­ç»ƒçš„æ—¶ä»£ï¼Œæˆ‘ä»¬ç»å¸¸å¬åˆ°â€œDeepSpeedâ€â€œZeROâ€â€œStage 3â€â€œæ¨¡å‹å¹¶è¡Œâ€â€œæ•°æ®å¹¶è¡Œâ€ç­‰æ¦‚å¿µã€‚å®ƒä»¬çœ‹ä¼¼ç›¸è¿‘ï¼Œå´ä»£è¡¨ç€ä¸åŒå±‚æ¬¡çš„åˆ†å¸ƒå¼è®­ç»ƒæ€æƒ³ã€‚å¾ˆå¤šäººç¬¬ä¸€æ¬¡å¬åˆ° ZeRO Stage 3 æ—¶ï¼Œä¼šäº§ç”Ÿä¸€ä¸ªç–‘æƒ‘ï¼š

> å®ƒæŠŠå‚æ•°éƒ½åˆ†ç‰‡åˆ°ä¸åŒ GPU ä¸Šï¼Œé‚£è¿™ä¸å°±æ˜¯æ¨¡å‹å¹¶è¡Œå—ï¼Ÿ

æœ¬æ–‡å°†ç³»ç»Ÿè§£é‡Šï¼š

1. ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ DeepSpeedï¼›
    
2. DeepSpeed çš„æ ¸å¿ƒæ€æƒ³ä¸ ZeRO çš„åˆ†çº§æœºåˆ¶ï¼›
    
3. æ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œçš„åŒºåˆ«ï¼›
    
4. æœ€é‡è¦çš„â€”â€”**ä¸ºä»€ä¹ˆ ZeRO Stage 3 è™½ç„¶åˆ†ç‰‡äº†æ¨¡å‹å‚æ•°ï¼Œä½†æœ¬è´¨ä¸Šä»ç„¶æ˜¯æ•°æ®å¹¶è¡Œã€‚**
    

---

## ä¸€ã€ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ DeepSpeed

åœ¨è®­ç»ƒ GPTã€BERT è¿™ç±»å¤§è§„æ¨¡ Transformer æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š

1. **æ˜¾å­˜é™åˆ¶ï¼ˆMemory Bottleneckï¼‰**ï¼šæ¨¡å‹å‚æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¿€æ´»å€¼ã€æ¢¯åº¦éƒ½ä¼šå ç”¨å¤§é‡æ˜¾å­˜ã€‚å•å¡ 24GB/48GB æ˜¾å­˜è¿œè¿œä¸å¤Ÿã€‚
    
2. **è®¡ç®—æ•ˆç‡ï¼ˆCompute Efficiencyï¼‰**ï¼šå³ä¾¿èƒ½æ”¾ä¸‹æ¨¡å‹ï¼Œä¹Ÿè¦é«˜æ•ˆåˆ©ç”¨ GPU ç®—åŠ›ï¼Œé¿å…é€šä¿¡å’Œç­‰å¾…æµªè´¹ã€‚
    
3. **é€šä¿¡å¼€é”€ï¼ˆCommunication Overheadï¼‰**ï¼šå¤š GPU è®­ç»ƒéœ€è¦ä¸æ–­åŒæ­¥å‚æ•°ä¸æ¢¯åº¦ï¼Œé€šä¿¡ä»£ä»·å¸¸æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
    

ä¼ ç»Ÿçš„ **Data Parallelï¼ˆæ•°æ®å¹¶è¡Œï¼‰** æ–¹æ¡ˆï¼Œå¦‚ PyTorch çš„ `DistributedDataParallel (DDP)` æˆ– Horovodï¼Œåªè§£å†³äº†**å¤šæ•°æ®æ ·æœ¬çš„åˆ†å¸ƒå¼è®­ç»ƒ**é—®é¢˜ï¼Œå´ä»ç„¶å¤åˆ¶äº†å®Œæ•´çš„æ¨¡å‹å‰¯æœ¬ï¼Œå¯¼è‡´æ˜¾å­˜æµªè´¹ä¸¥é‡ã€‚

äºæ˜¯ï¼Œå¾®è½¯æ¨å‡ºäº† **DeepSpeed** â€”â€” ä¸€ä¸ªé¢å‘å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„ç³»ç»Ÿçº§ä¼˜åŒ–æ¡†æ¶ï¼Œç›®æ ‡æ˜¯ï¼š

> è®©ç™¾äº¿ã€åƒäº¿çº§å‚æ•°æ¨¡å‹åœ¨æœ‰é™ GPU ä¸Šä¹Ÿèƒ½é«˜æ•ˆè®­ç»ƒã€‚

---

## äºŒã€DeepSpeed æ˜¯ä»€ä¹ˆ

DeepSpeed æ˜¯å¾®è½¯æ¨å‡ºçš„ä¸€æ•´å¥—å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒç³»ç»Ÿï¼Œå®ƒå¹¶ä¸ä»…ä»…æ˜¯ä¸€ä¸ªâ€œå¹¶è¡Œåº“â€ï¼Œè€Œæ˜¯ä¸€å¥—å®Œæ•´çš„ **è®­ç»ƒå¼•æ“ï¼ˆDeepSpeed Engineï¼‰**ï¼Œé›†æˆäº†å¤šä¸ªç»„ä»¶ï¼š

- **ZeROï¼ˆZero Redundancy Optimizerï¼‰**ï¼šæ ¸å¿ƒåˆ†å¸ƒå¼ä¼˜åŒ–æœºåˆ¶ï¼›
    
- **DeepSpeed Inference**ï¼šæ¨ç†åŠ é€Ÿï¼›
    
- **DeepSpeed MoE**ï¼šMixture of Experts æ¨¡å‹æ”¯æŒï¼›
    
- **DeepSpeed Compression**ï¼šé‡åŒ–ä¸å‰ªæï¼›
    
- **DeepSpeed Checkpointing / Offload**ï¼šæ˜¾å­˜ä¸å­˜å‚¨ä¼˜åŒ–ã€‚
    

å…¶ä¸­æœ€æ ¸å¿ƒã€æœ€å…·å½±å“åŠ›çš„éƒ¨åˆ†å°±æ˜¯ ZeROï¼Œå®ƒå‡ ä¹æˆä¸ºæ‰€æœ‰è¶…å¤§æ¨¡å‹è®­ç»ƒçš„åŸºç¡€è®¾æ–½ã€‚

---

## ä¸‰ã€å¹¶è¡Œç­–ç•¥å…¨æ™¯å›¾ï¼šæ¨¡å‹å¹¶è¡Œ vs æ•°æ®å¹¶è¡Œ

è¦ç†è§£ ZeROï¼Œé¦–å…ˆè¦æ¸…æ¥šåˆ†å¸ƒå¼è®­ç»ƒçš„ä¸¤å¤§åŸºæœ¬æ€è·¯ã€‚

### 1. æ•°æ®å¹¶è¡Œï¼ˆData Parallelismï¼‰

- æ¯ä¸ª GPU æ‹¥æœ‰ä¸€ä»½å®Œæ•´æ¨¡å‹å‰¯æœ¬ï¼›
    
- ä¸åŒ GPU å¤„ç†ä¸åŒçš„æ•°æ®æ ·æœ¬ï¼›
    
- æ¯ä¸ª GPU ç‹¬ç«‹è®¡ç®—æ¢¯åº¦ï¼Œæœ€åè¿›è¡Œæ¢¯åº¦å¹³å‡ï¼ˆall-reduceï¼‰ï¼Œæ¯ä¸ªGPUå†ç‹¬ç«‹è¿›è¡Œå‚æ•°æ›´æ–°ã€‚
    

ä¼˜ç‚¹ï¼šå®ç°ç®€å•ï¼Œæ‰©å±•æ€§å¼ºã€‚  
ç¼ºç‚¹ï¼šæ¯ä¸ª GPU éƒ½å­˜å®Œæ•´çš„æ¨¡å‹å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ˜¾å­˜æµªè´¹å¤§ã€‚

### 2. æ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelismï¼‰

- æŠŠæ¨¡å‹åˆ‡å¼€ï¼Œåˆ†å¸ƒåœ¨å¤šä¸ª GPU ä¸Šï¼›
    
- åŒä¸€ä¸ªæ ·æœ¬çš„å‰å‘/åå‘ä¼ æ’­éœ€è¦è·¨ GPU æ‰§è¡Œã€‚
    

å¸¸è§çš„æ¨¡å‹å¹¶è¡Œæœ‰ï¼š

- **Tensor Parallelismï¼ˆå¼ é‡å¹¶è¡Œï¼‰**ï¼šåŒä¸€å±‚çš„çŸ©é˜µè¿ç®—è¢«å¤šä¸ª GPU åˆ†æ‹…ï¼ˆå¦‚ Megatron-LMï¼‰ã€‚
    
- **Pipeline Parallelismï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰**ï¼šä¸åŒ GPU å­˜ä¸åŒå±‚ï¼Œæ ·æœ¬æ²¿å±‚ä¼ æ’­ï¼ˆå¦‚ GPipeã€PipeDreamï¼‰ã€‚
    

ä¼˜ç‚¹ï¼šçªç ´å•å¡æ˜¾å­˜é™åˆ¶ã€‚  
ç¼ºç‚¹ï¼šé€šä¿¡å¤æ‚ã€ä¾èµ–å±‚ç»“æ„ã€è°ƒåº¦å›°éš¾ã€‚

---

## å››ã€ZeRO çš„æ ¸å¿ƒæ€æƒ³ï¼šå‡å°‘å†—ä½™ï¼Œç²¾ç»†åˆ†ç‰‡

åœ¨ä¼ ç»Ÿæ•°æ®å¹¶è¡Œä¸­ï¼Œæ¯ä¸ª GPU éƒ½ä¼šå¤åˆ¶æ¨¡å‹å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€ä¸‰ä»½ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸ª GPU å­˜äº†ä¸‰ä»½å‡ ä¹ä¸€æ ·çš„ä¸œè¥¿ï¼

ZeROï¼ˆZero Redundancy Optimizerï¼‰çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> æŠŠè¿™ä¸‰éƒ¨åˆ†çŠ¶æ€åˆ†ç‰‡ï¼ˆshardï¼‰åˆ°ä¸åŒ GPU ä¸Šï¼Œè®©æ¯ä¸ª GPU åªå­˜ä¸€éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯å®Œæ•´å‰¯æœ¬ã€‚

å®ƒåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š

| é˜¶æ®µ          | åˆ†ç‰‡å†…å®¹    | æ˜¾å­˜èŠ‚çœ      | ç‰¹ç‚¹              |
| ----------- | ------- | --------- | --------------- |
| **Stage 1** | åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€ | å‡å°‘çº¦ 4Ã— æ˜¾å­˜ | é€šä¿¡é‡å’Œä¼ ç»Ÿæ•°æ®å¹¶è¡Œç›¸åŒ    |
| **Stage 2** | é¢å¤–åˆ†ç‰‡æ¢¯åº¦  | å‡å°‘çº¦ 8Ã— æ˜¾å­˜ | é€šä¿¡é‡å’Œä¼ ç»Ÿæ•°æ®å¹¶è¡Œç›¸åŒ    |
| **Stage 3** | å†åˆ†ç‰‡å‚æ•°æœ¬èº« | å¯è®­ç»ƒè¶…å¤§æ¨¡å‹   | éœ€è¦åŠ¨æ€å‚æ•°äº¤æ¢ï¼Œé€šä¿¡é‡æœ‰å¢åŠ  |

åœ¨ Stage 3 ä¸­ï¼Œæ¯ä¸ª GPU ä»…å­˜ä¸€éƒ¨åˆ†å‚æ•°åˆ†ç‰‡ã€‚  
å½“æ‰§è¡Œå‰å‘ä¼ æ’­æ—¶ï¼ŒDeepSpeed ä¼š**åŠ¨æ€åœ°å¹¿æ’­éœ€è¦çš„å‚æ•°åˆ†ç‰‡**åˆ°è®¡ç®— GPU ä¸Šï¼›  
è®¡ç®—ç»“æŸåï¼Œå‚æ•°å†è¢«é‡Šæ”¾æˆ–é‡æ–°åˆ†é…ã€‚

---

## äº”ã€ä¸ºä»€ä¹ˆ ZeRO Stage 3 ä»ç„¶æ˜¯æ•°æ®å¹¶è¡Œ

è¿™æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚

### 1. æ•°æ®å¹¶è¡Œçš„å®šä¹‰æ ¸å¿ƒï¼š

> æ¯ä¸ª GPU å¤„ç†ä¸åŒçš„æ•°æ®æ ·æœ¬ï¼Œæ¨¡å‹é€»è¾‘ä¸Šå®Œæ•´ï¼Œåªæ˜¯çŠ¶æ€åˆ†å¸ƒåœ¨ä¸åŒè®¾å¤‡ä¸Šã€‚

### 2. æ¨¡å‹å¹¶è¡Œçš„å®šä¹‰æ ¸å¿ƒï¼š

> å¤šä¸ª GPU å…±åŒå¤„ç†åŒä¸€ä¸ªæ ·æœ¬çš„å‰å‘æˆ–åå‘ä¼ æ’­ï¼ˆä¾‹å¦‚ä¸€å±‚è¢«æ‹†åˆ°å¤šå¡ä¸Šï¼‰ã€‚

### 3. ZeRO Stage 3 çš„å®é™…æƒ…å†µï¼š

Zero Stage 3 åŠ è½½æ—¶å°†æ¨¡å‹å‚æ•°è¿›è¡Œåˆ‡ç‰‡å­˜å‚¨åˆ°ä¸åŒçš„GPUä¸Šï¼Œæ¯ä¸ªGPUåªä¿ç•™å‚æ•°çš„1/Nã€‚è®¡ç®—æ—¶ï¼Œæ¯ä¸ªGPUè·‘ä¸åŒçš„æ•°æ®ï¼Œç„¶åGPUä¹‹é—´è¿›è¡Œå‚æ•°é€šä¿¡ï¼Œä¿è¯æ¯ä¸ªGPUä¸‹çš„batchéƒ½èƒ½é€šè¿‡æ¨¡å‹å…¨éƒ¨å‚æ•°ï¼Œè€Œä¸æ˜¯å±€éƒ¨å‚æ•°ã€‚ï¼ˆä¸»è¦åˆ©ç”¨all-gatheræ”¶é›†å‚æ•°ï¼Œreduce-scatterè§„çº¦è®¡ç®—ï¼‰ã€‚å› æ­¤

- æ¯ä¸ª GPU ä¾ç„¶åœ¨å¤„ç†ä¸åŒçš„æ•°æ® mini-batchï¼›
    
- æ¯ä¸ª GPU **é€»è¾‘ä¸Šæ‹¥æœ‰å®Œæ•´æ¨¡å‹**ï¼Œåªæ˜¯å‚æ•°æš‚æ—¶å­˜å‚¨åœ¨ä¸åŒ GPU ä¸Šï¼›
    
- è®¡ç®—æ—¶ï¼Œé€šè¿‡å‚æ•°åˆ†ç‰‡å¹¿æ’­æœºåˆ¶ï¼Œå½“å‰ GPU æ‹¿åˆ°è‡ªå·±éœ€è¦çš„å‚æ•°å—è¿›è¡Œ forward/backwardï¼›
    
- æ‰€ä»¥å®ƒä¾ç„¶å±äº **æ•°æ®å¹¶è¡ŒèŒƒç•´**ï¼Œåªæ˜¯é€šè¿‡â€œåˆ†å¸ƒå¼çŠ¶æ€ç®¡ç†â€èŠ‚çœæ˜¾å­˜ã€‚
    

æ¢å¥è¯è¯´ï¼š

> ZeRO Stage 3 æ˜¯ä¸€ç§â€œå‚æ•°åˆ†ç‰‡ç‰ˆçš„æ•°æ®å¹¶è¡Œâ€ï¼ˆFully Sharded Data Parallelï¼ŒFSDPï¼‰ã€‚

å®ƒå¹¶ä¸ä¼šè®©ä¸åŒ GPU å…±åŒè®¡ç®—åŒä¸€ä¸ªæ ·æœ¬çš„æŸä¸€å±‚ï¼Œè¿™ä¸€ç‚¹å’Œæ¨¡å‹å¹¶è¡Œæœ¬è´¨ä¸åŒã€‚

---

## å…­ã€ZeRO ä¸å…¶ä»–å¹¶è¡ŒæŠ€æœ¯çš„å…³ç³»

DeepSpeed çš„ ZeRO è®¾è®¡éå¸¸çµæ´»ï¼Œå¯ä»¥ä¸å…¶ä»–å¹¶è¡Œæ–¹å¼ç»„åˆï¼š

|å¹¶è¡Œç±»å‹|æ¡ˆä¾‹|å¯å¦ä¸ ZeRO ç»“åˆ|
|---|---|---|
|**Tensor å¹¶è¡Œ**|Megatron-LM|âœ… å¸¸è§ç»„åˆï¼ˆZeRO + TPï¼‰|
|**Pipeline å¹¶è¡Œ**|GPipe / PipeDream|âœ… å¯ç»“åˆ|
|**MoE å¹¶è¡Œ**|DeepSpeed-MoE|âœ… ä¸“é—¨æ”¯æŒ|
|**FSDP**|PyTorch å®˜æ–¹|ğŸ” æœ¬è´¨ä¸Šç­‰ä»·äº ZeRO Stage 3|

ç°ä»£å¤§æ¨¡å‹ï¼ˆå¦‚ GPT-4ã€Mixtralã€DeepSeek-V2ï¼‰å‡ ä¹éƒ½é‡‡ç”¨ **Hybrid Parallelism**ï¼š

> Data + Tensor + Pipeline + MoE + ZeRO æ··åˆæ¶æ„ã€‚

---

## ä¸ƒã€æ€»ç»“ä¸å¯å‘

- DeepSpeed çš„ ZeRO æ˜¯ä¸€ç§é©å‘½æ€§çš„åˆ†å¸ƒå¼è®­ç»ƒæ€æƒ³ï¼Œé€šè¿‡æ˜¾å­˜åˆ†ç‰‡ï¼Œä½¿ç™¾äº¿çº§æ¨¡å‹èƒ½åœ¨æœ‰é™ GPU ä¸Šè®­ç»ƒã€‚
    
- ZeRO Stage 3 å¹¶æ²¡æœ‰æ”¹å˜æ•°æ®å¹¶è¡Œçš„æœ¬è´¨ï¼Œè€Œæ˜¯è®©â€œæ¯ä¸ª GPU æ‹¥æœ‰å®Œæ•´æ¨¡å‹â€è¿™ä»¶äº‹åœ¨æ˜¾å­˜å±‚é¢æ›´é«˜æ•ˆåœ°å®ç°ã€‚
    
- æ¨¡å‹å¹¶è¡Œå¼ºè°ƒè®¡ç®—åˆ‡åˆ†ï¼ŒZeRO å¼ºè°ƒçŠ¶æ€åˆ‡åˆ†ã€‚
    
- PyTorch çš„ FSDP æœ¬è´¨ä¸Šå°±æ˜¯ ZeRO Stage 3 çš„æ€æƒ³è½åœ°ã€‚
    

> **ç»“è®ºï¼š**
> 
> ZeRO Stage 3 æ˜¯ä¸€ç§â€œæ— å†—ä½™çš„æ•°æ®å¹¶è¡Œâ€ï¼Œè€Œä¸æ˜¯æ¨¡å‹å¹¶è¡Œã€‚  
> å®ƒä½¿æ•°æ®å¹¶è¡Œèƒ½å¤Ÿæ‰©å±•åˆ°åŸæœ¬åªæœ‰æ¨¡å‹å¹¶è¡Œæ‰èƒ½è®­ç»ƒçš„è§„æ¨¡ã€‚

---

## å‚è€ƒèµ„æ–™

[DeepSpeed å®˜æ–¹æ–‡æ¡£](https://www.deepspeed.ai/)

[Zero Redundancy Optimizer: Memory Efficiency in Data-Parallel Training](https://arxiv.org/abs/1910.02054)

[PyTorch Fully Sharded Data Parallel (FSDP)](https://pytorch.org/docs/stable/fsdp.html)

[Megatron-LM: Model Parallelism at Scale](https://arxiv.org/abs/1909.08053)
    
[ZeRO & DeepSpeed: New system optimizations enable training models with over 100 billion parameters - Microsoft Research](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)

