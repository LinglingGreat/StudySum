## NLP资料

### 在线课程

机器学习：
Stanford CS229 机器学习
Stanford CS246 数据挖掘 
资料链接:
http://sendanywhe.re/900QEJJZ

•  Dan Jurafsky 和 Chris Manning：自然语言处理[非常棒的视频介绍系列]

[https://www.youtube.com/watch?v=nfoudtpBV68&list=PL6397E4B26D00A269](http:)

•  斯坦福CS224d：自然语言处理的深度学习[更高级的机器学习算法、深度学习和NLP的神经网络架构]

[http://cs224d.stanford.edu/syllabus.html](http:)

•  Coursera：自然语言处理简介[由密西根大学提供的NLP课程]

[https://www.coursera.org/learn/natural-language-processing](http:)

多伦多大学三巨头，被誉为“深度学习之父“的Geoffrey Hinton教授在Coursera上的Neural Networks For Machine Learning网课。他的UT实验室在2012年的某医药大赛中如一匹黑马般赢得桂冠（即使整个团队没有一个人懂生物），真正地把深度学习带入了主流媒体的视线。链接： https://www.coursera.org/learn/neural-networks

斯坦福大学CS231n 卷积神经网络视觉识别课程，大数据文摘授权汉化教程链接： http://study.163.com/course/introduction/1003223001.htm

牛津大学与DeepMind合作的自然语言处理深度学习课程。链接： https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/

专门致力于为深度学习工程师提供教育资源的fast.ai。
链接： http://www.fast.ai/

Tensorflow提供的机器学习教程，分为两篇

初学者篇： https://www.tensorflow.org/get_started/mnist/beginners
进阶篇： https://www.tensorflow.org/get_started/mnist/pros

果壳网的 MOOC 学院，比如斯坦福的《编译原理》和 MIT 的《Python》

### 活跃的博客

•  自然语言处理博客（HalDaumé）

博客网址：[https://nlpers.blogspot.com/](http:)

•  Google研究博客

博客网址：[https://research.googleblog.com/](http:)

•  语言日志博客（Mark Liberman）

博客网址：[http://languagelog.ldc.upenn.edu/nll/](http:)

### 书籍

•  言语和语言处理（Daniel Jurafsky和James H. Martin）[经典的NLP教科书，涵盖了所有NLP的基础知识，第3版即将出版]

[https://web.stanford.edu/~jurafsky/slp3/](http:)

• 统计自然语言处理的基础（Chris Manning和HinrichSchütze）[更高级的统计NLP方法]

[https://nlp.stanford.edu/fsnlp/](http:)

•  信息检索简介（Chris Manning，Prabhakar Raghavan和HinrichSchütze）[关于排名/搜索的优秀参考书]

[https://nlp.stanford.edu/IR-book/](http:)

•  自然语言处理中的神经网络方法（Yoav Goldberg）[深入介绍NLP的NN方法，和相对应的入门书籍]

[https://www.amazon.com/Network-Methods-Natural-Language-Processing/dp/1627052984](http:)

入门书籍： http://u.cs.biu.ac.il/~yogo/nnlp.pdf

佛罗赞和莫沙拉夫的《计算机科学导论》，《穿越计算机的迷雾》。

### 其它杂项

•  如何在TensorFlow中构建word2vec模型[学习指南]

[https://www.tensorflow.org/versions/master/tutorials/word2vec/index.html](http:)

•  NLP深度学习的资源[按主题分类的关于深度学习的顶尖资源的概述]

[https://github.com/andrewt3000/dl4nlp](http:)

•  最后一句话：计算语言学和深度学习——论自然语言处理的重要性。（Chris Manning）[文章]

[http://mitp.nautil.us/article/170/last-words-computational-linguistics-and-deep-learning](http:)

•  对分布式表征的自然语言的理解（Kyunghyun Cho）[关于NLU的ML / NN方法的独立讲义]

[https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf](http:)

•  带泪水的贝叶斯推论（Kevin Knight）[教程工作簿]

[http://www.isi.edu/natural-language/people/bayes-with-tears.pdf](http:)

•  国际计算语言学协会（ACL）[期刊选集]

[http://aclanthology.info/](http:)

•  果壳问答网站(Quora)：我是如何学习自然语言处理的？

[https://www.quora.com/How-do-I-learn-Natural-Language-Processing](http:)

### DIY项目和数据集

资料来源：[http://gunshowcomic.com/](http:)

•  Nicolas Iderhoff已经创建了一份公开的、详尽的NLP数据集的列表。除了这些，这里还有一些项目，可以推荐给那些想要亲自动手实践的NLP新手们：

数据集：[https://github.com/niderhoff/nlp-datasets](http:)

•  基于隐马尔可夫模型（HMM）实现词性标注（POS tagging）.

[https://en.wikipedia.org/wiki/Part-of-speech_tagging](http:)

[https://en.wikipedia.org/wiki/Hidden_Markov_model](http:)

•  使用CYK算法执行上下文无关的语法解析

[https://en.wikipedia.org/wiki/CYK_algorithm](http:)

[https://en.wikipedia.org/wiki/Context-free_grammar](http:)

•  在文本集合中，计算给定两个单词之间的语义相似度，例如点互信息（PMI，Pointwise Mutual Information）

[https://en.wikipedia.org/wiki/Semantic_similarity](http:)

[https://en.wikipedia.org/wiki/Pointwise_mutual_information](http:)

•  使用朴素贝叶斯分类器来过滤垃圾邮件

[https://en.wikipedia.org/wiki/Naive_Bayes_classifier](http:)

[https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering](http:)

•  根据单词之间的编辑距离执行拼写检查

[https://en.wikipedia.org/wiki/Spell_checker](http:)

[https://en.wikipedia.org/wiki/Edit_distance](http:)

•  实现一个马尔科夫链文本生成器

[https://en.wikipedia.org/wiki/Markov_chain](http:)

•  使用LDA实现主题模型

[https://en.wikipedia.org/wiki/Topic_model](http:)

[https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation](http:)

•  使用word2vec从大型文本语料库，例如维基百科，生成单词嵌入。

[https://code.google.com/archive/p/word2vec/](http:)

[https://en.wikipedia.org/wiki/Wikipedia:Database_download](http:)

### NLP在社交媒体上

•  Twitter：#nlproc，NLPers上的文章列表（由Jason Baldrige提供）

[https://twitter.com/hashtag/nlproc](http:)

[https://twitter.com/jasonbaldridge/lists/nlpers](http:)

•  Reddit 社交新闻站点：/r/LanguageTechnology

[https://www.reddit.com/r/LanguageTechnology](http:)

•  Medium发布平台：Nlp

[https://medium.com/tag/nlp](http:)

原文链接：

[https://medium.com/towards-data-science/how-to-get-started-in-nlp-6a62aa4eaeff](http:)

### 其他

SQL：Leecode题目，尝试多种解法

Python：廖雪峰网站/pandas手册501页后（http://pandas.pydata.org/pandas-docs/stable/pandas.pdf），熟练掌握pandas、numpy等常用数据包


https://biendata.com/ 这个国内的NLP竞赛平台

https://www.kesci.com/home/workspace/competiton 和鲸

 https://github.com/yanqiangmiffy/NLP-Interview-Notes 闫强的NLP面试资料

https://github.com/yanqiangmiffy/quincy-python 闫强的Python资料



https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/

 https://blog.csdn.net/mr2zhang/article/details/90754134#Sequencetosequence_attentional_model_39 

 https://aistudio.baidu.com/aistudio/competition/detail/3  百度的问答比赛

 https://github.com/kmkurn/pytorch-crf  

 https://sm1les.com/2019/07/26/maximum-entropy-markov-model/ 文睿的博客


## **了解NLP的最基本知识**
Jurafsky和Martin的Speech and Language Processing是领域内的经典教材，里面包含了NLP的基础知识、语言学扫盲知识、基本任务以及解决思路。阅读此书会接触到很多NLP的最基本任务和知识，比如tagging, 各种parsing，coreference, semantic role labeling等等等等。这对于全局地了解NLP领域有着极其重要的意义。

Chris Manning 的 introduction to information retrieval 也是一本可以扫一下盲的书

## **了解早年经典的NLP模型以及论文**

## **了解机器学习的基本模型**

Pattern Recognition and Machine Learning

## **多看NLP其他子领域的论文**
MT，信息抽取，parsing，tagging，情感分析，MRC等等。

## **了解CV和data mining领域的基本重大进展**

NLP领域里面一些重要的文章其实或多或少借鉴了CV里面的思想，当然也同样出现CV借鉴NLP的情况。NLP神经网络可视化、可解释性的研究，时间上还是落后于CV里面对CNN的可视化。

因为跨领域不好懂，所以第一次推荐看tutorial, 如果有 sudo code 的tutorial那就更好了。另外看看扫盲课的视频，比如Stanford CS231n也是个好办法。另外，一个NLP组里面有一个很懂CV的人也很重要


## 参考资料

[初入NLP领域的一些小建议](https://zhuanlan.zhihu.com/p/59184256)