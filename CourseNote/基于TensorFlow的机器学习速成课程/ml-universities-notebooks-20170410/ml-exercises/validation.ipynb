{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbIgBK-oXHO7"
   },
   "source": [
    "# Validation\n",
    "In this exercise, we'll dive a bit more deeply into the training and evaluation of a model.\n",
    "\n",
    "As in the prior exercises, we're working with the California housing data set, to try and predict `median_house_value` at the city block level from 1990 census data.\n",
    "\n",
    "In this exercise, we'll use multiple features (instead of a single feature), and also get familiar with the train / validation / test split methodology.\n",
    "\n",
    "First off, let's load up and prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "california_housing_dataframe = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "# california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "#     np.random.permutation(california_housing_dataframe.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_features(california_housing_dataframe):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "  selected_features = california_housing_dataframe[\n",
    "    [\"latitude\",\n",
    "     \"longitude\",\n",
    "     \"housing_median_age\",\n",
    "     \"total_rooms\",\n",
    "     \"total_bedrooms\",\n",
    "     \"population\",\n",
    "     \"households\",\n",
    "     \"median_income\"]]\n",
    "  processed_features = selected_features.copy()\n",
    "  # Create a synthetic feature.\n",
    "  processed_features[\"rooms_per_person\"] = (\n",
    "    california_housing_dataframe[\"total_rooms\"] /\n",
    "    california_housing_dataframe[\"population\"])\n",
    "  return processed_features\n",
    "\n",
    "def preprocess_targets(california_housing_dataframe):\n",
    "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "  \"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  # Scale the target to be in units of thousands of dollars.\n",
    "  output_targets[\"median_house_value\"] = (\n",
    "    california_housing_dataframe[\"median_house_value\"] / 1000.0)\n",
    "  return output_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **training set**, we'll choose the first 12000 examples, out of the total of 17000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
    "training_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
    "training_targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **validation set**, we'll choose the last 5000 examples, out of the total of 17000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
    "validation_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
    "validation_targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3TZV1pgfZ1n"
   },
   "source": [
    "### Examine the data\n",
    "Okay, let's look at the data above. We have `9` input features that we can use.\n",
    "\n",
    "**Take a quick skim over the table of values. Do they pass a quick sanity check?**\n",
    "\n",
    "Take a look at the data on your own. Everything look okay? See how many issues you can spot. Don't worry if you don't have a background in statistics; common sense is often enough.\n",
    "\n",
    "After you've had a chance to look over the data yourself, check the solution for some additional thoughts on how to sanity check data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJIWKBdfsDjg"
   },
   "source": [
    "Let's take a close look at two features in particular: **`latitude`** and **`longitude`**. These are geographical coordinates of the city block in question.\n",
    "\n",
    "This might make a nice visualization â€” let's plot `latitude` and `longitude`, and use color to show the `median_house_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "5_LD23bJ06TW"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 8))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.set_title(\"Validation Data\")\n",
    "\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_ylim([32, 43])\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_xlim([-126, -112])\n",
    "plt.scatter(validation_examples[\"longitude\"],\n",
    "            validation_examples[\"latitude\"],\n",
    "            cmap=\"coolwarm\",\n",
    "            c=validation_targets[\"median_house_value\"] / validation_targets[\"median_house_value\"].max())\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.set_title(\"Training Data\")\n",
    "\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_ylim([32, 43])\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_xlim([-126, -112])\n",
    "plt.scatter(training_examples[\"longitude\"],\n",
    "            training_examples[\"latitude\"],\n",
    "            cmap=\"coolwarm\",\n",
    "            c=training_targets[\"median_house_value\"] / training_targets[\"median_house_value\"].max())\n",
    "_ = plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32_DbjnfXJlC"
   },
   "source": [
    "Wait a second ... this should have given us a nice map of the state of California, with red showing up in expensive areas like the San Francisco and Los Angeles.\n",
    "\n",
    "The training set sort of does, compared to a [real map](https://www.google.com/maps/place/California/@37.1870174,-123.7642688,6z/data=!3m1!4b1!4m2!3m1!1s0x808fb9fe5f285e3d:0x8b5109a227086f55), but the validation set clearly doesn't.\n",
    "\n",
    "**Go back up and look at the sanity check data again.**\n",
    "\n",
    "Do you see any other differences in the distributions of features or targets between the training and validation data?\n",
    "\n",
    "Check the solution to view the key issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "025Ky0Dq9ig0"
   },
   "source": [
    "### Task 1:  Go back up to the data importing and pre-processing code, and see if you spot any bugs there.\n",
    "If you do, go ahead and fix the bug. Don't spend more than a minute or two looking. If you can't find the bug, check the solution for a hint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFsd2eWHAMdy"
   },
   "source": [
    "When you've found and fixed the issue, re-run `latitude` / `longitude` plotting cell above and confirm that our sanity checks look better.\n",
    "\n",
    "By the way, there's an important lesson here.\n",
    "\n",
    "**Debugging in ML is often *data debugging* rather than code debugging.**\n",
    "\n",
    "If the data is wrong, even the most advanced ML code can't save things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCdqLpQyAos2"
   },
   "source": [
    "### Task 2: Train and evaluate a model.\n",
    "\n",
    "**Spend 5 minutes or so trying different hyperparameter settings.  Try to get the best validation performance you can.**\n",
    "\n",
    "Go ahead and write some code to set up a linear_regressor, using the `LinearRegressor` interface provided by the TensorFlow Estimators library.\n",
    "\n",
    "It's okay to use the code in the previous exercises, but you'll want to call `fit()` and `predict()` on the appropriate data sets.\n",
    "\n",
    "Using multiple input features instead of a single feature doesn't require anything special; the Estimators interface accepts Pandas `DataFrame` objects.\n",
    "\n",
    "If the `DataFrame` has multiple features defined (as ours does) these will all be used.\n",
    "\n",
    "Compare the losses on training data and validation data.\n",
    "\n",
    "With a single raw feature, our best root mean squared error (RMSE) was of about 180.\n",
    "\n",
    "See how much better you can do now that we can use multiple features.\n",
    "\n",
    "Use some of the sanity-checking methods we've looked at before.  These might include:\n",
    "\n",
    "   * comparing distributions of predictions and actual target values\n",
    "\n",
    "   * creating a scatter plot of predictions vs. target values\n",
    "\n",
    "   * creating two scatter plots of validation data using `latitude` and `longitude`:\n",
    "      * one plot mapping color to actual target `median_house_value`\n",
    "      * a second plot mapping color to predicted `median_house_value` for side-by-side comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UXt0_4ZTEf4V"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65sin-E5NmHN"
   },
   "source": [
    "### Task 3: Evaluate on test data.\n",
    "\n",
    "**In the cell below, load in the test data set and evaluate your model on it.**\n",
    "\n",
    "We've done a lot of iteration on our validation data.  Let's make sure we haven't overfit to the pecularities of that particular sample.\n",
    "\n",
    "Test data set is located [here](https://storage.googleapis.com/ml_universities/california_housing_test.csv).\n",
    "\n",
    "How does your test performance compare to the validation performance?  What does this say about the generalization performance of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "icEJIl5Vp51r"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "validation.ipynb",
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
