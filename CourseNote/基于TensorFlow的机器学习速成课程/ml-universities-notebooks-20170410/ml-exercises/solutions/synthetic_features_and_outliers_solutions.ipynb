{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Features and Outliers - Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn import learn_io\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "california_housing_dataframe = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, steps, batch_size, input_feature):\n",
    "  \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    input_feature: A `string` specifying a column from `california_housing_dataframe`\n",
    "      to use as input feature.\n",
    "      \n",
    "  Returns:\n",
    "    A Pandas `DataFrame` containing targets and the corresponding predictions done\n",
    "    after training the model.\n",
    "  \"\"\"\n",
    "  \n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  my_feature = input_feature\n",
    "  my_feature_column = california_housing_dataframe[[my_feature]].astype('float32')\n",
    "  my_label = \"median_house_value\"\n",
    "  targets = california_housing_dataframe[my_label].astype('float32')\n",
    "  \n",
    "  # Create input functions\n",
    "  training_input_fn = learn_io.pandas_input_fn(\n",
    "     x=my_feature_column, y=targets,\n",
    "     num_epochs=None, batch_size=batch_size)\n",
    "  predict_training_input_fn = learn_io.pandas_input_fn(\n",
    "     x=my_feature_column, y=targets,\n",
    "     num_epochs=1, shuffle=False)\n",
    "\n",
    "  # Create a linear regressor object.\n",
    "  feature_columns = [tf.contrib.layers.real_valued_column(my_feature)]\n",
    "  linear_regressor = tf.contrib.learn.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate),\n",
    "      gradient_clip_norm=5.0\n",
    "  )\n",
    "\n",
    "  # Set up to plot the state of our model's line each period.\n",
    "  plt.figure(figsize=(15, 6))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.title(\"Learned Line by Period\")\n",
    "  plt.ylabel(my_label)\n",
    "  plt.xlabel(my_feature)\n",
    "  sample = california_housing_dataframe.sample(n=300)\n",
    "  plt.scatter(sample[my_feature], sample[my_label])\n",
    "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print \"Training model...\"\n",
    "  print \"RMSE (on training data):\"\n",
    "  root_mean_squared_errors = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.fit(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period,\n",
    "    )\n",
    "    # Take a break and compute predictions.\n",
    "    predictions = list(linear_regressor.predict(input_fn=predict_training_input_fn))\n",
    "    # Compute loss.\n",
    "    root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(predictions, targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print \"  period %02d : %0.2f\" % (period, root_mean_squared_error)\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    root_mean_squared_errors.append(root_mean_squared_error)\n",
    "    # Finally, track the weights and biases over time.\n",
    "    # Apply some math to ensure that the data and line are plotted neatly.\n",
    "    y_extents = np.array([0, sample[my_label].max()])\n",
    "    x_extents = (y_extents - linear_regressor.bias_) / linear_regressor.weights_[0]\n",
    "    x_extents = np.maximum(np.minimum(x_extents,\n",
    "                                      sample[my_feature].max()),\n",
    "                           sample[my_feature].min())\n",
    "    y_extents = linear_regressor.weights_[0] * x_extents + linear_regressor.bias_\n",
    "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
    "  print \"Model training finished.\"\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.ylabel('RMSE')\n",
    "  plt.xlabel('Periods')\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(root_mean_squared_errors)\n",
    "\n",
    "  # Output a table with calibration data.\n",
    "  calibration_data = pd.DataFrame()\n",
    "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
    "  calibration_data[\"targets\"] = pd.Series(targets)\n",
    "  display.display(calibration_data.describe())\n",
    "\n",
    "  print \"Final RMSE (on training data): %0.2f\" % root_mean_squared_error\n",
    "  \n",
    "  return calibration_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe[\"rooms_per_person\"] = (\n",
    "    california_housing_dataframe[\"total_rooms\"] / california_housing_dataframe[\"population\"])\n",
    "\n",
    "calibration_data = train_model(\n",
    "    learning_rate=0.05,\n",
    "    steps=500,\n",
    "    batch_size=5,\n",
    "    input_feature=\"rooms_per_person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Task 2\n",
    "\n",
    "The calibration data shows most scatter points aligned to a line. The line is almost vertical, but we'll come back to that later. Right now let's focus on the ones that deviate from the line. We notice that they are relatively few in number.\n",
    "\n",
    "Plotting a histogram of `rooms_per_person` reveals that we have a few outliers in our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(calibration_data[\"predictions\"], calibration_data[\"targets\"])\n",
    "plt.subplot(1, 2, 2)\n",
    "_ = california_housing_dataframe[\"rooms_per_person\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Task 3\n",
    "\n",
    "The histogram at Task 2 shows that the majority of values are less than `5`. Let's also plot a histogram to double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe[\"rooms_per_person\"] = (\n",
    "    california_housing_dataframe[\"rooms_per_person\"]).apply(lambda x: min(x, 5))\n",
    "\n",
    "_ = california_housing_dataframe[\"rooms_per_person\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that clipping worked, let's train again and print the calibration data once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calibration_data = train_model(\n",
    "    learning_rate=0.05,\n",
    "    steps=500,\n",
    "    batch_size=5,\n",
    "    input_feature=\"rooms_per_person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(calibration_data[\"predictions\"], calibration_data[\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
