{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Crosses - Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "california_housing_dataframe = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_features(california_housing_dataframe):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "  selected_features = california_housing_dataframe[\n",
    "    [\"latitude\",\n",
    "     \"longitude\",\n",
    "     \"housing_median_age\",\n",
    "     \"total_rooms\",\n",
    "     \"total_bedrooms\",\n",
    "     \"population\",\n",
    "     \"households\",\n",
    "     \"median_income\"]]\n",
    "  processed_features = selected_features.copy()\n",
    "  # Create a synthetic feature.\n",
    "  processed_features[\"rooms_per_person\"] = (\n",
    "    california_housing_dataframe[\"total_rooms\"] /\n",
    "    california_housing_dataframe[\"population\"])\n",
    "  return processed_features\n",
    "\n",
    "def preprocess_targets(california_housing_dataframe):\n",
    "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "  \"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  # Scale the target to be in units of thousands of dollars.\n",
    "  output_targets[\"median_house_value\"] = (\n",
    "    california_housing_dataframe[\"median_house_value\"] / 1000.0)\n",
    "  return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
    "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
    "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
    "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_function(examples_df, targets_df, single_read=False):\n",
    "  \"\"\"Converts a pair of examples/targets `DataFrame`s to `Tensor`s.\n",
    "  \n",
    "  The `Tensor`s are reshaped to `(N,1)` where `N` is number of examples in the `DataFrame`s.\n",
    "  \n",
    "  Args:\n",
    "    examples_df: A `DataFrame` that contains the input features. All its columns will be\n",
    "      transformed into corresponding input feature `Tensor` objects.\n",
    "    targets_df: A `DataFrame` that contains a single column, the targets corresponding to\n",
    "      each example in `examples_df`.\n",
    "    single_read: A `bool` that indicates whether this function should stop after reading\n",
    "      through the dataset once. If `False`, the function will loop through the data set.\n",
    "      This stop mechanism is user by the estimator's `predict()` to limit the number of\n",
    "      values it reads.\n",
    "  Returns:\n",
    "    A tuple `(input_features, target_tensor)`:\n",
    "      input_features: A `dict` mapping string values (the column name of the feature) to\n",
    "        `Tensor`s (the actual values of the feature).\n",
    "      target_tensor: A `Tensor` representing the target values.\n",
    "  \"\"\"\n",
    "  features = {}\n",
    "  for column_name in examples_df.keys():\n",
    "    batch_tensor = tf.to_float(\n",
    "        tf.reshape(tf.constant(examples_df[column_name].values), [-1, 1]))\n",
    "    if single_read:\n",
    "      features[column_name] = tf.train.limit_epochs(batch_tensor, num_epochs=1)\n",
    "    else:\n",
    "      features[column_name] = batch_tensor\n",
    "  target_tensor = tf.to_float(\n",
    "      tf.reshape(tf.constant(targets_df[targets_df.keys()[0]].values), [-1, 1]))\n",
    "\n",
    "  return features, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    feature_columns,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    feature_columns: A `set` specifying the input feature columns to use.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearRegressor` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  # Create a linear regressor object.\n",
    "  linear_regressor = tf.contrib.learn.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=tf.train.FtrlOptimizer(learning_rate=learning_rate),\n",
    "      gradient_clip_norm=5.0\n",
    "  )\n",
    "  \n",
    "  training_input_function = lambda: input_function(\n",
    "      training_examples, training_targets)\n",
    "  training_input_function_for_predict = lambda: input_function(\n",
    "      training_examples, training_targets, single_read=True)\n",
    "  validation_input_function_for_predict = lambda: input_function(\n",
    "      validation_examples, validation_targets, single_read=True)\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print \"Training model...\"\n",
    "  print \"RMSE (on training data):\"\n",
    "  training_rmse = []\n",
    "  validation_rmse = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.fit(\n",
    "        input_fn=training_input_function,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    # Take a break and compute predictions.\n",
    "    training_predictions = list(linear_regressor.predict(\n",
    "        input_fn=training_input_function_for_predict))\n",
    "    validation_predictions = list(linear_regressor.predict(\n",
    "        input_fn=validation_input_function_for_predict))\n",
    "    # Compute training and validation loss.\n",
    "    training_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(training_predictions, training_targets))\n",
    "    validation_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print \"  period %02d : %0.2f\" % (period, training_root_mean_squared_error)\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_rmse.append(training_root_mean_squared_error)\n",
    "    validation_rmse.append(validation_root_mean_squared_error)\n",
    "  print \"Model training finished.\"\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"RMSE\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_rmse, label=\"training\")\n",
    "  plt.plot(validation_rmse, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longitude = tf.contrib.layers.real_valued_column(\"longitude\")\n",
    "latitude = tf.contrib.layers.real_valued_column(\"latitude\")\n",
    "housing_median_age = tf.contrib.layers.real_valued_column(\"housing_median_age\")\n",
    "households = tf.contrib.layers.real_valued_column(\"households\")\n",
    "median_income = tf.contrib.layers.real_valued_column(\"median_income\")\n",
    "rooms_per_person = tf.contrib.layers.real_valued_column(\"rooms_per_person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Task 1\n",
    "\n",
    "You may be wondering what is the best number of buckets to select. That is of course data-dependent. Here, we just selected arbitrary values so as to obtain a not-too-large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
    "  boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "  quantiles = feature_values.quantile(boundaries)\n",
    "  return [quantiles[q] for q in quantiles.keys()]\n",
    "\n",
    "bucketized_households = tf.contrib.layers.bucketized_column(\n",
    "  households, boundaries=get_quantile_based_boundaries(\n",
    "    california_housing_dataframe[\"households\"], 7))\n",
    "bucketized_longitude = tf.contrib.layers.bucketized_column(\n",
    "  longitude, boundaries=get_quantile_based_boundaries(\n",
    "    california_housing_dataframe[\"longitude\"], 10))\n",
    "bucketized_latitude = tf.contrib.layers.bucketized_column(\n",
    "  latitude, boundaries=get_quantile_based_boundaries(\n",
    "    training_examples[\"latitude\"], 10))\n",
    "bucketized_housing_median_age = tf.contrib.layers.bucketized_column(\n",
    "  housing_median_age, boundaries=get_quantile_based_boundaries(\n",
    "    training_examples[\"housing_median_age\"], 7))\n",
    "bucketized_median_income = tf.contrib.layers.bucketized_column(\n",
    "  median_income, boundaries=get_quantile_based_boundaries(\n",
    "    training_examples[\"median_income\"], 7))\n",
    "bucketized_rooms_per_person = tf.contrib.layers.bucketized_column(\n",
    "  rooms_per_person, boundaries=get_quantile_based_boundaries(\n",
    "    training_examples[\"rooms_per_person\"], 7))\n",
    "\n",
    "bucketized_feature_columns = set([\n",
    "  bucketized_longitude,\n",
    "  bucketized_latitude,\n",
    "  bucketized_housing_median_age,\n",
    "  bucketized_households,\n",
    "  bucketized_median_income,\n",
    "  bucketized_rooms_per_person])\n",
    "\n",
    "_ = train_model(\n",
    "    learning_rate=1.5,\n",
    "    steps=500,\n",
    "    feature_columns=bucketized_feature_columns,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Task 2\n",
    "\n",
    "We've added the cross to the previous list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_x_lat = tf.contrib.layers.crossed_column(\n",
    "  set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000)\n",
    "\n",
    "feature_columns_with_cross = set([\n",
    "  long_x_lat,\n",
    "  bucketized_longitude,\n",
    "  bucketized_latitude,\n",
    "  bucketized_housing_median_age,\n",
    "  bucketized_households,\n",
    "  bucketized_median_income,\n",
    "  bucketized_rooms_per_person])\n",
    "\n",
    "_ = train_model(\n",
    "    learning_rate=3.0,\n",
    "    steps=500,\n",
    "    feature_columns=feature_columns_with_cross,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
