---
title: 对话数据集整理
created: 2022-08-15
tags: [对话/数据集]

---


# 对话数据集整理

## 公开数据集

### Cantonese-Dialogue粤语

发布时间：

论文链接：

数据集链接：[stvlynn/Cantonese-Dialogue · Datasets at Hugging Face](https://huggingface.co/datasets/stvlynn/Cantonese-Dialogue)

数据集语言：中文粤语

数据集模态：文本

数据集描述：


### C3KG-中文常识对话知识图谱

发布时间：2022年

论文链接：[C3KG: A Chinese Commonsense Conversation Knowledge Graph](https://arxiv.org/abs/2204.02549 "C3KG: A Chinese Commonsense Conversation Knowledge Graph")

数据集链接：[https://github.com/xiaomi/c3kg](https://github.com/xiaomi/c3kg "https://github.com/xiaomi/c3kg")

数据集语言：中文

数据集模态：文本

数据集描述：该文章是小米AI实验室发表在ACL2022会议上的一篇论文，因为现有的常识知识库是以孤立的方式组织元组，这对于常识对话模型目标规划是不够的。 作者创建了第一个结合了社会常识知识和对话流信息的**中文常识对话知识图谱**。作者收集了日常场景中的大规模多轮对话， 并手动注释对话的情感信息。 基于这些标注信息，可以提取 ATOMIC（知识库） 中与对话相关的事件，并使用不同的对话流将它们连接起来。 通过这种用对话相关的知识来增强 ATOMIC，有助于聊天机器人挑选出有用的常识性知识，并丢弃掉那些对与对话流不相关的知识。

评论：质量还不错，可以用来做多轮对话的finetune

```text
[{"sens": "小许，你今天来的比平时晚呀？是身体不舒服吗？", "label": "others", "intent": "询问"}, {"sens": "呜呜，昨晚空调开的太低，一大早起来头就特别疼。", "label": "悲伤", "intent": "描述"}, {"sens": "怪不得我看你走路都摇摇晃晃的。吃过感冒药了吗？", "label": "others", "intent": "询问"}, {"sens": "吃过了，现在已经好多了，就是有点想睡觉。", "label": "others", "intent": "描述"}, {"sens": "唉，你说你，工作那么拼干嘛，生病了就休息一天吗？", "label": "others", "intent": "询问"}, {"sens": "没办法，生活所迫呀！", "label": "others", "intent": "others"}, {"sens": "为什么这么说？是家里面发生了什么事吗？", "label": "others", "intent": "询问"}, {"sens": "也没啥事，就是我弟弟已经到了适婚的年龄，我得为他攒点彩礼钱。", "label": "others", "intent": "描述"}, {"sens": "这也太不像话了吧！都已经成年了还不能承担起自己的责任吗？", "label": "生气", "intent": "观点"}, {"sens": "唉，他在家里面被爸妈娇生惯养惯了，没事的，我已经习惯了。", "label": "others", "intent": "描述"}, {"sens": "那好吧！家家有本难念的经，那你好好照顾自己。", "label": "others", "intent": "建议"}, {"sens": "好，今天的工作安排多吗？", "label": "others", "intent": "others"}, {"sens": "还好，就有一些琐事，我待会顺便帮你做了吧，你多休息会。", "label": "others", "intent": "建议"}, {"sens": "那真的是太感谢你了。", "label": "开心", "intent": "others"}, {"sens": "噢，突然想起来今天不是周三吗，我们还要参加一个例会。", "label": "others", "intent": "others"}, {"sens": "好好好，我知道了，到时候我和你们一起去。", "label": "others", "intent": "others"}]
```

### chatterbot\_corpus-多语言高质量翻译

发布时间：2018年

论文链接：无

数据集链接：[https://github.com/gunthercox/chatterbot-corpus](https://github.com/gunthercox/chatterbot-corpus "https://github.com/gunthercox/chatterbot-corpus")

数据集语言：多语言

数据集模态：文本

数据集描述：按类型领域分类，质量较高。多语言对话数据集。

评论：虽然数据质量较高，但是中文是翻译过来的（翻译的不是很好）

### CPED中文

发布时间：2022年

论文链接：[CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI](https://arxiv.org/pdf/2205.14727v1.pdf "CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI")

数据集链接：[https://github.com/scutcyr/CPED](https://github.com/scutcyr/CPED "https://github.com/scutcyr/CPED")

数据集语言：中文

数据集模态：视频、音频、文本

数据集描述：人类的语言表达是基于对情景的主观识解，而不是客观的真实条件，这意味着说话人的个性和情感经过认知处理后对会话有着重要的影响。为了在会话生成过程中同时考虑个性和情感，CPED由与情感和个性相关的多源知识组成。这些知识包括性别、大五人格特征、13种情绪、19种对话行为和10个场景，包含超过12K段对话，将给中文对话理解与生成领域提供一个更有挑战性的任务。任务设置见https\://paperswithcode.com/dataset/cped。

评论：数据来源于电视剧，会有很多人物名字，父母关于孩子的对话等

### Crosswoz-中文任务型

发布时间：2020年

论文链接：[CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset](https://arxiv.org/abs/2002.11893 "CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset")

数据集链接：[https://github.com/thu-coai/CrossWOZ](https://github.com/thu-coai/CrossWOZ "https://github.com/thu-coai/CrossWOZ")

数据集语言：中文

数据集模态：文本

数据集描述：2020年由清华大学人工智能研究院发布的CrossWOZ包含 6K 个对话，102K 个句子，涉及 5 个领域（景点、酒店、餐馆、地铁、出租）。平均每个对话涉及 3.2 个领域，远超之前的多领域对话数据集，增添了对话管理的难度。截至2020年，是第一个大规模中文对话数据集。可以用于研究任务型对话系统中各个方面，比如NLU、DST、对话策略学习、NLG都可以，也可以用于对话上下文补全的研究。

评论：适合任务型对话

### Diamante中文
发布时间：2022年

论文链接：Towards Boosting the Open-Domain Chatbot with Human Feedback

数据集链接：https://www.luge.ai/#/luge/dataDetail?id=52

数据集语言：中文

数据集模态：文本

数据集描述：

评论：

详细情况见[Diamante](Diamante/Diamante.md)

### daily_dialog英文

发布时间：

论文链接：

数据集链接：[https://huggingface.co/datasets/daily_dialog](https://huggingface.co/datasets/daily_dialog)

数据集语言：英文

数据集模态：文本

数据集描述：我们开发了一个高质量的多轮对话数据集 DailyDialog，它在几个方面都很有趣。该语言是人类编写的并且噪音较小。数据集中的对话反映了我们日常的交流方式，涵盖了我们日常生活的各种话题。我们还用沟通意图和情感信息手动标记开发的数据集。然后，我们评估 DailyDialog 数据集上的现有方法，并希望它有益于对话系统的研究领域。

```
This example was too long and was cropped:

{
    "act": [2, 1, 1, 1, 1, 2, 3, 2, 3, 4],
    "dialog": "[\"Good afternoon . This is Michelle Li speaking , calling on behalf of IBA . Is Mr Meng available at all ? \", \" This is Mr Meng ...",
    "emotion": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
}

```

### dialogsum英文

发布时间：

论文链接：

- **主页：** [https://aclanthology.org/2021.findings-acl.449](https://aclanthology.org/2021.findings-acl.449)
- **存储库：** [https://github.com/cylnlp/dialogsum](https://github.com/cylnlp/dialogsum)
- **论文：** [https://aclanthology.org/2021.findings-acl.449](https://aclanthology.org/2021.findings-acl.449)
- **联系方式：** [https://huggingface.co/knkarthick](https://huggingface.co/knkarthick)

数据集链接：[https://huggingface.co/datasets/daily_dialog](https://huggingface.co/datasets/daily_dialog)

数据集语言：英文

数据集模态：文本

数据集描述：

DialogSum 是一个大规模对话摘要数据集，由 13,460 个（加上用于生成主题的 100 个保留数据）对话以及相应的手动标记的摘要和主题组成。

数据实例

DialogSum 是一个大规模对话摘要数据集，由 13,460 个对话（+1000 个测试）组成，分为训练、测试和验证。训练集中的第一个实例：{'id': 'train_0', 'summary':“史密斯先生正在接受检查，霍金斯医生建议他每年进行一次检查。霍金斯会提供一些有关他们的信息帮助史密斯先生戒烟的课程和药物。", '对话': "#Person1#：嗨，史密斯先生。我是霍金斯医生，你今天为什么在这里？\n#Person2#：我发现会这样。 \n#Person1#：是的，你已经 5 年没有做过检查了。\n#Person2#：我知道。只要没有什么问题，为什么要去看医生呢？\n#Person1#：嗯，避免严重疾病的最好方法就是尽早发现，所以为了自己好，尽量每年至少去看一次。 \n#Person2#：好的。\n#Person1#：让我看看，你的眼睛和耳朵看起来都很好。史密斯先生，你抽烟吗？\n#Person2#：是的。 n#Person1#：吸烟是肺癌和心脏病的主要原因，你真的应该戒烟。\n#Person2#：我已经尝试了数百次，但我似乎就是戒不掉这个习惯。 .\n#Person1#：嗯，我们有课程和一些可能有帮助的药物。在你离开之前我会给你更多信息。\n#Person2#: 好的，谢谢医生。", 'topic': "去检查一下}

数据字段

- 对话：对话的文字。
- 摘要：人类书面的对话摘要。
- 主题：人类书面主题/对话的一句台词。
- id：示例的唯一文件 ID。

在论文中：我们从三个公共对话语料库中收集 DialogSum 的对话数据，即 Dailydialog (Li et al., 2017)、DREAM (Sun et al., 2019) 和 MuTual (Cui et al., 2019)，以及英语口语练习网站。这些数据集包含面对面的口语对话，涵盖广泛的日常生活主题，包括上学、工作、药物、购物、休闲、旅行。大多数对话发生在朋友、同事之间以及服务提供商和客户之间。

与之前的数据集相比，DialogSum 中的对话具有明显的特点：

丰富的现实场景下，包括更加多样化的任务场景；具有清晰的沟通模式和意图，对于作为摘要来源很有价值；有一个合理的长度，有利于自动摘要的目的。

我们要求注释者根据以下标准总结每个对话： 传达最重要的信息；简洁的;保留对话中重要的命名实体；从观察者的角度来写；用正式语言书写。

### 百度DuConv-中文知识对话

发布时间：2019年

论文链接：[Proactive Human-Machine Conversation with Explicit Conversation Goals](https://arxiv.org/abs/1906.05572 "Proactive Human-Machine Conversation with Explicit Conversation Goals")

数据集链接：[https://github.com/Cindy-xdZhang/ACL-duconv](https://github.com/Cindy-xdZhang/ACL-duconv "https://github.com/Cindy-xdZhang/ACL-duconv")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：[https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv](https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv "https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv")，给定一个对话目标 g 和一组与主题相关的背景知识，系统期望为当前对话输出一个话语，在给定目标的指导下保持对话的连贯性和信息量。在对话过程中，系统需要主动将对话从一个话题引导到另一个话题。对话目标g是这样给出的：“Start->Topic\_A->TOPIC\_B”，这意味着机器应该将对话从任何开始状态引导到主题A，然后到主题B。给定的背景知识包括与主题A相关的知识和主题B，以及这两个主题之间的关系。

评论：

### 百度DuLeMon中文

发布时间：2022年

论文链接：Long Time No See! Open-Domain Conversation with Long-Term Persona Memory

数据集链接： https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2022-DuLeMon 

数据集语言：中文

数据集模态：文本

数据集描述：长期记忆对话数据集，有人设，有

评论：

示例：

```
{
   "bot_persona":[
      "B1: 我 喜欢 做饭 ， 但是 不 爱 刷 碗",
      "B2: 我 喜欢 去 不同 的 国家 旅行",
      "B3: 我 25 岁"
   ],
   "user_said_persona":[
      "U1: 我 在 学校 的 图书馆 打工",
      "U2: 每次 有 机会 我 都 会 去 游泳",
      "U3: 我 喜欢 雪",
      "U4: 我 最 喜欢 的 演员 是 胡歌",
      "U5: 我 叫 曾鹏"
   ],
   "user_no_said_persona":[
      "U6: 我 在 上 大学"
   ],
   "conversation":[
      "Usr: 我 的 大学 生活 真 是 太 轻松 了 。",
      "Bot: 嗯嗯 ， 看起来 是 挺 轻松 的 。 你 还在 图书馆 里 打工 呢 。\tU1",
      "Usr: 是 的 ， 平时 也 没有 什么 事情 ， 闲 的 时间 很多 。",
      "Bot: 那 挺好 的 ， 你 也 有 很多 时间 去 游泳 了 。\tU2",
      "Usr: 是 呀 ， 我 现在 每天 过 的 都 很 充实 。",
      "Bot: 嗯嗯 ， 最近 胡歌 要 出演 电视 剧 了 ， 你 知道 吗 ？\tU4",
      "Usr: 当然 了 ， 我 可是 他的 铁粉 ， 他的 每个 电视 剧 我 都 会 看 。",
      "Bot: 我 也 很 喜欢 他 演 的 电视 ， 他的 演技 我 觉得 特别 好 。",
      "Usr: 是 的 。 每次 他 演 的 角色 都 很 能 打动 我 。",
      "Bot: 嗯嗯 ， 都 会 引起 很多 人 的 触动 。",
      "Usr: 对 的 ， 你 最近 在 干嘛 呀 ？",
      "Bot: 我 打算 去 不同 的 国家 旅行 ， 我 真 的 太 喜欢 出去 了 。\tB2",
      "Usr: 那 这 是 一 个 大 工程 呀 ， 也 得 具备 很多 钱 。",
      "Bot: 嗯嗯 ， 我 知道 。 我 也 在 为 之 付出 努力 认真 的 工作 呢 。",
      "Usr: 真好 呀 ， 为 自己 喜欢 的 事情 努力 也 会 很 有 动力 。",
      "Bot: 是 的 。"
   ]
}
```

### 百度DuRecDial-中文对话推荐

发布时间：2020年

论文链接：[Towards Conversational Recommendation over Multi-Type Dialogs](https://arxiv.org/pdf/2005.03954.pdf "Towards Conversational Recommendation over Multi-Type Dialogs")

数据集链接：[https://baidu-nlp.bj.bcebos.com/DuRecDial.zip](https://baidu-nlp.bj.bcebos.com/DuRecDial.zip "https://baidu-nlp.bj.bcebos.com/DuRecDial.zip")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：DuRecDial包含多种类型的对话(推荐对话、闲聊、任务导向对话和QA)，来自7个领域(电影、明星、音乐、新闻、食物、poi和天气)的10.2k对话，以及156K个utterances。DuRecDial是首个融合多种对话类型的对话推荐数据集，它包含多种对话类型、多领域和丰富对话逻辑(考虑用户实时反馈)。在每个对话中，推荐者(bot)使用丰富的交互行为主动引导一个多类型对话不断接近推荐目标。DuRecDial旨在考察模型是否可以在对话过程中基于用户兴趣以及用户的实时反馈，主动给用户做出合理的推荐。

评论：

### ECM(ESTC)-中文情感对话

发布时间：2018年

论文链接：[Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory](https://arxiv.org/abs/1704.01074 "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory")

数据集链接：[https://github.com/thu-coai/ecm](https://github.com/thu-coai/ecm "https://github.com/thu-coai/ecm")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：ECM是一个大规模的中文情感对话数据集，旨在考察模型是否可以在对话过程中充分利用情感信息，并生成具有正确情感倾向、且与上下文相关的对话回复。ESTC数据集是在STC数据集的基础上，使用一个训练好的文本情感分类器得到，通过文本情感分类器，自动标注了6类情感标签，常用于中文情感对话生成任务。

评论：单轮对话，感觉质量一般

### ESConv-英文情绪支持策略对话

发布时间：2021年

论文链接：[**Towards Emotional Support Dialog Systems**](https://arxiv.org/abs/2106.01144 "Towards Emotional Support Dialog Systems")

数据集链接：[https://github.com/thu-coai/Emotional-Support-Conversation](https://github.com/thu-coai/Emotional-Support-Conversation "https://github.com/thu-coai/Emotional-Support-Conversation")

数据集语言：英文

数据集模态：文本

数据集描述：标注语句的情绪支持策略

评论：

### empathetic_dialogues英文

发布时间：

论文链接：

数据集链接：[empathetic\_dialogues · Datasets at Hugging Face](https://huggingface.co/datasets/empathetic_dialogues)

数据集语言：英文

数据集模态：文本

数据集描述：PyTorch 迈向同理心开放域对话模型的原始实现：新的基准和数据集

- **下载的数据集文件大小：** 28.02 MB
- **生成的数据集大小：** 25.13 MB
- **使用的磁盘总量：** 53.15 MB

```
{
    "context": "sentimental",
    "conv_id": "hit:0_conv:1",
    "prompt": "I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.",
    "selfeval": "5|5|5_2|2|5",
    "speaker_idx": 1,
    "tags": "",
    "utterance": "I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.",
    "utterance_idx": 1
}

```


### KdConv-中文知识驱动对话

发布时间：

论文链接：[{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation](https://arxiv.org/abs/2004.04100 "{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation")

数据集链接：[https://github.com/thu-coai/KdConv](https://github.com/thu-coai/KdConv "https://github.com/thu-coai/KdConv")

数据集语言：中文

数据集模态：文本

数据集描述：KdConv是中文多领域知识驱动对话数据集。KdConv 包含来自**三个**领域（电影、音乐和旅行）的**4.5K**对话和**86K**话语，平均轮数为**19.0**。这些对话包含对相关主题的深入讨论和多个主题之间的自然过渡，同时语料库还可以用于探索迁移学习和领域适应。

评论：回复时会参考知识库进行回答

### KvPI-中文对话回复一致性

发布时间：2020年

论文链接：**Proﬁle Consistency Identiﬁcation for Open-domain Dialogue Agents**. [\[Paper\]](https://www.aclweb.org/anthology/2020.emnlp-main.539.pdf "\[Paper]")

数据集链接：[https://github.com/songhaoyu/KvPI](https://github.com/songhaoyu/KvPI "https://github.com/songhaoyu/KvPI")

数据集语言：中文

数据集模态：文本

数据集描述：一致性问题是当前开放域对话面临的主要问题之一。已有的研究工作主要探索了如何将属性信息融合到对话回复中，但是很少有人研究如何理解、识别对话系统的回复与其预设属性之间的一致性关系。为了研究这一问题，在这项工作中我们构建了一个大规模的人工标注数据集KvPI（Key-value Profile consistency Identification）。该数据集包含了超过11万组的单轮对话及其键值对属性信息，并且对回复和属性信息之间的一致性关系进行了人工标注。该数据集的一条基本数据元组包含了键值对角色信息，单轮对话输入-回复对，领域信息，人工抽取的对话回复角色信息以及人工标注的角色一致性标签。考虑数据收集以及公开信息等诸多因素，我们在角色信息中引入了性别、地点和星座三种常见的基本属性。

评论：单轮对话

### LCCC-large-中文综合数据

发布时间：2020年

论文链接：[A Large-Scale Chinese Short-Text Conversation Dataset](https://arxiv.org/abs/2008.03946 "A Large-Scale Chinese Short-Text Conversation Dataset")

数据集链接：[https://github.com/thu-coai/CDial-GPT](https://github.com/thu-coai/CDial-GPT "https://github.com/thu-coai/CDial-GPT")

数据集语言：中文

数据集模态：文本

数据集描述：LCCC-base 数据集中的原始对话数据来自于微博对话，LCCC-large 数据集中的原始对话数据在这些微博对话的基础上融合了其他开源对话数据集

| 数据集                                                                                                                       | 总对话轮次 | 对话示例                                                         |
| ------------------------------------------------------------------------------------------------------------------------- | ----- | ------------------------------------------------------------ |
| Weibo Corpus                                                                                                              | 79M   | Q:火锅我在重庆成都吃了七八顿火锅 A: 哈哈哈哈！那我的嘴巴 可能要烂掉！                       |
| [PTT Gossiping Corpus](https://github.com/zake7749/Gossiping-Chinese-Corpus "PTT Gossiping Corpus")                       | 0.4M  | Q:为什么乡民总是欺负国高中生呢QQ A:如果以为选好科系就会变成比尔盖兹那不如退学吧                  |
| [Subtitle Corpus](https://github.com/skdjfla/dgk_lost_conv "Subtitle Corpus")                                             | 2.74M | Q:京戏里头的人都是不自由的 A:他们让人拿笼子给套起来了了                               |
| [Xiaohuangji Corpus](https://github.com/skdjfla/dgk_lost_conv "Xiaohuangji Corpus")                                       | 0.45M | Q:你谈过恋爱么 A:谈过，哎，别提了，伤心..                                     |
| [Tieba Corpus](https://github.com/codemayq/chinese_chatbot_corpus "Tieba Corpus")                                         | 2.32M | Q:前排，鲁迷们都起床了吧 A:标题说助攻，但是看了那球，真是活生生的讽刺了                       |
| [Qingyun Corpus](https://github.com/codemayq/chinese_chatbot_corpus "Qingyun Corpus")                                     | 0.1M  | Q:看来你很爱钱 A:噢是吗？那么你也差不多了                                      |
| [Douban Conversation Corpus](https://github.com/MarkWuNLP/MultiTurnResponseSelection "Douban Conversation Corpus")        | 0.5M  | Q:看原版英文电影学纯正英语 A:大爱老友记反复看了好多次 了 Q:一样光盘都快被我看花了 A:那你现在的英语应该不错了 |
| [E-commerical Conversation Corpus](https://github.com/cooelf/DeepUtteranceAggregation "E-commerical Conversation Corpus") | 0.5M  | Q:这个会不会聚划算 A:暂时没有哦 Q:后期会不会有 A:不一定哦亲多多关注我们哦                   |
| [Chinese Chat Corpus](https://github.com/yangjianxin1/GPT2-chitchat "Chinese Chat Corpus")                                | 0.5M  | Q: 我今天腿都废了，你们过节，我搬砖 A: 辛苦啊，圣诞节还去赚大钱了加油 Q: 毕竟是没男朋友的人，什么节都是一样的 |

评论：

### LUGE-Dialogue-中文综合数据

发布时间：2021年

论文链接：

数据集链接：[https://www.luge.ai/#/luge/dataDetail?id=26](https://www.luge.ai/#/luge/dataDetail?id=26 "https://www.luge.ai/#/luge/dataDetail?id=26")

数据集语言：中文

数据集模态：文本

数据集描述：本数据集旨在全面评测基于统一生成模型建模不同对话技能的整体效果，包括内容丰富度，多轮连贯性，知识准确率，对话主动性。 

其中收集了一系列公开的开放域对话数据集，并对数据集进行了统一的整理以及提供了统一的评测方式，期望从多个技能、多个领域的角度对模型效果进行综合评价。该开源数据集旨在为研究人员和开发者提供学术和技术交流的平台，进一步提升开放域对话的研究水平，推动自然语言理解和人工智能领域技术的应用和发展。 

同时，我们还收集并提供了开源的中文对话数据，参赛队可以基于这些对话数据构建自己的对话模型： 

1.知识对话相关数据：百度的DuConv \[1]。

2.推荐对话相关数据：百度的DuRecDial \[2]。 

3.画像对话数据：百度的画像数据集(DuPersona)。 

4.其他对话数据：华为的微博数据 \[3] ，北航和微软的豆瓣多轮对话 \[4]，清华的LCCC数据集\[5]，清华情感对话数据\[6]，腾讯的检索辅助生成对话数据集 \[7] ，清华的KdConv \[8]。

| 对话技能名称 | 数据集                                | 训练集样例数量  | 开发集样例数量 | 测试集样例数量 | 单/多轮 | 领域                    |
| ------ | ---------------------------------- | -------- | ------- | ------- | ---- | --------------------- |
| 知识对话   | 百度DuConv                           | 19858    | 2000    | 5000    | 多轮   | 电影                    |
| 推荐对话   | 百度DuRecDial                        | 6618     | 946     | 4645    | 多轮   | 明星、电影、音乐、新闻、天气、美食、POI |
| 画像对话   | 百度画像数据集(Chinese Persona Chat, CPC) | 23000    | 1500    | 3000    | 多轮   | 开放域                   |
| 其他     | 微博数据                               | 3103764  | 1500    | 3000    | 多轮   | 开放域                   |
| 其他     | 豆瓣多轮对话                             | 500000   | 25001   | 1186    | 单轮   | 开放域                   |
| 其他     | 清华LCCC                             | 11987759 | 20000   | 10000   | 多轮   | 开放域                   |
| 其他     | 清华情感数据集                            | 899207   | 110000  | 110000  | 单轮   | 开放域                   |
| 其他     | 腾讯检索辅助生成对话数据集                      | 5498480  | 107332  | 156706  | 单轮   | 开放域                   |
| 其他     | 清华kdConv                           | 3000     | 300     | 2751    | 多轮   | 电影、音乐、旅游              |
## MagicData-中文

[MagicData-CLAM-Conversation\_CN - MagicHub](https://magichub.com/datasets/magicdata-clam-conversation_cn/)

“大模型多轮对话SFT数据集_中文”包含97184轮中文自然对话句子，涉及【家庭生活、教育医疗、军事战争、科学技术、气候环境、人文科学、商业经济、数码产品、体育竞技、休闲娱乐、衣食住行、艺术美术、政治法律、职业发展、宗教信仰】15个主题。

“大模型多轮对话SFT数据集_中文”源自真实的人类自然交谈。

![](img/Pasted%20image%2020241113111552.png)

![](img/Pasted%20image%2020241113111558.png)

### MedDialog-中英

发布时间：

论文链接：

数据集链接：[medical\_dialog · Datasets at Hugging Face](https://huggingface.co/datasets/medical_dialog)

数据集语言：中文，英文

数据集模态：文本

数据集描述：

MedDialog数据集（中文）包含医生和患者之间的对话（中文）。它有 110 万个对话和 400 万条话语。数据在不断增长，更多的对话将会被添加。原始对话来自haodf.com。所有数据版权归haodf.com所有。

MedDialog 数据集（英语）包含医生和患者之间的对话（英语）。它有26万个对话。数据在不断增长，更多的对话将会被添加。原始对话来自healthcaremagic.com 和icliniq.com。数据的所有版权均属于healthcaremagic.com和icliniq.com。

主页中提供了使用 PyTorch 使用 BERT 预训练模型的说明。

每次咨询包括以下内容：

- ID
- 网址
- 患者医疗状况的描述
- 对话
- （可选）诊断和建议。

```
{
{'dialogue_id': 2,
  'dialogue_turns': [{'speaker': '病人',
    'utterance': '孩子哭闹时，鸡鸡旁边会肿起，情绪平静时肿块会消失，去一个私人诊所看过，说是疝气.如果确定是疝气，是不是一定要手术治疗？我孩子只有1岁10月，自愈的可能性大吗？如果一定要手术，这么小的孩子风险大吗？术后的恢复困难吗？谢谢.'},
   {'speaker': '医生', 'utterance': '南方医的B超说得不清楚，可能是鞘膜积液，可到我医院复查一个B超。'}],
  'dialogue_url': 'https://www.haodf.com/doctorteam/flow_team_6477251152.htm',
  'file_name': '2020.txt'},
}

```

处理后的

```
{
  'description': 'throat a bit sore and want to get a good imune booster, especially in light of the virus. please advise. have not been in contact with nyone with the virus.',
  'utterances': [
    'patient: throat a bit sore and want to get a good imune booster, especially in light of the virus. please advise. have not been in contact with nyone with the virus.',
    "doctor: during this pandemic. throat pain can be from a strep throat infection (antibiotics needed), a cold or influenza or other virus, or from some other cause such as allergies or irritants. usually, a person sees the doctor (call first) if the sore throat is bothersome, recurrent, or doesn't go away quickly. covid-19 infections tend to have cough, whereas strep throat usually lacks cough but has more throat pain. (3/21/20)"
  ]
}

```

```
{
  'utterances': [
    '病人：强制性脊柱炎，晚上睡觉翻身时腰骶骨区域疼痛，其他身体任何部位均不疼痛。', 
    '医生：应该没有问题，但最好把图像上传看看。'
  ]
}

```
### MMChat-中文

发布时间：2022年

论文链接：**[MMChat: Multi-Modal Chat Dataset on Social Media](https://arxiv.org/abs/2108.07154)**

数据集链接：https://github.com/silverriver/MMChat

数据集语言：中文

数据集模态：图片-对话

数据集描述：

示例

![](img/Pasted%20image%2020220906143210.png)

### MDIA-多语言

发布时间：2022年

论文链接：MDIA: A Benchmark for Multilingual Dialogue Generation in 46 Languages

数据集链接： https://github.com/DoctorDream/mDIA

数据集语言：多语言

数据集模态：文本

数据集描述：


### 腾讯NaturalConv-中文

[NaturalConv](NaturalConv/NaturalConv.md)

发布时间：2021年

论文链接：[NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation](https://arxiv.org/pdf/2103.02548.pdf "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation")

数据集链接：[https://ai.tencent.com/ailab/nlp/dialogue/#datasets](https://ai.tencent.com/ailab/nlp/dialogue/#datasets "https://ai.tencent.com/ailab/nlp/dialogue/#datasets")，[https://github.com/naturalconv/NaturalConvDataSet](https://github.com/naturalconv/NaturalConvDataSet "https://github.com/naturalconv/NaturalConvDataSet")

数据集语言：中文

数据集模态：文本

数据集描述：NaturalConv是腾讯2021年发布的中文对话数据集，是基于话题驱动的中文对话生成。它更接近于类人对话，具有自然属性，包括场景假设、自由话题扩展、问候语等完整的自然环境。它包含约400K语句和19.9K对话，涉及多个领域（包括但不限于体育、娱乐、科技）。平均轮数为20，明显长于其他语料库。NaturalConv提供了一个评估在自然环境下生成对话能力的基准。该语料库不仅可以赋能未来基于文档的对话生成研究，还可以赋能不同场景下的对话风格和策略学习。

```text
{'dialog_id': '6499_1', 'document_id': 6499, 'content': ['你好！', '你好啊！', '你也是来看明星走红毯的嘛？', '对啊，我本来是来三亚旅游的，听说这里举办电影节，就想过来见见世面。', '那你可是来对了，这次可以说是众星云集，明星可以看到你想吐的。', '那我可要好好等等看完红毯仪式了，不知道有没有我的沈腾叔叔。', '这种级别的电影节肯定有他啊，再怎么说别人现在票房总量累计也是超过100亿的。', '我最开始喜欢他是从2012年春晚他的小品，“郝建”贱贱的小样子太好笑了。', '我也是他的粉丝，他每年春晚的小品的台词我都可以背出来，主要是太经典了。', '而且他现在在电影大荧幕里面表现的也不错，他们开心麻花出品的电影每一部都是精品。', '有句话不是说沈腾什么都不用干，就站在那里，你就想笑。', '哈哈哈，确实，他那张脸就会让人不由自主想笑，他一开口我就忍不住了。', '这次听说沈腾就是带着新作品过来的，不知道是什么类型的。', '我知道，他之前采访的时候说了，叫《全民狂欢》，应该也是一部喜剧电影。', '虽然也很期待，但还是希望能看到他能演演不同类型的电影和角色，毕竟在好的演员同类型也会看腻的。', '说的也对，我觉他可以试试都市剧，就演那种不着调的角色很适合他。话说你这次是来看那个明星的？', '我是来等迪丽热巴的，他可是我的女神，简直就是仙女下凡。', '我也觉得她长得很漂亮，特别是那双眼睛，很有灵气。', '啊，我的迪丽热巴来了，我的先过去了，拜拜。', '再见。']}
```

### no-robots-英文

发布时间：

论文链接：

数据集链接：[HuggingFaceH4/no\_robots · Datasets at Hugging Face](https://huggingface.co/datasets/HuggingFaceH4/no_robots)

数据集语言：英文

数据集模态：文本

数据集描述：

No Robots 是由熟练的人类注释者创建的包含 10,000 条指令和演示的高质量数据集。该数据可用于监督微调（SFT），使语言模型更好地遵循指令。 No Robots 是根据 OpenAI 的[InstructGPT 论文](https://huggingface.co/papers/2203.02155)中描述的指令数据集进行建模的，并且主要由以下类别的单轮指令组成：

![](img/Pasted%20image%2020240510114320.png)

```
{'prompt': 'Bunny is a chatbot that stutters, and acts timid and unsure of its answers.',
 'prompt_id': '2dc7ea89a2b6a2ed97d4eda07903162a801824261d3d3ae4dd2513db66fd79c8',
 'messages': [{'content': 'Bunny is a chatbot that stutters, and acts timid and unsure of its answers.',
   'role': 'system'},
  {'content': 'When was the Libary of Alexandria burned down?',
   'role': 'user'},
  {'content': "Umm, I-I think that was in 48 BC, b-but I'm not sure, I'm sorry.",
   'role': 'assistant'},
  {'content': 'Who is the founder of Coca-Cola?', 'role': 'user'},
  {'content': "D-don't quote me on this, but I- it might be John Pemberton.",
   'role': 'assistant'},
  {'content': "When did Loyle Carner's debut album come out, and what was its name?",
   'role': 'user'},
  {'content': "I-It could have b-been on the 20th January of 2017, and it might be called Yesterday's Gone, b-but I'm probably wrong.",
   'role': 'assistant'}],
 'category': 'Chat'}

```


### nus-sms-corpus-中英

发布时间：2015年

论文链接：[Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus](http://link.springer.com/article/10.1007/s10579-012-9197-9 "Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus")

数据集链接：[https://github.com/kite1988/nus-sms-corpus](https://github.com/kite1988/nus-sms-corpus "https://github.com/kite1988/nus-sms-corpus")

数据集语言：中文，英文

数据集模态：文本

数据集描述：这是在新加坡国立大学计算机科学系收集的用于研究的SMS（短消息服务）消息的语料库。 该数据集包括2015年3月9日从语料库中提取的67,093条SMS消息。 这些消息主要来自新加坡人，主要来自大学的学生。这些信息来自志愿者，他们知道他们的贡献将公之于众。 
数据收集器机会性地收集尽可能多的关于消息及其发送者的元数据，以便实现不同类型的分析。

### OpenSubData-多语言

发布时间：2009年

论文链接：[http://www.lrec-conf.org/proceedings/lrec2016/pdf/947\_Paper.pdf](http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf "http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf")

数据集链接：[http://nlp.stanford.edu/data/OpenSubData.tar](http://nlp.stanford.edu/data/OpenSubData.tar "http://nlp.stanford.edu/data/OpenSubData.tar")

数据集链接2：[https://opus.nlpl.eu/OpenSubtitles-v2018.php](https://opus.nlpl.eu/OpenSubtitles-v2018.php "https://opus.nlpl.eu/OpenSubtitles-v2018.php")

数据集语言：多语言（62种语言）

数据集模态：文本

数据集描述：OpenSubtitles主要用于开放域对话生成，包含2.6 billion语句。文件很大，读取方式[https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei\_dataset.py](https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei_dataset.py "https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei_dataset.py")

### M^3 ED-中文

发布时间：2022年

论文链接：[https://aclanthology.org/2022.acl-long.391/](https://aclanthology.org/2022.acl-long.391/ "https://aclanthology.org/2022.acl-long.391/")

数据集链接：[https://github.com/aim3-ruc/rucm3ed](https://github.com/aim3-ruc/rucm3ed "https://github.com/aim3-ruc/rucm3ed")

数据集语言：中文

数据集模态：视频、音频、文本

数据集描述：与MELD数据集类似，但其数据来源于56部电视剧，人物更加丰富。文章构建了一个大规模高质量的多模态、多场景、多标签情感对话数据集，从56部中文电视剧，大约500集中选取900多个对话片段，并对对话中的每句话进行多情感标签的标注，共标注24,449句话。文章采用主流的6类基本情感标注（高兴、惊讶、伤心、生气、厌恶，害怕）以及正常无明显情感，共7类离散情感。从数据来源选取，对话片段选取，情感标注，标注后处理等方面进行严格把控，以保证数据的质量，最终得到标注者间一致性0.59，高于MELD 的0.43、IEMOCAP的0.48 以及MSP-IMPROV 中的0.49。


### PchatbotW-中文

发布时间：2021年

论文链接：[https://arxiv.org/abs/2009.13284](https://arxiv.org/abs/2009.13284 "https://arxiv.org/abs/2009.13284")

数据集链接：[https://github.com/qhjqhj00/Pchatbot](https://github.com/qhjqhj00/Pchatbot "https://github.com/qhjqhj00/Pchatbot")

数据集语言：中文

数据集模态：文本

数据集描述：PchatbotW主要从微博爬取得到，包括了139,448,339个对话、 278,896,678，并且提供了时间戳和用户ID两种个性信息，可以隐式地建模说话者的个性。这是一个大规模的用于开发个性化对话模型的数据集。在这个数据集中，我们保留了匿名的用户ID和会话时间戳，可以检索用户的对话历史记录并用于建立丰富的用户个人资料。依据对话历史，我们可以让聊天机器人从历史对话中学习语言和语义信息，并根据所学知识生成个性化回复。Pchatbot有两个子集，名为PchatbotW(爬取微博数据构建)和PchatbotL(爬取司法论坛构建)。



### Persona-中文画像对话数据

发布时间：2020年

论文链接：

数据集链接：[https://www.luge.ai/#/luge/dataDetail?id=38](https://www.luge.ai/#/luge/dataDetail?id=38 "https://www.luge.ai/#/luge/dataDetail?id=38")

数据集语言：中文

数据集模态：文本

数据集描述：画像对话数据集，考察对话模型在闲聊场景中是否可以生成符合对话历史和画像信息，且自然流畅、信息丰富的机器回复。有人物画像的对话数据集。

```
{"p1_persona": ["我 喜欢 旅行", "最喜欢 的 颜色 是 绿色", "我 喜欢 汽车", "我 喜欢 猫"], "p2_persona": ["我 是 个 夜猫子", "我 有 一只 哈巴狗 ， 它 是 最 忠诚 的 动物", "我 住在 镇上 ， 附近 有 商店", "我 是 学 法律 的 研究生", "我 有时 喜欢 和 朋友们 在 公园 玩 飞盘"], "conversation": ["p1 : 你好 呀 。", "p2 : 你好 呀 ， 在 干 吗 呢 ？", "p1 : 我 在 给 我 的 小猫 喂食 呢 。", "p2 : 听 你 这么说 ， 你 喜欢 小猫 喽 ？", "p1 : 对 的 呀 ， 我 非常 喜欢 小猫 呢 ， 觉得 小猫 很可爱 。", "p2 : 我 也 觉得 小猫 很可爱 呢 ， 毛茸茸 的 呢 ， 特别 可爱 。", "p1 : 那 你 是 从事 什么 工作 的 呢 ？", "p2 : 我 是 一名 大学生 呢 。", "p1 : 那 你 学 的 是 什么 专业 呢 ？", "p2 : 我 学 的 是 法律 呢 ， 现在 正在 读 研究生 呢 。", "p1 : 哇塞 ， 那 你 的 知识 一定 很 渊博 啊 ？", "p2 : 是 的 呢 ， 我 学 了 很多 关于 法律 方面 的 知识 呢 。", "p1 : 那 你们 的 律师费 也 不 便宜 啊 ， 打 赢 一场 官司 需要 很多 律师费 呢 。", "p2 : 律师费 还行 吧 ， 那 要 看 什么 官司 呢 。", "p1 : 好 吧 ， 那 你 喜欢 运动 吗 ？", "p2 : 不 喜欢 ， 我 比较 懒 ， 不 喜欢 运动 。"]}
```

### PersonalDialog-中文

发布时间：2019年

论文链接：[https://arxiv.org/abs/1901.09672](https://arxiv.org/abs/1901.09672 "https://arxiv.org/abs/1901.09672")

数据集链接：[https://github.com/silverriver/PersonalDilaog](https://github.com/silverriver/PersonalDilaog "https://github.com/silverriver/PersonalDilaog")，
Please contact \[<zhengyinhe1@163.com>] for the PersonalDialog dataset，一部分在[https://huggingface.co/datasets/silver/personal\_dialog](https://huggingface.co/datasets/silver/personal_dialog "https://huggingface.co/datasets/silver/personal_dialog")

数据集语言：中文

数据集模态：文本

数据集描述：该数据集包括20.83M个对话、56.25M个句子，对于每个说话人，提供了5种个性特征(Age, Gender, Location, Interest, self descriptions)。

数据示例：https://huggingface.co/datasets/silver/personal_dialog

### PsyQA-中文心理健康支持问答数据

发布时间：

论文链接：[PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support](https://arxiv.org/abs/2106.01702 "PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support")

数据集链接：[https://github.com/thu-coai/PsyQA](https://github.com/thu-coai/PsyQA "https://github.com/thu-coai/PsyQA")，需要申请

数据集语言：中文

数据集模态：文本

数据集描述：一个用于生成心理健康支持长篇咨询文本的中文数据集，该数据集主要收集了壹心理社区的问答数据，标注了6种助人策略，总共包括了22346个问题以及56063个回复。

评论：

```text
{
"question": "去爱一个事事让着你的人，是一种不可能的期待吗？",
"description": "去爱一个事事让着你的人？有这样的人么？是一种不可能的期待么？",
"keywords": "恋爱,恋爱经营",
"answers": [
{
"answer_text": "你好，首先回答你关于有没有事事让着你的人，如果你真的去找这样的人还是基本上能够找到的，并不算是非常不可能的期待。在我的所见所谓中就看到过不止有一个这样的人。但你要说你还能去爱一个这样的人，那就太不容易了，就变成了比较困难的事情，为什么这样说，通常常见的情况是你爱的人不爱你，爱你的人你又不爱，所以常常难以两全。当然相爱的情况还是很多的，但相爱又要他事事让着你，唔，这就有点麻烦了。无论如何两个人在一起首先是两个相互独立的个体，总有一些自己不同于任何的需要和想法，因为爱，两个人会磨合会有拖鞋和退让，互相拉锯，关系才能保持平衡，如果是只有一方做完全的退让，关系就是失衡的，短暂的时间可以因为爱而维系，但长期关系是很难维持下去的。嗯，所以总结来说，你的期待有点理想化了。",
"has_label": true,
"labels_sequence": [
{
"start": 0,
"end": 78,
"type": "Interpretation"
},
{
"start": 78,
"end": 190,
"type": "Interpretation"
},
{
"start": 190,
"end": 313,
"type": "Interpretation"
},
{
"start": 313,
"end": 332,
"type": "Interpretation"
}
]
}
],
"questionID": 4394
}
```

### Retrieval\_Generation\_Chat\-tecent中文

发布时间：2019年

论文链接：[Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework](https://www.aclweb.org/anthology/D19-1195 "Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework")

数据集链接：[https://ai.tencent.com/ailab/nlp/dialogue/](https://ai.tencent.com/ailab/nlp/dialogue/ "https://ai.tencent.com/ailab/nlp/dialogue/")，[https://www.luge.ai/#/luge/dataDetail?id=36](https://www.luge.ai/#/luge/dataDetail?id=36 "https://www.luge.ai/#/luge/dataDetail?id=36")

数据集语言：中文

数据集模态：文本

数据集描述：Tencent是一个大规模的检索辅助生成的中文开放域对话数据集，旨在考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复。

评论：

```
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 合适 不|巨蟹座 太 强势 了
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 合适 么|觉得 不 合适 ~
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|巨蟹 和 白羊 合适 吗|这个 没试 过 , 还 真不知道 呢
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 不 和|为什么 不 和 ! ? 我 挺 喜欢 巨蟹 的
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹|白羊 和 巨蟹 , 有 希望 不 。 。 诶 。 貌似 白羊 比较 爱 天蝎 和 摩 羯 。 。 伤心 啦
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 不 和 吗|和 摩羯合 吗
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 巨蟹|觉得 巨蟹 男 还行 吧
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 。 。 巨蟹|讨厌 巨蟹座
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 巨蟹 。 巨蟹 白羊|东土 大唐 形象大使 发来 慰问 贺电
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 的 我 和 巨蟹 的 他|白羊 的 沙发

```

### soda-英文

发布时间：

论文链接：

数据集链接：[allenai/soda · Datasets at Hugging Face](https://huggingface.co/datasets/allenai/soda)

数据集语言：英文

数据集模态：文本

数据集描述：

SODA 是第一个公开的、百万规模的高质量对话数据集，涵盖广泛的社交互动。通过将知识图谱中的社会常识知识置于上下文中（Atomic10x；West 等人，2022），从 PLM 中提取对话（InstructGPT；Ouyang 等人，2022）。人类评估表明，SODA 中的对话比之前人类编写的数据集（例如 DailyDialog（Li 等人，2017）、BlendedSkillTalk（Smith 等人，2020））更加一致、具体和（令人惊讶）自然。此外，由于社会常识知识包含情绪反应（即 xReact `relation`），SODA 包括 385K 个对话，标记有 1.7K 种独特情绪，以及有关体验者和原因的信息，`PersonX`即`head`符号常识知识三元组中的事件。

为了创建🥤SODA，我们通过将社会常识知识置于情境中，从 InstructGPT 中提取对话，即分多个步骤添加上下文信息：(1) 从符号常识知识图中检索社会常识，(2) 将其转换为句子形式，(3)从句子中生成叙述，（4）从叙述中推断说话者，最后（5）基于叙述和说话者得出内容丰富的对话。将 PLM 锚定在常识知识中以导出对话具有两个关键优势：(1) 最大限度地减少无意义的对话；(2) 最大限度地提高多样性。欲了解更多详细信息，请参阅我们的[论文](https://arxiv.org/abs/2212.10465)。

![](img/Pasted%20image%2020240510114148.png)


### Scifi_TV_Shows-英文

发布时间：

论文链接：

数据集链接：[lara-martin/Scifi\_TV\_Shows · Datasets at Hugging Face](https://huggingface.co/datasets/lara-martin/Scifi_TV_Shows)

数据集语言：英文

数据集模态：文本

数据集描述：

从 Fandom.com 维基上抓取的长期运行（80 多集）科幻电视节目情节概要的集合。收集于 2017 年 11 月。每一集都被视为一个“故事”。

包含以下情节摘要：

- 巴比伦 5 ( [https://babylon5.fandom.com/wiki/Main_Page](https://babylon5.fandom.com/wiki/Main_Page) ) - 84 个故事
- 神秘博士 ( [https://tardis.fandom.com/wiki/Doctor_Who_Wiki](https://tardis.fandom.com/wiki/Doctor_Who_Wiki) ) - 311 个故事
- 神秘博士衍生作品 - 95 个故事
- Farscape ( [https://farscape.fandom.com/wiki/Farscape_Encyclopedia_Project:Main_Page](https://farscape.fandom.com/wiki/Farscape_Encyclopedia_Project:Main_Page) ) - 90 个故事
- 边缘 ( [https://fringe.fandom.com/wiki/FringeWiki](https://fringe.fandom.com/wiki/FringeWiki) ) - 87 个故事
- 飞出个未来 ( [https://futurama.fandom.com/wiki/Futurama_Wiki](https://futurama.fandom.com/wiki/Futurama_Wiki) ) - 87 个故事
- 星际之门 ( [https://stargate.fandom.com/wiki/Stargate_Wiki](https://stargate.fandom.com/wiki/Stargate_Wiki) ) - 351 个故事
- 星际迷航 ( [https://memory-alpha.fandom.com/wiki/Star_Trek](https://memory-alpha.fandom.com/wiki/Star_Trek) ) - 701 个故事
- 星球大战书籍 ( [https://starwars.fandom.com/wiki/Main_Page](https://starwars.fandom.com/wiki/Main_Page) ) - 205 个故事，每本书都是一个故事
- 星球大战义军崛起 ( [https://starwarsrebels.fandom.com/wiki/Main_page](https://starwarsrebels.fandom.com/wiki/Main_page) ) - 65 个故事
- X 档案 ( [https://x-files.fandom.com/wiki/Main_Page](https://x-files.fandom.com/wiki/Main_Page) ) - 200 个故事

总计：2276 个故事

数据集是“事件化”和概括的（参见 LJ Martin、P Ammanabrolu、X Wang、W Hancock、S Singh、B Harrison 和 MO Riedl。使用深度神经网络自动生成故事的事件表示，第 32 届 AAAI 人工智能会议（AAAI），2018。有关这些过程的详细信息。）并分成训练-测试-验证集（按故事分隔，以便完整的故事保持在一起），以便将事件转换为完整的句子。

```
Dataset({
    features: ['story_num', 'story_line', 'event', 'gen_event', 'sent', 'gen_sent', 'entities'],
    num_rows: 257108
})
```


### STC-中文

发布时间：2015年

论文链接：[https://www.aclweb.org/anthology/P15-1152/](https://www.aclweb.org/anthology/P15-1152/ "https://www.aclweb.org/anthology/P15-1152/")

数据集链接：[https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip](https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip "https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip")

数据集语言：中文

数据集模态：文本

数据集描述：STC是从微博爬取的语料构造的短文本对话(Short-Text Conversation)数据集，包含4.4 million个对话，。这里的数据集下载链接来自项目CDial-GPT。

### Stylistic-中文

发布时间：

论文链接：Stylistic Dialogue Generation via Information-Guided Reinforcement Learning Strategy

数据集链接：

数据集语言：中文

数据集模态：文本

数据集描述：单轮对话

评论：

### tv_dialogue-英文

发布时间：

论文链接：

数据集链接：[sedthh/tv\_dialogue · Datasets at Hugging Face](https://huggingface.co/datasets/sedthh/tv_dialogue)

数据集语言：英文

数据集模态：文本

数据集描述：

This dataset contains transcripts for famous movies and TV shows from multiple sources.

An example dialogue would be:

```
[PERSON 1] Hello
[PERSON 2] Hello Person 2!
How's it going?

(they are both talking)

[PERSON 1] I like being an example
on Huggingface!

They are examples on Huggingface.
CUT OUT TO ANOTHER SCENCE

We are somewhere else
[PERSON 1 (v.o)] I wonder where we are?
```

All dialogues were processed to follow this format. Each row is a single episode / movie (**2781** rows total) following the [OpenAssistant](https://open-assistant.io/) format. The METADATA column contains dditional information as a JSON string.

**Dialogue only, with some information on the scene**

|Show|Number of scripts|Via|Source|
|---|---|---|---|
|Friends|236 episodes|[https://github.com/emorynlp/character-mining](https://github.com/emorynlp/character-mining)|friends/emorynlp|
|The Office|186 episodes|[https://www.kaggle.com/datasets/nasirkhalid24/the-office-us-complete-dialoguetranscript](https://www.kaggle.com/datasets/nasirkhalid24/the-office-us-complete-dialoguetranscript)|office/nasirkhalid24|
|Marvel Cinematic Universe|18 movies|[https://www.kaggle.com/datasets/pdunton/marvel-cinematic-universe-dialogue](https://www.kaggle.com/datasets/pdunton/marvel-cinematic-universe-dialogue)|marvel/pdunton|
|Doctor Who|306 episodes|[https://www.kaggle.com/datasets/jeanmidev/doctor-who](https://www.kaggle.com/datasets/jeanmidev/doctor-who)|drwho/jeanmidev|
|Star Trek|708 episodes|[http://www.chakoteya.net/StarTrek/index.html](http://www.chakoteya.net/StarTrek/index.html) based on [https://github.com/GJBroughton/Star_Trek_Scripts/](https://github.com/GJBroughton/Star_Trek_Scripts/)|statrek/chakoteya|

**Actual transcripts with detailed information on the scenes**

|Show|Number of scripts|Via|Source|
|---|---|---|---|
|Top Movies|919 movies|[https://imsdb.com/](https://imsdb.com/)|imsdb|
|Top Movies|171 movies|[https://www.dailyscript.com/](https://www.dailyscript.com/)|dailyscript|
|Stargate SG-1|18 episodes|[https://imsdb.com/](https://imsdb.com/)|imsdb|
|South Park|129 episodes|[https://imsdb.com/](https://imsdb.com/)|imsdb|
|Knight Rider|80 episodes|[http://www.knightriderarchives.com/](http://www.knightriderarchives.com/)|knightriderarchives|

### Ubuntu对话语料库-英文

发布时间：

论文链接：

数据集链接：[https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886](https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886 "https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886")

数据集语言：英文

数据集模态：文本

数据集描述：Ubuntu对话语料库包括从Ubuntu聊天记录中提取的近一百万个两人对话，用于获得针对与Ubuntu相关的各种问题的技术支持。每次对话平均8轮，至少3轮。所有对话均以文本形式（而非音频）进行。

完整的数据集包含93万个对话和超过1亿个单词。该数据集包含分布在.csv文件中的该数据集的样本。该数据集包含超过2.69亿个单词的文本，分布超过了2600万圈。


## 未开放下载

### EVA数据集



## 模版

发布时间：

论文链接：

数据集链接：

数据集语言：中文

数据集模态：文本

数据集描述：

评论：

## 参考

[https://blog.csdn.net/m0\_37201243/article/details/120051649](https://blog.csdn.net/m0_37201243/article/details/120051649 "https://blog.csdn.net/m0_37201243/article/details/120051649")

[https://blog.csdn.net/Thanours/article/details/118368742](https://blog.csdn.net/Thanours/article/details/118368742 "https://blog.csdn.net/Thanours/article/details/118368742")

[https://www.luge.ai/#/](https://www.luge.ai/#/ "https://www.luge.ai/#/")
