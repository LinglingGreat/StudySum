---
title: T0
created: 2023-02-17
tags: 多任务 prompt
type: 论文
papername: Multitask Prompted Training Enables Zero-Shot Task Generalization
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2021
institution: 
---

## 论文基本信息

标题：Multitask Prompted Training Enables Zero-Shot Task Generalization   2021.10.15

**英文模型**

作者：

链接：

代码： https://huggingface.co/bigscience/T0     https://github.com/bigscience-workshop/t-zero

框架图：


![](img/Pasted%20image%2020230217152436.png)

建议使用[T0pp](https://huggingface.co/bigscience/T0pp)，因为它（平均）在各种 NLP 任务上带来最佳性能。

![](img/Pasted%20image%2020230217152637.png)

[为了可重复性，我们在P3 数据集中](https://huggingface.co/datasets/bigscience/P3)发布了用于训练（和评估）的数据。




### Motivation

T0和 FLAN 工作整体相似，区别是增加了任务和 prompt 数量，FLAN使用了decoder-only,T0使用了encoder+decoder，FLAN每次针对测试一个任务训练一个模型，其他任务作为训练集，T0为了测试模型泛化能力，只在多任务数据集上训练一个模型。证明了隐式多任务学习能提升模型泛化和zero-shot能力。

### Method

a.训练模型：11B LM-adapted T5 model---T5+LM

b.数据集：一共171 个多任务数据集，总共创建了 1939 个 prompt,平均每个数据集有11.3个prompt，共有来自8个国家、24家机构的36位人员贡献prompt。Prompt开发地址： https://github.com/bigscience-workshop/promptsource

c.评估方法：人工划分训练和测试集，Multiple-Choice QA、Summarization和Topic Classification等作为训练集，4个传统的nlp任务natural language inference、coreference、 word sense disambiguation、sentence completion和14个来自BIG-bench作为测试集，使用accuracy作为评估指标,和FLAN比没有做few-shot相关的实验。

d:训练方法：

对样本超过50k的数据集，采样500000 / num templates样本，其中num templates为数据集的template数量。学习率为1e-3，输入最大长度为1024，输出最大长度为256。

### Contribution

T0与GPT-3的Zero-shot性能对比，T0模型在11个数据上中有8个超越了GPT-3，而T0模型比GPT-3比小160倍，增加更多的prompt数量，会提升Zero-Shot泛化性能。相比FLAN模型参数减少超过10倍，在zero-shot场景下效果CB和RTE超过 FLAN，Winogrande和ANLI比FLAN稍差。



## 核心亮点

## 主要收获

## 参考资料

https://zhuanlan.zhihu.com/p/558286175    