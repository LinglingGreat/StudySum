---
title: LLaMA
created: 2023-02-27
tags: 大模型 语言模型
type: 论文
papername: LLaMA Open and Efficient Foundation Language Models
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2023
institution: MetaAI
---

## 论文基本信息

标题：LLaMA: Open and Efficient Foundation Language Models

作者：

链接：

代码： https://github.com/facebookresearch/llama

框架图：

LLaMA-13B的性能优于GPT-3，而体积却小了10倍以上，LLaMA-65B与Chinchilla-70B和PaLM-540B具有竞争性。

Meta表示，该模型在数以万亿计的token上进行训练，并表明有可能完全使用公开的数据集来训练最先进的模型，而不需要求助于专有的和不可获取的数据集。

Hoffmann等人（2022）最近的工作表明，在给定的计算预算下，最好的性能不是由最大的模型实现的，而是由在更多数据上训练的较小的模型实现的。

Hoff-mann等人（2022）的缩放定律的目标是确定如何在特定的训练计算预算下最佳地扩展数据集和模型大小。然而，这个目标忽略了推理预算，而推理预算在大规模服务语言模型时变得至关重要。

在这种情况下，给定一个目标性能水平，首选的模型不是训练速度最快的，而是推理速度最快的，尽管训练一个大的模型以达到一定的性能水平可能更便宜，但训练时间较长的小模型最终会在推理中更便宜。

例如，Hoffmann等人（2022年）曾建议在200B的token上训练一个10B的模型，但研究发现7B的模型的性能甚至在1T的token之后还能继续提高。

因此，该工作的重点是训练一系列语言模型，通过对比通常使用的更多的token进行训练，在不同的推理预算下达到最佳的性能。

### 数据

![](img/Pasted%20image%2020230227191345.png)

**1、英语CommonCrawl，占比67%**

由于CommonCraw数据较为杂乱，该工作采用CCNet pipleline的方式（Wenzek等人，2020）预处理了从2017年到2020年的CommonCrawl网页。

具体的，该工作首先在行的层面上对数据进行了删除，用fastText线性分类器进行语言识别，以去除非英语页面，并用n-gram语言模型过滤低质量内容。

其次，训练了一个线性模型来对维基百科中用作参考的页面与随机抽样的页面进行分类，并丢弃了未被归类为参考的页面。

**2、C4 ，占比15%**

在探索性实验中，该工作观察到，使用不同的预处理Com-monCrawl数据集可以提高性能。

因此，该工作将公开的C4数据集（Raffel等人，2020）也纳入我们的数据。

C4的预处理也包含重复数据删除和语言识别步骤，其与CCNet的主要区别在于质量过滤，它主要依赖于不存在的标点符号或网页中的单词和句子数量等判例。

**3、Github，占比4.5%**

在代码方面，该工作使用了谷歌BigQuery上的GitHub公共数据集，并只保留在Apache、BSD和MIT许可下发布的项目。

此外，为了提高数据质量，还用基于行长或字母数字字符比例的启发式方法过滤了低质量的文件，并用规范的表达式删除了如标题在内的模板化内容。

最后在文件层面上对结果数据集进行重复计算，并进行精确匹配。

**4、维基百科，占比4.5%**

该工作添加了2022年6月至8月期间的维基百科转储数据，涵盖20种语言，这些语言使用拉丁字母或西里尔字母，具体是：BG、CA、CS、DA、DE、EN、ES、FR、HR、HU、IT、NL、PL、UP、RO、RU、SL、SR、SV、UK。

此外，该工作对数据进行处理，以删除超链接、评论和其他格式化的模板。

**5、GutenbergProject和Books3，占比4.5%**

书籍也是重要的语料来源，该工作的训练数据集包括两个书籍语料库：古腾堡计划（GutenbergProject）和ThePile（Gao等人，2020）的Books3部分，后者是一个可用于训练大型语言模型的公开数据集。

在数据处理上，该工作在书的层面上进行了去重处理，删除了内容重叠度超过90%的书。

**6、ArXiv，占比2.5%**

科研文献对于提升专业性也有重要作用，该工作对arXiv的Latex文件进行处理，将科学数据添加到预训练数据集中。

按照Lewkowycz等人（2022年）的做法，该工作删除了第一节之前的所有内容以及书目。

此外，还删除了.tex文件中的评论，以及用户写的内联扩展定义和宏，以增加论文之间的一致性。

**7、Stack Exchange，占比2%**

QA数据对于提升垂直的专业问题也有帮助。

该工作还使用了Stack Exchange的开放数据，Stack Exchange是一个高质量的问题和答案的网站，涵盖了从计算机科学到化学的不同领域。

具体的，该工作保留了28个最大的网站的数据，从文本中去除HTML标签，并按分数（从高到低）对答案进行排序。

值得注意的是，我们将所有数字拆分为单个数字，并退回到字节来分解未知的UTF-8字符。

最后，在Tokenizer进行切分方面，该工作我们用bytepairencoding（BPE）算法（Sennrich等人，2015）对数据进行切分，并使用Sentence-Piece（Kudo和Richardson，2018）进行实现。值得注意的是，该将所有数字拆分为单个数字，并退回到字节来分解未知的UTF-8字符。

总的来说，我们的整个训练数据集在切分之后包含了大约1.4T的token。

另外，在数据采样方面，对于大多数训练数据，每个token在训练过程中只采样一次，但维基百科和图书领域除外，对这些领域进行了大约两个epochs。

### 训练细节：架构选择以及优化策略

**1、架构选择**

在架构选型上，该工作同样采用是Transformer架构（Vaswani等人，2017），并利用随后提出的各种改进，在不同的模型中进行使用，如PaLM。这里是与原始架构的主要区别主要包括：

**1）Pre-normalization  VS GPT3**

为了提高训练的稳定性，我们对每个变换子层的输入进行规范化，而不是对输出进行规范化。

并使用Zhang和Sennrich（2019）介绍的RMSNorm归一化函数。

**2）SwiGLU activation function VS PaLM**

采用SwiGLU激活函数取代由Shazeer（2020）介绍的ReLU非线性方法，以提高性能。此外，在维度上使用的维度是2/3\*4d，而不是PaLM中的4d。

**3）Rotary Embeddings  VS GPTNeo**

在位置编码上，删除了绝对位置嵌入，而在网络的每一层增加了Su等人（2021）介绍的旋转位置嵌入（RoPE）。


**2、Optimizer设计**

该模型使用AdamW优化器（Loshchilov和Hutter，2017）进行训练，超参数设置为β1=0.9，β2=0.95。

此外，使用余弦学习率方式，使最终学习率等于最大学习率的10%，并使用0.1的权重衰减和1.0的梯度剪裁。最并使用2,000个warm up策略，并根据模型的大小改变学习率和批次大小。


**3、 模型加速优化**

在模型训练加速方面，该工作进行了一些优化，以提高模型的训练速度。

首先，该工作使用了一个高效的因果多头注意力方式的实现，灵感来自Rabe和Staats（2021）以及Dao等人（2022），这个实现可在xformers库中找到，可以有效减少了内存的使用和计算。

具体原理为通过不存储注意力权重和不计算由于语言建模任务的因果性质而被掩盖的键/查询分数来实现的。

其次，为了进一步提高训练效率，减少了在check point的后向传递中重新计算的激活量，在实现上，通过手动实现transformer层的后向函数来进行操作。为了充分受益于这种优化，还通过如Korthikanti等人（2022）中采用的方法，进行使用模型和序列并行来减少模型的内存使用。

最后，该工作还尽可能地重叠激活的计算和GPU之间在网络上的通信。

因此，最终的优化性能效果为：当训练一个65B参数的模型时，代码在2048A100的GPU上处理大约380个token/秒/GPU，并耗费80GB的内存，这意味着对包含1.4Ttoken的数据集进行训练大约花费了21天。

### 实验结果分析：zero shot与few shot性能对比测试

zero-shot任务指的是提供了任务的文字描述和一个测试例子，该任务要么使用开放式生成提供一个答案，要么对提议的答案进行排序。

Few-shot任务指的是提供任务的几个例子（1到64个之间）和一个测试例子。该任务将这些文本作为输入，并生成答案或对不同的选项进行排序。

在模型对比上，将LLaMA与其他基础模型进行比较，包括：公开的语言模型GPT-3（Brown等人，2020）、Gopher（Rae）和Lauren等人。2020）、Gopher（Raeet al.，2021）、Chinchilla（Hoffmann等，2022）和PaLM（Chowdhery等，2022），以及开源的OPT模型（Zhang等，2022）、GPT-J（Wang和Komatsuzaki，2021）和GPTneo（Black等，2022）。

此外，该工作还简要比较了LLaMA与OPT-IML（Iyer等人，2022）和Flan-PaLM（Chung等人，2022）等指令微调模型。

**1、Common Sense Reasoning评测**

该工作选择了八个标准的常识推理基准：BoolQ（Clark等人，2019），PIQA（Bisk等人，2020），SIQA（Sap等人，2019），HellaSwag（Zellers等人，2019），WinoGrande（Sakaguchiet al.，2021），ARC easy and challenge（Clarket al.，2018）和OpenBookQA（Mihaylov等，2018）。

这些数据集包括Cloze和Winograd style的任务，以及多选题回答。

![](img/Pasted%20image%2020230228141613.png)

LLaMA-65B在所有报告的基准上都优于Chinchilla-70B，但BoolQ除外。

该模型除了在BoolQ和WinoGrande上，在其他地方都超过了PaLM-540B。

也就是说，LLaMA-13B模型在大多数基准上也超过了GPT-3，尽管它要小10倍。

**2、Closed-book Question Answering评测**

闭卷答题测评任务指的是闭卷情况下的精确匹配性能，即模型不能访问包含回答问题的证据的文件。

![](img/Pasted%20image%2020230228141708.png)

![](img/Pasted%20image%2020230228141731.png)

LLaMA-65B在0-shot和少数shot设置中都达到了最先进的性能。更重要的是，LLaMA-13B在这些基准测试中与GPT-3和Chinchilla相比也很有竞争力，尽管其体积小了5-10倍。

在推理过程中，该模型在单个V100 GPU上运行。

**3、Reading Comprehension评测**

RACE阅读理解评测指的是从为中国初中和高中学生设计的英语阅读理解考试

![](img/Pasted%20image%2020230228141759.png)

LLaMA-65B与PaLM-540B具有竞争力，LLaMA-13的性能比GPT-3好几个百分点。

**4、Mathematical reasoning评测**

为了验证模型的推理能力，该工作在两个数学推理基准上MATH（Hendrycks等人，2021）和GSM8k（Cobbe等人，2021）进行了测试。

其中，MATH是一个用LaTeX编写的12K初中和高中数学问题的数据集。GSM8k是一套初中数学问题。

![](img/Pasted%20image%2020230228141831.png)

Minerva是在从ArXiv和Math网页中提取的38.5B个符号上进行微调的一系列PaLM模型，而PaLM或LaMA都是在数学数据上进行微调的。

指标maj1@k表示对每个问题产生k个样本并进行多数投票的评价（Wanget al., 2022）。在GSM8k上，可以发现，尽管还没有在数学数据上进行微调，LLaMA-65B优于Minerva-62B。

**5、Code generation评测**

该工作在两个基准上评估了模型从自然语言描述中写入代码的能力，包括HumanEval（Chen等人，2021）和MBPP（Austin等人，2021）两个测评。

其中，在HumanEval测试中，它会收到一个函数签名，提示被格式化为自然码，并在docstring中提供文本描述和测试。该模型需要生成一个符合描述并满足测试案例的Python程序。

![](img/Pasted%20image%2020230228141915.png)
  
表8显示了当前模型与现有没有经过代码微调的语言模型，即PaLM和LaMDA（Thopilan等人，2022）的比较结果，其中：pass@1的结果通过温度为0.1的采样，pass@100和pass@80的指标通过温度为0.8时得到，性能如下：

对于类似的参数数量，LLaMA优于其他通用模型，如LaMDA和PaLM，它们没有专门针对代码进行训练或微调。

LLaMA在HumanEval和MBPP上以13B以上的参数优于LaMDA 137B。

即使它的训练时间更长，LLaMA 65B也优于PaLM 62B。

**6、Massive Multitask Language Understanding评测**

由Hendryckset al.（2020）介绍的大规模多任务语言理解基准，或称MMLU，由涵盖各种知识领域的多项选择题组成，包括人文、STEM和社会科学。

该工作在5-shot的环境中进行了模型评估，效果如，表9所示：

![](img/Pasted%20image%2020230228141950.png)

LLaMA-65B在大多数领域都比Chinchilla-70B和PaLM-540B平均落后几个百分点。

一个潜在的解释是，该模型在预训练数据中使用了有限的书籍和学术论文，即ArXiv、Gutenberg和Books3，总共只有177GB，而这些模型是在高达2TB的书籍上训练的。

因此，Gopher、Chinchilla和PaLM所使用的大量书籍可能也解释了为什么Gopher在这个基准上优于GPT-3，而在其他基准上却不相上下。

**7、Evolution of performance during training评测**

此外。该工作还跟踪了在训练过程中，模型在一些问题回答和常识性基准上的表现，并如图1、2所示：

![](img/Pasted%20image%2020230228143314.png)

![](img/Pasted%20image%2020230228143337.png)

在大多数基准上，性能很快就会提高，并与模型的训练困惑度相关。

不过，SIQA和WinoGrande很例外，最值得注意的是，在SIQA上，该工作发现很多性能上的差异，这可能表明这个基准并不可靠。

此外，在WinoGrande上，性能与训练困惑度的相关性不大：LLaMA-33B和LLaMA-65B在训练期间的性能相似。

### Instruction Finetuning下带来的性能测试

Instruction Finetuning的实验表明：

尽管非微调版本的LLaMA-65B已经能够遵循基本指令，但非常小的微调就能提高MMLU的性能，并进一步提高模型遵循指令的能力。

由于这不是本文的重点，该工作只进行了一次实验，在模型上采用与Chung等人（2022）相同的方法训练一个指令模型，得到LLaMA-I。

表10显示了微调模型LLaMA-I在MMLU评测上与现有的中等规模的指令微调模型，即OPT-IML（Iyer等人，2022）和Flan-PaLM系列（Chung等人，2022）的结果。

![](img/Pasted%20image%2020230228142052.png)

正如表中所示：

尽管这里使用的指令微调方法很简单，但该模型在MMLU上达到了68.9%。

LLaMA-I（65B）在MMLU上超过了现有的中等规模的指令微调模型，但离最先进的水平有较大的差距，即GPT代码-DAVINCI-002在MMLU上的表现为77.4%（数字取自Iyer等人（2022））。

### Bias, Toxicity and Misinformation上的分析测试

大型语言模型已被证明可以重现和放大训练数据中存在的偏见（Sheng等人，2019年；Kurita等人，2019年），并产生有毒或攻击性内容（Gehman等人，2020年）。

由于该模型训练数据集包含了很大一部分来自网络的数据，因此，评估模型产生这种内容的可能性是至关重要的。

为了了解LLaMA-65B的潜在危害，该工作在不同的基准上进行评估，这些基准衡量了有毒内容的产生和刻板印象的检测。

**1、RealToxicityPrompts毒性测试**

语言模型可以产生有毒的语言，例如，侮辱、仇恨言论或威胁。一个模型可以产生的有毒内容范围非常大，这使得彻底的评估具有挑战性。

最近的一些工作（Zhang等人，2022；Hoffmann等人，2022）已经考虑了RealToxicityPrompts基准（Gehman等人，2020）作为他们的模型的毒性指标。

RealToxicityPrompts由模型必须完成的大约10万个提示组，；然后通过向PerspectiveAPI 3提出请求来自动评估毒性分数。

但由于无法控制第三方PerspectiveAPI使用的流程，因此很难与以前的模型进行比较，所以仅进行了单一模型实验，每个提示的得分范围从0（无毒）到1（有毒），结果如表11所示：

![](img/Pasted%20image%2020230228143446.png)

可以看到，毒性随着模型的大小而增加，特别是对于尊重提示，这在以前的工作中也观察到了（Zhang等人，2022），但Hoffmann等人（2022）是个明显的例外，他们没有看到Chinchilla和Gopher之间的差异。  
不过，这可以解释为较大的模型Gopher的性能比Chinchilla差，这表明毒性和模型大小之间的关系可能只适用于一个模型系列。

**2、CrowS-Pairs社会偏见评测**

在偏见测试上，该工作在CrowSPairs（Nangia等人，2020）上进行了评估。

这个数据集允许测量9个类别的偏见：性别、宗教、种族/肤色、性取向、年龄、国籍、残疾、外貌和社会经济地位。

每个例子都由一个刻板印象和一个反刻板印象组成，该工作在zero-shot场景下使用两个句子的复杂度来衡量模型对刻板印象句子的偏好。

表12中显示了该模型与GPT-3和OPT-175B的对比结果：

![](img/Pasted%20image%2020230228143511.png)

从表中的结果我们发现，该模型与这两个模型相比，平均来说略胜一筹。

特别的，在宗教类别中特别有偏见（与OPT-175B相比+10），其次是年龄和性别（与最佳模型相比各+6）。

因此，从数据的角度上，可以发展，尽管有多个过滤步骤，预计这些偏见来自CommonCrawl，毕竟数据太杂了。

**3、WinoGender性别偏见评测**

为了进一步研究该模型在性别类别上的偏差，WinoGenderbenchmark（Rudinger等人，2018）数据集也作为了测评任务。

WinoGender是由Winogradschema构成的，通过确定模型的共同参考解决性能是否受到代词性别的影响来评估偏见。

更确切地说，每个句子有三个提及：一个 "职业"，一个 "参与者 "和一个 "代词"，其中代词是共同参考职业或参与者。

该任务要求该模型确定共同参照关系，并根据句子的上下文来衡量它是否正确，其目的是揭示与职业相关的社会偏见是否被模型所捕捉。

例如，WinoGender数据集中的一个句子是 "护士通知病人，他的班将在一小时后结束。"，后面的 "他的 "是指。然后，我们比较了护士和病人的连续性的困惑，用模型进行共同参考解决。

具体的，该工作评估了使用3个代词时的表现："her/her/she"，"his/him/he "和 "they/them/someone"（不同的选择对应于代词的语法功能。

在表13显示了数据集中包含的三个不同代词的共同参考得分。

![](img/Pasted%20image%2020230228143548.png)

可以看到，该模型在解决 "他们/他们/某人 "代词的共同参照方面明显优于 "她/她/他 "和 "他/他/他 "代词，这在以前的工作中也有类似的观察（Raeet al., 2021; Hoffmann et al., 2022），这可能是性别偏见的表现。

事实上，在 "她/他 "和 "他/他 "代词的情况下，模型可能使用职业的多数性别来进行共同参考解析，而不是使用句子的证据。

为了进一步研究这一假设，该工作研究了WinoGender数据库中 "她/他 "和 "他/他 "代词的 "疑难 "案例。这些情况对应于代词与职业的多数性别不匹配的句子，而职业是正确答案。

进一步的，我们发现，LLaMA-65B在有问题的例子上犯了更多的错误，清楚地表明它捕捉到了与性别和职业有关的社会偏见。"她/她/她 "和 "他/他 "代词的性能下降，这表明了与性别无关的偏见。

**4、TruthfulQA可信度评测**

TruthfulQA（Lin等人，2021）旨在衡量一个模型的真实性，即它识别一个主张是真的能力。

Lin等人（2021）认为 "真实 "的定义是指 "关于现实世界的字面意义上的真实"，而不是指在信仰体系或传统背景下才是真实的主张。这些问题以不同的风格写成，涵盖了38个类别，并被设计成对抗性的。

表14显示了该模型在这两个问题上的表现，以衡量真实的模型和真实与信息的交集。

![](img/Pasted%20image%2020230228143614.png)

如上表所示：与GPT-3相比，模型在这两个类别中得分较高，但正确答案的比率仍然很低，这表明我们的模型很可能会产生幻觉的错误答案。【这是大模型的一个通病】




## 核心亮点

## 主要收获

## 参考资料

[LLaMA论文研读｜小参数+大数据的开放、高效基础语言模型阅读笔记](https://hub.baai.ac.cn/view/24440)

