---
title: ORPO
created: 2024-06-15
tags:
  - alignment
type: è®ºæ–‡
papername: 
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 
institution:
---

## è®ºæ–‡åŸºæœ¬ä¿¡æ¯

æ ‡é¢˜ï¼š

ä½œè€…ï¼š

é“¾æ¥ï¼š

ä»£ç ï¼š

æ¡†æ¶å›¾ï¼š


## èƒŒæ™¯

ä¸ç®¡æ˜¯å“ªç§ DPOï¼Œé™¤äº† policy model å¤–ï¼Œéƒ½è¿˜æœ‰ä¸€ä¸ª reference modelï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½æŠŠ ref_model ä¹Ÿå¹²æ‰ã€‚

å›æƒ³ä¸€ä¸‹ï¼Œåœ¨ DPOP ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ ref_model æ¥ä¿è¯æ¨¡å‹åœ¨ chosen ä¸Šçš„æ¦‚ç‡ä¸è¦è¿‡ä½ï¼Œ

å¦‚æœåªæ˜¯ä¸ºäº†ä¿è¯æ¨¡å‹èƒ½å¤Ÿæ‹Ÿåˆ chosen ç­”æ¡ˆï¼Œé‚£æˆ‘ä»¬æ˜¯ä¸æ˜¯ç›´æ¥æŠŠ chosen ç­”æ¡ˆæ‹¿å‡ºæ¥åš SFT å°±å¥½ï¼Œ

è¿™ä¸å°±ä¸éœ€è¦ ref_model æ¥å—ï¼Ÿ

[[ORPO](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2403.07691)] çš„ç›®æ ‡å‡½æ•°ä¸€å…±ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼ˆSFT Loss + Odds Ratio Lossï¼‰ï¼š

![](img/Pasted%20image%2020240615171020.png)

å…¶ä¸­ SFT Loss å°±æ˜¯æ‹¿ chosen ç­”æ¡ˆç®— CrossEntropy Lossï¼Œè¿™å¾ˆå¥½ç†è§£ï¼Œå‰©ä¸‹çš„å°±æ˜¯è¿™ä¸ª Odds Ratio æ˜¯ä»€ä¹ˆã€‚

åœ¨ç»Ÿè®¡å­¦å’Œæ¦‚ç‡è®ºä¸­ï¼Œodds æŒ‡çš„æ˜¯ã€ŒæŸäº‹ä»¶å‘ç”Ÿä¸ä¸å‘ç”Ÿçš„æ¯”ä¾‹ã€ï¼Œ

æ¯”å¦‚ï¼Œå¦‚æœä¸€ä»¶äº‹æƒ…å‘ç”Ÿçš„æ¦‚ç‡æ˜¯Â ğ‘ï¼Œé‚£ä¹ˆå®ƒä¸å‘ç”Ÿçš„æ¦‚ç‡å°±æ˜¯Â 1âˆ’ğ‘ï¼Œå…¶ odds è®¡ç®—å…¬å¼å°±ä¸ºï¼š

![](img/Pasted%20image%2020240615171039.png)

å½“ä¸€ä»¶äº‹æƒ…çš„å‘ç”Ÿæ¦‚ç‡è¶Šå¤§ï¼Œå…¶å¯¹åº”çš„ odds å€¼å°±è¶Šå¤§ã€‚

çŸ¥é“ odds çš„æ¦‚å¿µåï¼Œæˆ‘ä»¬å†ä¸€èµ·ä¸Šè¿° loss function çš„ååŠéƒ¨åˆ†Â ğ¿ğ‘‚ğ‘…Â çš„å®šä¹‰ï¼š

![](img/Pasted%20image%2020240615171055.png)

é€šè¿‡ minimize è¿™ä¸ª loss å€¼ï¼Œæˆ‘ä»¬å°±éœ€è¦ maximize æ‹¬å·å†…çš„å€¼ï¼Œ**ä¹Ÿå°±æ˜¯å°½å¯èƒ½çš„è®©ã€Œå¥½å¥å­ã€å‘ç”Ÿçš„æ¦‚ç‡å¢å¤§ï¼Œã€Œåå¥å­ã€å‘ç”Ÿçš„æ¦‚ç‡å‡å°**ã€‚

ç”±æ­¤å¯è§ï¼Œ**ORPO é€šè¿‡å®šä¹‰äº†ä¸€ä¸ªç¥å¥‡çš„ odds å€¼æ¥æå‡å¥½æ ·æœ¬çš„æ¦‚ç‡ï¼Œé™ä½åæ ·æœ¬çš„æ¦‚ç‡ï¼Œå¹¶é€šè¿‡ä¸€ä¸ª SFT loss æ¥ä¿è¯æ¨¡å‹å¯¹ chosen response çš„åŸºæœ¬æ‹Ÿåˆ**ã€‚

[[æºç ](https://link.zhihu.com/?target=https%3A//github.com/huggingface/trl/blob/main/trl/trainer/orpo_trainer.py%23L667)] ä¸­å¯¹ odds_ratio çš„è®¡ç®—å¦‚ä¸‹ï¼š

```python
def odds_ratio_loss(
        self,
        policy_chosen_logps,
        policy_rejected_logps,
    ):
        """Compute ORPO's odds ratio (OR) loss for a batch of policy and reference model log probabilities.

        Args:
            policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)
            policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)

        Returns:
            A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).
            The losses tensor contains the ORPO loss for each example in the batch.
            The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.
            The log odds ratio of the chosen responses over the rejected responses ratio for logging purposes.
            The `log(sigmoid(log_odds_chosen))` for logging purposes.
        """
        # Derived from Eqs. (4) and (7) from https://arxiv.org/abs/2403.07691 by using 
        # log identities and exp(log(P(y|x)) = P(y|x)
        log_odds = (
            policy_chosen_logps - policy_rejected_logps
            ) - (
            torch.log1p(-torch.exp(policy_chosen_logps)) - 
            torch.log1p(-torch.exp(policy_rejected_logps))
        )
        sig_ratio = F.sigmoid(log_odds)
        ratio = torch.log(sig_ratio)
        losses = self.beta * ratio
        return losses
```


## ç›¸å…³ç ”ç©¶
æœ‰å“ªäº›ç›¸å…³ç ”ç©¶ï¼Ÿå¦‚ä½•å½’ç±»ï¼Ÿè°æ˜¯è¿™ä¸€è¯¾é¢˜åœ¨é¢†åŸŸå†…å€¼å¾—å…³æ³¨çš„ç ”ç©¶å‘˜ï¼Ÿ



## æ ¸å¿ƒäº®ç‚¹



## å®éªŒ
è®ºæ–‡ä¸­çš„å®éªŒæ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿ

ç”¨äºå®šé‡è¯„ä¼°çš„æ•°æ®é›†æ˜¯ä»€ä¹ˆï¼Ÿä»£ç æœ‰æ²¡æœ‰å¼€æºï¼Ÿ

è®ºæ–‡ä¸­çš„å®éªŒåŠç»“æœæœ‰æ²¡æœ‰å¾ˆå¥½åœ°æ”¯æŒéœ€è¦éªŒè¯çš„ç§‘å­¦å‡è®¾ï¼Ÿ



## æœªæ¥æ–¹å‘



## ä¸»è¦æ”¶è·


## å‚è€ƒèµ„æ–™
