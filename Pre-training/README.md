

## 现有大模型

![](img/Pasted%20image%2020230227103950.png)



[LLMs](LLMs/README.md)

## Prompt
- [ ] todo


## Instruction tuning

[Flan-PaLM_T5](Flan-PaLM_T5/Flan-PaLM_T5.md)


## CoT

总结：[CoT](CoT/CoT.md)


[Why did all of the public reproduction of GPT-3 fail? In which tasks should we use GPT-3.5/ChatGPT?](https://jingfengyang.github.io/gpt)

## Benchmark

[Benchmark](Benchmark/README.md)

## dataset




## 资源列表汇总

【收集了有关大型语言模型中不确定性、可靠性和鲁棒性的资源和论文】: github.com/jxzhangjhu/Awesome-LLM-Uncertainty-Reliability-Robustnes

【收集和梳理垂直领域的开源模型、数据集及评测基准】： [GitHub - luban-agi/Awesome-Domain-LLM: 收集和梳理垂直领域的开源模型、数据集及评测基准。](https://github.com/luban-agi/Awesome-Domain-LLM)

【LLM的评测有关的工具、demo、论文、文档】： [GitHub - onejune2018/Awesome-LLM-Eval: Awesome-LLM-Eval: a curated list of tools, demos, papers, docs for Evaluation on Large Language Models like ChatGPT, LLaMA, GLM](https://github.com/onejune2018/Awesome-LLM-Eval)

【'Xwin-LM：旨在开发并开源大型语言模型的对齐技术，包括监督微调(SFT)、奖励模型(RM)、拒绝采样、人类反馈强化学习(RLHF)等】’Xwin-LM: a collection of LLM alignment technologies and models' GitHub: github.com/Xwin-LM/Xwin-LM

领域大模型： [GitHub - luban-agi/Awesome-Domain-LLM: 收集和梳理垂直领域的开源模型、数据集及评测基准。](https://github.com/luban-agi/Awesome-Domain-LLM)




## 训练情况对比

baichuan1:

baichuan2: 2.6T tokens

qwen

llama

