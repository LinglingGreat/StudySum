

## 现有大模型

![](img/Pasted%20image%2020230227103950.png)



[LLMs](LLMs/README.md)

## Prompt
- [ ] todo


## Instruction tuning

[Flan-PaLM_T5](Flan-PaLM_T5/Flan-PaLM_T5.md)


## CoT

总结：[CoT](CoT/CoT.md)


[Why did all of the public reproduction of GPT-3 fail? In which tasks should we use GPT-3.5/ChatGPT?](https://jingfengyang.github.io/gpt)

## Benchmark

[Benchmark](Benchmark/README.md)

## dataset




## 资源列表汇总

【收集了有关大型语言模型中不确定性、可靠性和鲁棒性的资源和论文】: github.com/jxzhangjhu/Awesome-LLM-Uncertainty-Reliability-Robustnes

