简单总结来说：

-   大量文本数据（万亿级别 token 数量）做预训练：语言生成能力，基础的世界知识，in context learning 的基础。
-   足够大的模型规模（千亿级别参数）：大量知识的记忆与获取能力。
-   在代码数据上训练：复杂推理能力，长距离依赖关系的学习。这也是最令人着迷的一点。
-   有监督的指令微调：响应人类问题并泛化到没有见过的问题（zero-shot）上。减弱了 in context learning 的能力。
-   RLHF：总体让回答更加丰富具体，也增强了与人类期望的一致性（zero-shot，价值观，内容安全，避免胡说），但会降低模型在任务上的性能。比较有意思的是都用了 RLHF，text-003 模型也跟 ChatGPT 有不同的能力侧重，可惜目前没有论文透露其中的细节。

  在多种语言上做了预训练后，只要教某一个语言的某种任务，自动学习其它语言的同样任务。——Multi-BERT(在104个语言上预训练)

## 未来方向

1. 如何精准的提出需求

![](img/Pasted%20image%2020230227214915.png)

2. 如何更正错误

预训练语料只到2021年

![](img/Pasted%20image%2020230227215114.png)

![](img/Pasted%20image%2020230227215157.png)

3. 检测是否AI生成

4. 不小心泄漏秘密、隐私

![](img/Pasted%20image%2020230227215539.png)



## 资源集锦

https://github.com/cedrickchee/chatgpt-universe

https://zhuanlan.zhihu.com/p/604884758  