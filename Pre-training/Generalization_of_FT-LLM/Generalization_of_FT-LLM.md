---
title: Generalization_of_FT-LLM
created: 2024-03-16
tags:
  - 微调
type: 论文
papername: Unveiling the Generalization Power of Fine-Tuned Large Language Models
conference: ACL/EMNLP/NAACL/EACL/COLING/SIGIR/AAAI/ICML/ICDM
year: 2024
institution:
  - 清华
  - 香港中文大学
---

## 论文基本信息

标题：Unveiling the Generalization Power of Fine-Tuned Large Language Models

作者：[Haoran Yang](https://arxiv.org/search/?searchtype=author&query=Haoran%20Yang) ; [Yumeng Zhang](https://arxiv.org/search/?searchtype=author&query=Yumeng%20Zhang) ; [Jiaqi Xu](https://arxiv.org/search/?searchtype=author&query=Jiaqi%20Xu) ; [Hongyuan Lu](https://arxiv.org/search/?searchtype=author&query=Hongyuan%20Lu) ; [Pheng Ann Heng](https://arxiv.org/search/?searchtype=author&query=Pheng%20Ann%20Heng) ; [Wai Lam](https://arxiv.org/search/?searchtype=author&query=Wai%20Lam)

链接：http://arxiv.org/abs/2403.09162

代码：https://github.com/ LHRYANG/Generalization_of_FT-LLM

框架图：


## 背景

这篇论文探讨了大型语言模型（LLMs）在经过微调（fine-tuning）后其泛化能力的变化。尽管LLMs在多任务学习中表现出色，但为了在特定下游任务上获得更好的性能，通常需要对这些模型进行微调。然而，微调对LLMs内在泛化能力的综合影响尚未被充分理解。论文的主要目标是：

1. 研究原始、未经修改的LLMs与经过微调的变体之间的差异。
    
2. 探究微调是否影响LLMs的泛化能力。
    
3. 分析在生成任务和分类任务上微调的模型在不同领域和任务中的泛化行为。
    
4. 考察在生成任务微调过程中集成上下文学习（in-context learning, ICL）策略是否能增强模型的泛化能力。
    
5. 通过系统性研究，为LLMs的微调实践提供有价值的见解，旨在不仅提升特定任务的性能，还促进更广泛的泛化能力。
    

论文通过在五个不同的语言任务和多个数据集上进行广泛的实验，来探讨这些关键问题。主要发现包括：

- 在生成和分类任务上微调的模型在泛化到不同领域和任务时表现出不同的行为。
    
- 在生成任务中使用ICL策略的微调可以增强LLMs的泛化能力。
    
- 微调的模型在特定任务上的性能提升与其泛化能力的损失之间存在权衡。
    

这些发现有助于深入理解微调对LLMs泛化能力的影响，并为未来的微调策略提供指导。

## 相关研究
这篇论文提到了与大型语言模型（LLMs）的微调（fine-tuning）和上下文学习（in-context learning, ICL）相关的一些研究：

1. **多任务微调对零样本和ICL能力的提升**：
    
    - Wei et al. (2022a) 揭示了多任务微调可以增强LLMs的零样本（zero-shot）和ICL能力。这表明微调不仅改善了在训练任务上的性能，还增强了模型的固有学习能力。
2. **微调与ICL在分类任务中的泛化比较**：
    
    - Mosbach et al. (2023) 强调了在分类任务中，少样本微调（few-shot fine-tuning）和ICL在领域外泛化（out-of-domain generalization）方面表现出类似的水平。
3. **微调可能导致的任务特定格式的过度定制**：
    
    - Wang et al. (2023c) 发现微调可能使模型过度适应特定任务的格式，从而可能损害其适应其他新任务的能力。
4. **ICL在微调过程中的潜在帮助**：
    
    - Anil et al. (2022) 发现在微调过程中加入几个ICL示例对于文本长度泛化是有帮助的。论文进一步扩展了这一观点，并发现这种方法在保持甚至增强微调模型的泛化能力方面也是有价值的。

此外，论文还讨论了大型语言模型的发展历程，如BERT (Devlin et al., 2019)、GPT-2 (Radford et al., 2019)、GPT-3 (Brown et al., 2020) 和 Llama-2 (tou, 2023) 等模型在自然语言处理领域的影响。这些模型通过在大量文本上进行预训练，展示了在零样本或少样本情况下理解和解决各种任务的卓越能力。

这些相关研究为论文的研究背景提供了理论和实证基础，并帮助论文构建了其实验设计和研究方法。

## 核心亮点



## 实验
论文进行了一系列实验来探究微调对大型语言模型（LLMs）泛化能力的影响。具体的实验设计如下：

1. **实验设置**：
    
    - 对于每个任务，选择一个特定的数据集作为训练集，其余数据集用作测试集。
        
    - 测试集分为领域内（in-domain）和领域外（out-of-domain）数据集。
        
    - 实验涵盖三种不同的评估设置：
        
        - 同一任务，领域内数据集。
            
        - 同一任务，领域外数据集。
            
        - 不同任务。
            
2. **评估任务**：
    
    - 选择了五种语言任务进行实验，包括摘要生成、问题生成、情感分类、释义检测和自然语言推理。
3. **模型选择**：
    
    - 使用开源的Llama-2-7b模型作为基础模型进行微调。
4. **训练细节**：
    
    - 对每个任务特定的训练集进行微调，使用不同大小的样本子集（2000、4000和6000个样本）。
5. **测试细节**：
    
    - 对于生成任务，使用Rouge-L3指标进行评估。
        
    - 对于分类任务，使用准确率作为评估指标。
        
    - 在测试阶段，采用了两种策略：0样本提示方法（无上下文示例的正常测试）和上下文学习（ICL）。
        
6. **微调与ICL结合的实验**：
    
    - 探索在生成任务微调过程中集成ICL策略对泛化能力的影响。
7. **结果分析**：
    
    - 分析微调模型在领域内和领域外测试集上的表现。
        
    - 比较微调模型在不同任务类型上的泛化能力。
        
    - 讨论训练数据规模对模型性能的影响。

## 未来方向

论文在结论部分提到了两个主要的局限性，并提出了未来可能的研究方向：

1. **微调模型的内在机制**：
    
    - 论文指出，对于在分类任务和生成任务上微调的模型之间泛化能力差异的底层原因尚未进行深入研究。未来的研究可以更深入地探讨这一问题，包括微调过程中模型学习方式的变化、不同任务类型对模型泛化能力影响的机制等。
2. **微调与上下文学习（ICL）结合的方法**：
    
    - 论文提到，微调结合ICL的方法（FTICL）的复杂操作机制尚未被完全理解。未来的研究可以探索这种方法的工作原理，包括ICL在微调过程中的作用、如何更有效地结合ICL和微调来优化模型性能等。

此外，论文的研究结果和方法也提出了其他可能的研究方向：

3. **微调策略的优化**：
    
    - 研究更精细的微调策略，例如调整微调过程中的学习率、优化器选择、训练周期数等，以提高模型的泛化能力。
4. **跨领域和跨任务的泛化能力**：
    
    - 扩展研究到更多的领域和任务类型，以更全面地理解微调对LLMs泛化能力的影响。
5. **模型结构和参数的影响**：
    
    - 探索不同模型结构和参数规模对微调后泛化能力的影响。
6. **数据集和样本选择**：
    
    - 研究不同数据集特性（如数据质量、多样性、规模）对微调效果的影响。
7. **模型解释性**：
    
    - 提高模型的可解释性，以便更好地理解微调过程中模型的决策过程。
8. **实际应用场景的评估**：
    
    - 在真实世界的应用场景中评估微调模型的性能，包括模型的鲁棒性和可靠性。

通过进一步的研究，可以更好地理解和利用LLMs解决新任务，同时保持或提升其泛化能力。

## 主要收获


## 参考资料
