人类学习过语言，所以可以很轻松地判断一句话是不是人话，但是计算机怎么判断呢？它只认识0和1，并没有学习过人类的语言呀。这也就是为什么我们要将人类的语言（比如文本、声音等）翻译成计算机能够理解的语言（数字），如果一个词对应一个数字的话，那么一句话就对应着一个向量。

那么怎么将文本转换成向量呢？首先要明确我们转换成向量的目的，是要让计算机通过向量尽可能地理解对应的文本的含义。比如你，我，他都是人称代词，其实计算机不需要知道它们是什么类型的词，只需要知道它们是一类词就可以了，至于它们是人称代词还是名词其实是由我们人类去定义的。也就是说，**计算机能够通过词向量获取的信息和人类通过文本看到的信息一致。这就是词向量的目标。**

最早的表示词向量的方法是**one-hot(独热编码)表示法**。首先我们有一个词表，里面包括了我们可能会用到的所有词，每个词占据一个位置。那么词向量就是一个该词表维度大小的向量，词所在位置取值1，其它位置取值0。例如我们的词表有下面9个词：

```
你,我,他,是,谁,哪,里,来,自
```

那么“我”就可以表示为向量[0, 1, 0, 0, 0, 0, 0, 0, 0]，“是”表示为[0, 0, 0, 1, 0, 0, 0, 0, 0]。是不是很简单？

one-hot表示法很简单，但是存在较大的问题：**维度灾难**和**语义鸿沟**。

维度灾难很好理解，如果我们的词表很大（这是通常情况），那么词向量的维度也会一样很大，这会使得数据样本稀疏，计算困难。

语义鸿沟是指one-hot表示法产生的词向量都是彼此正交的（两个向量的内积为0），体现不出任何语义上的联系。比如“我”的向量[0, 1, 0, 0, 0, 0, 0, 0, 0]和“你”的向量[1, 0, 0, 0, 0, 0, 0, 0, 0]的内积（对应位置的元素相乘得到的数值再相加）为0，“我”和“是”的向量的内积也是0，没有任何差异，并不能体现出它们之间的相似性大小。