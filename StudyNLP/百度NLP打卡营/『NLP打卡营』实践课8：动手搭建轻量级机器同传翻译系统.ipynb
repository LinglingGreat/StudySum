{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STACL机器同传\n",
    "机器同传，即在句子完成之前进行翻译，同声传译的目标是实现同声传译的自动化，它可以与源语言同时翻译，延迟时间只有几秒钟。\n",
    "\n",
    "同传翻译的难点在于源语言和目标语言之间词序的差异带来的翻译延迟。 例如，考虑将SOV（主宾谓）语言（如日语或德语）翻译为SVO（主谓宾）语言（如英语或汉语），必须等到源语言动词出现才可以准确翻译。因此，翻译系统必须求助于传统的全句翻译，因此造成至少一句话的延迟。\n",
    "\n",
    "本项目是基于机器翻译领域主流模型 Transformer网络结构的同传模型STACL的PaddlePaddle 实现，包含模型训练，预测以及使用自定义数据等内容。用户可以基于发布的内容搭建自己的同传翻译模型。\n",
    "\n",
    "STACL 是论文 [STACL: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework](https://www.aclweb.org/anthology/P19-1289/) 中针对同传提出的适用于所有同传场景的翻译架构，该架构基于Transformer实现，可参考PaddleNLP的[Transformer](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/machine_translation/transformer)。\n",
    "\n",
    "STACL 主要具有以下优势：\n",
    "\n",
    "- **Implicit Anticipation**: Prefix-to-Prefix架构拥有预测能力，即在未看到源词的情况下仍然可以翻译出对应的目标词，克服了SOV→SVO等词序差异；\n",
    "\n",
    "- **Controllable Latency**: Wait-k策略可以不需要全句的源句，直接预测目标句，可以实现任意的字级延迟，同时保持较高的翻译质量。\n",
    "\n",
    "### Implicit Anticipation（隐式的预测能力）\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/9243f9077b16417c9148333b731ac5d2275cf79ef5df4579af5ff644af5b9d47\" width=\"1000\" height=\"500\" ></center>\n",
    "\n",
    "<br><center>图1：Implicit Anticipation</center></br>\n",
    "源端只输入“他 还 说 现在 正在 为 这 一 会议”，目标端前两个策略就已经翻译出“making preparations”和“making”，充分体现了STACL的预测能力。\n",
    "\n",
    "### Controllable Latency（可控的延迟）\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/8c919fe235d6415b97ffe91c54bc0ab991d3cfac5b714b6f90a32d40cf34983f\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图2： Controllable Latency (Wait-k)</center></br>\n",
    "Wait-k策略首先等待源端读入k个词后开始进行翻译。上图2中，k=1，第一个目标词在读入第一个1个源词后翻译，第二个目标词在读入前2个源词后翻译，以此类推，所以当源端读入“他 还 说”3个词后，目前端就已经翻译出“he also said”。当k=3，第一个目标词在读入前3个源词后翻译，所以当源端读入“他 还 说”后，目标端翻译出第一个词”he“。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Demo动画展示\n",
    "如果有ASR(Automatic Speech Recognition)的api接入，即刻实现语音同传\n",
    "\n",
    "\n",
    "该Demo的具体实现：[STACL Demo](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/simultaneous_translation/stacl/demo)   \n",
    "<center><img src=\"https://gongel.cn/wp-content/uploads/2021/05/textdemo_show_20210609.gif\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图3.1：文本同传Demo </center></br>\n",
    "\n",
    "<center><img src=\"https://gongel.cn/wp-content/uploads/2021/05/audiodemo_show_20210609.gif\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图3.2：语音同传Demo </center></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 环境介绍\n",
    "\n",
    "- PaddlePaddle框架，AI Studio平台已经默认安装最新版2.1。\n",
    "\n",
    "- PaddleNLP，深度兼容框架2.1，是飞桨框架2.1在NLP领域的最佳实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "开源不易，希望大家多多支持~ \n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)  \n",
    "PaddleNLP文档：[https://paddlenlp.readthedocs.io](https://paddlenlp.readthedocs.io)  \n",
    "本项目完整版：[https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/simultaneous_translation/stacl](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/simultaneous_translation/stacl)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4afc34d18d6940af8ff6139fb0e6aa4ae46fcfd0d8cf49a18b491a91a22f959e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/stacl\n"
     ]
    }
   ],
   "source": [
    "%cd stacl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/7a/e6098c8794d7753470071f58b07843824c40ddbabe213eae458d321d2dbe/paddlenlp-2.0.3-py3-none-any.whl (451kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 25kB/s eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.3\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting attrdict==2.0.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
      "Collecting PyYAML==5.4.1 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 11.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting subword_nmt==0.3.7 (from -r requirements.txt (line 3))\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from attrdict==2.0.1->-r requirements.txt (line 1)) (1.15.0)\n",
      "Installing collected packages: attrdict, PyYAML, subword-nmt\n",
      "  Found existing installation: PyYAML 5.1.2\n",
      "    Uninstalling PyYAML-5.1.2:\n",
      "      Successfully uninstalled PyYAML-5.1.2\n",
      "Successfully installed PyYAML-5.4.1 attrdict-2.0.1 subword-nmt-0.3.7\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖\n",
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pipeline\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b7aafbcc8e2f4bfc9b864d1a1bc0af749260ef9b690c458399f2ba9c66c1ab80\" width=\"1200\" height=\"600\" ></center>\n",
    "<br><center>图4：Pipeline </center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "import paddle.distributed as dist\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import Vocab, Pad\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import WordEmbedding, PositionalEmbedding, position_encoding_init\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "from utils import CrossEntropyCriterion, post_process_seq, Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 数据预处理\n",
    "本项目展示的训练数据为NIST的中英demo数据(1000条中英文本对)，同时提供基于全量NIST中英数据训练的预训练模型下载。  \n",
    "中文需要Jieba+BPE，英文需要BPE  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BPE(Byte Pair Encoding)\n",
    "BPE优势：\n",
    "- 压缩词表；\n",
    "- 一定程度上缓解OOV(out of vocabulary)问题\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/e7a59d7bab514a6fa17d24a116af0b680fbd664439c948799c0a0541dffd35a2\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图5：learn BPE </center></br>\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d4b9c48ba7274395af3fbb267c1f9adcba50dd4b147d4258be58999b3b5a198c\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图6：Apply BPE </center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/968fefdeff604651b0f779191892106a15b27378b4ab48df85dacc2eeef76b59\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图7：Jieba+BPE </center></br>\n",
    "\n",
    "### 数据格式:\n",
    "\n",
    "`兵营 是 双@@ 枪 老@@ 大@@ 爷 的 前提 建筑 之一 。\tit serves as a prerequisite for Re@@ apers to be built at the Bar@@ rac@@ ks .`  \n",
    "\n",
    "与文本翻译的数据预处理几乎一致，可以参考[Transformer机器翻译](https://aistudio.baidu.com/aistudio/projectdetail/1918692)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompress train_dev_test data.\n",
      "Download model.\n",
      "--2021-06-21 21:51:54--  https://paddlenlp.bj.bcebos.com/models/stacl/nist_zhen_full_w5.tar.gz\n",
      "Resolving paddlenlp.bj.bcebos.com (paddlenlp.bj.bcebos.com)... 182.61.200.229, 182.61.200.195, 2409:8c00:6c21:10ad:0:ff:b00e:67d\n",
      "Connecting to paddlenlp.bj.bcebos.com (paddlenlp.bj.bcebos.com)|182.61.200.229|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 849689440 (810M) [application/x-gzip]\n",
      "Saving to: ‘trained_models/nist_zhen_full_w5.tar.gz’\n",
      "\n",
      "nist_zhen_full_w5.t 100%[===================>] 810.33M  26.7MB/s    in 33s     \n",
      "\n",
      "2021-06-21 21:52:27 (24.2 MB/s) - ‘trained_models/nist_zhen_full_w5.tar.gz’ saved [849689440/849689440]\n",
      "\n",
      "Decompress model.\n",
      "Over.\n"
     ]
    }
   ],
   "source": [
    "!bash get_data_and_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 构造Dataloader\n",
    "\n",
    "下面的`create_data_loader`函数用于创建训练集、验证集所需要的`DataLoader`对象,  \n",
    "`create_infer_loader`函数用于创建预测集所需要的`DataLoader`对象，   \n",
    "`DataLoader`对象用于产生一个个batch的数据。下面对函数中调用的`paddlenlp`内置函数作简单说明：\n",
    "* `paddlenlp.data.Vocab.load_vocabulary`：Vocab词表类，集合了一系列文本token与ids之间映射的一系列方法，支持从文件、字典、json等一系方式构建词表\n",
    "* `paddlenlp.datasets.load_dataset`：从本地文件创建数据集时，推荐根据本地数据集的格式给出读取function并传入 load_dataset() 中创建数据集\n",
    "* `paddlenlp.data.Pad`：padding 操作  \n",
    "\n",
    "具体可参考[PaddleNLP的文档](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html)\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/0085d53068134546bcb914347774430c3a2c94cd77934c2e90420ac740d16fc7\" width=\"700\" height=\"350\" ></center>\n",
    "<br><center>图8：构造Dataloader的流程 </center></br>\n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/3bf38365718346a19c25729bb67e2e6afe8f0bafc61348018d2b9dd60dc9a8bf\" width=\"1000\" height=\"500\" ></center>\n",
    "<br><center>图9：Dataloader细节 </center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 自定义读取本地数据的方法\n",
    "def read(src_tgt_file, only_src=False):\n",
    "    with open(src_tgt_file, 'r', encoding='utf8') as src_tgt_f:\n",
    "        for line in src_tgt_f:\n",
    "            line = line.strip('\\n')\n",
    "            if not line:\n",
    "                continue\n",
    "            line_split = line.split('\\t')\n",
    "            # 判断是否是测试集，测试集不需要target\n",
    "            if only_src:\n",
    "                yield {\"src\": line_split[0]}\n",
    "            else:\n",
    "                if len(line_split) != 2:\n",
    "                    continue\n",
    "                yield {\"src\": line_split[0], \"trg\": line_split[1]}\n",
    "\n",
    " # 过滤掉长度 ≤min_len或者≥max_len 的数据  \n",
    "def min_max_filer(data, max_len, min_len=0):\n",
    "    # 获取每条src和tgt的最小长度和最大长度（+1是为了<s>或者<e>），过滤掉不满足长度范围的样本\n",
    "    data_min_len = min(len(data[0]), len(data[1]))\n",
    "    data_max_len = max(len(data[0]), len(data[1]))\n",
    "    return (data_min_len >= min_len) and (data_max_len <= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 为训练集和验证集创建dataloader\n",
    "def create_data_loader(args, places=None):\n",
    "    data_files = {'train': args.training_file, 'dev': args.validation_file}\n",
    "\n",
    "    # 通过paddlenlp.datasets.load_dataset从本地文件创建数据集：根据本地数据集的格式给出读取function并传入load_dataset()中创建数据集\n",
    "    datasets = [\n",
    "        load_dataset(\n",
    "            read, src_tgt_file=filename, lazy=False)\n",
    "        for split, filename in data_files.items()\n",
    "    ]\n",
    "\n",
    "    # 通过Paddlenlp.data.Vocab.load_vocabulary从本地创建词表\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    args.src_vocab_size = len(src_vocab)\n",
    "    args.trg_vocab_size = len(trg_vocab)\n",
    "\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        target = sample['trg'].split()\n",
    "\n",
    "        # 将tokens转化为词表对应的ids\n",
    "        source = src_vocab.to_indices(source) + [args.eos_idx]\n",
    "        target = [args.bos_idx] + \\\n",
    "                 trg_vocab.to_indices(target) + [args.eos_idx]\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    # 训练集dataloader和验证集dataloader  \n",
    "    data_loaders = []\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        # 通过Dataset的map方法将样本token转换为id；通过Dataset的filter方法过滤掉不符合条件的样本\n",
    "        dataset = dataset.map(convert_samples, lazy=False).filter(\n",
    "            partial(min_max_filer, max_len=args.max_length))\n",
    "\n",
    "        # BatchSampler，批采样器BatchSampler组batch: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/BatchSampler_cn.html\n",
    "        batch_sampler = BatchSampler(dataset,batch_size=args.batch_size, shuffle=True,drop_last=False)\n",
    "\n",
    "        # DataLoader，构造Dataloader用于后续迭代取数据进行训练/验证/测试: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            places=places,\n",
    "            batch_sampler=batch_sampler,\n",
    "            collate_fn=partial(\n",
    "                prepare_train_input, \n",
    "                pad_idx=args.bos_idx),\n",
    "                num_workers=0)\n",
    "\n",
    "        data_loaders.append(data_loader)\n",
    "\n",
    "    return data_loaders\n",
    "\n",
    "def prepare_train_input(insts, pad_idx):\n",
    "    # 通过paddlenlp.data.Pad来padding，用于对齐同一batch中样本的长度\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad([inst[0] for inst in insts])\n",
    "    trg_word = word_pad(inst[1][:-1] for inst in insts)\n",
    "    lbl_word = word_pad([inst[1][1:] for inst in insts])\n",
    "    data_inputs = [src_word, trg_word, lbl_word]\n",
    "\n",
    "    return data_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 为测试集创建dataloader（同训练集和验证集的dataloader）\n",
    "def create_infer_loader(args, places=None):\n",
    "    data_files = {'test': args.predict_file, }\n",
    "    dataset = load_dataset(\n",
    "        read, src_tgt_file=data_files['test'], only_src=True, lazy=False)\n",
    "\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    args.src_vocab_size = len(src_vocab)\n",
    "    args.trg_vocab_size = len(trg_vocab)\n",
    "\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        source = src_vocab.to_indices(source) + [args.eos_idx]\n",
    "        target = [args.bos_idx]\n",
    "        return source, target\n",
    "        \n",
    "    dataset = dataset.map(convert_samples, lazy=False)\n",
    "\n",
    "    # BatchSampler: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/BatchSampler_cn.html\n",
    "    batch_sampler = BatchSampler(dataset,batch_size=args.batch_size,drop_last=False)\n",
    "\n",
    "    # DataLoader: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        places=places,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=partial(\n",
    "            prepare_infer_input, \n",
    "            pad_idx=args.bos_idx),\n",
    "            num_workers=0,\n",
    "            return_list=True)\n",
    "\n",
    "    return data_loader, trg_vocab.to_tokens\n",
    "\n",
    "def prepare_infer_input(insts, pad_idx):\n",
    "    \"\"\"\n",
    "    Put all padded data needed by beam search decoder into a list.\n",
    "    \"\"\"\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad(inst[0] for inst in insts)\n",
    "\n",
    "    return [src_word, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 搭建模型\n",
    "基于PaddlePaddle的相关API，包括：  \n",
    "* [`paddle.nn.TransformerEncoderLayer`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/TransformerEncoderLayer_cn.html#transformerencoderlayer)：Transformer编码器层\n",
    "* [`paddle.nn.TransformerEncoder`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/TransformerEncoder_cn.html#transformerencoder)：Transformer编码器\n",
    "* [`paddle.nn.TransformerDecoderLayer`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/TransformerDecoderLayer_cn.html#transformerdecoderlayer)：Transformer解码器层\n",
    "* [`paddle.nn.TransformerDecoder`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/TransformerDecoder_cn.html#transformerdecoder)：Transformer解码器\n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/31886c6aa0424fce92fb9a78248bd7d252f843bfa1f34e5f91bc763c62b46c29\" width=\"700\" height=\"350\" ></center>\n",
    "<br><center>图10：模型搭建 </center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Encoder层\n",
    "和原生Transformer一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Decoder层\n",
    "基于paddle.nn.TransformerDecoderLayer加入Wait-k策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义Decoder层，这里给出和nn.TransformerDecoderLayer不一致地方的注释\n",
    "class DecoderLayer(nn.TransformerDecoderLayer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(DecoderLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, cache=None):\n",
    "        residual = tgt\n",
    "        # 计算LayerNorm\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm1(tgt)\n",
    "        # 计算self attention\n",
    "        if cache is None:\n",
    "            tgt = self.self_attn(tgt, tgt, tgt, tgt_mask, None)\n",
    "        else:\n",
    "            tgt, incremental_cache = self.self_attn(tgt, tgt, tgt, tgt_mask,\n",
    "                                                    cache[0])\n",
    "                                                \n",
    "        # 加上残差\n",
    "        tgt = residual + self.dropout1(tgt)\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm1(tgt)\n",
    "\n",
    "        residual = tgt\n",
    "        # 计算LayerNorm\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm2(tgt)\n",
    "\n",
    "        # 下面是添加了waitk策略的部分\n",
    "        # memory为encoder的output\n",
    "        if len(memory) == 1:\n",
    "            # 整句模型\n",
    "            tgt = self.cross_attn(tgt, memory[0], memory[0], memory_mask, None)        \n",
    "        else:\n",
    "            # Wait-k策略\n",
    "            cross_attn_outputs = []\n",
    "            for i in range(tgt.shape[1]):\n",
    "                # 取当前target第i位\n",
    "                q = tgt[:, i:i + 1, :]\n",
    "                if i >= len(memory):\n",
    "                    e = memory[-1]\n",
    "                else:\n",
    "                    e = memory[i]\n",
    "                # 计算cross attention\n",
    "                cross_attn_outputs.append(\n",
    "                    self.cross_attn(q, e, e, memory_mask[:, :, i:i + 1, :\n",
    "                                                         e.shape[1]], None))\n",
    "            # 将target每一位计算出的cross attention进行拼接\n",
    "            tgt = paddle.concat(cross_attn_outputs, axis=1)\n",
    "\n",
    "        # 加上残差\n",
    "        tgt = residual + self.dropout2(tgt)\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm2(tgt)\n",
    "\n",
    "        residual = tgt\n",
    "        # 计算LayerNorm\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm3(tgt)\n",
    "        tgt = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        # 加上残差\n",
    "        tgt = residual + self.dropout3(tgt)\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm3(tgt)\n",
    "        return tgt if cache is None else (tgt, (incremental_cache, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型主结构\n",
    "和原生Transformer基本一致，具体细节可参考可参考：[paddlenlp.transformers.TransformerModel](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/paddlenlp/transformers/transformer/modeling.py)\n",
    "\n",
    "SimultaneousTransformer：Encoder+Decoder(wait-k 策略)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transformer\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/4b3299f4552e4f82b93707d91e765fdbb617ab5fbb0c495aa769059c1b3c8ec2\" width=\"1200\" height=\"600\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SimultaneousTransformer\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7a46a5bced474d02b20c23685e4534c727462ea007f44e52922fa701da3a423a\" width=\"1200\" height=\"600\" ></center>  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1628f330ab73442496c17c8a2ecd3276719e521776474b97ba20277c58bf04ea\" width=\"1200\" height=\"600\" ></center>  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/830c3250c6b546f6bce6f75148286c9f7bd7c17f6b8d40958c783bd2b0e47b81\" width=\"1200\" height=\"600\" ></center>  \n",
    "\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/8cf8837e63ee4cf593fb2327886574134f3ce9febb19446c8600a1608b36b6fd\" width=\"1200\" height=\"600\" ></center>  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/29729d66acab4e909fb107cb80be8ccd60a2511eeee64f75aae60937bf0ae4f8\" width=\"1200\" height=\"600\" ></center>  \n",
    "\n",
    "<br><center>图11：Example </center></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义SimultaneousTransformer，这里给出和nn.TransformerDecoderLayer不一致地方的注释\n",
    "class SimultaneousTransformer(nn.Layer):\n",
    "    \"\"\"\n",
    "    model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 src_vocab_size,\n",
    "                 trg_vocab_size,\n",
    "                 max_length,\n",
    "                 n_layer,\n",
    "                 n_head,\n",
    "                 d_model,\n",
    "                 d_inner_hid,\n",
    "                 dropout,\n",
    "                 weight_sharing,\n",
    "                 bos_id=0,\n",
    "                 eos_id=1,\n",
    "                 waitk=-1):\n",
    "        super(SimultaneousTransformer, self).__init__()\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.emb_dim = d_model\n",
    "        self.bos_id = bos_id\n",
    "        self.eos_id = eos_id\n",
    "        self.dropout = dropout\n",
    "        self.waitk = waitk\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 声明WordEmbedding\n",
    "        self.src_word_embedding = WordEmbedding(\n",
    "            vocab_size=src_vocab_size, emb_dim=d_model, bos_id=self.bos_id)\n",
    "\n",
    "        # 声明PositionalEmbedding\n",
    "        self.src_pos_embedding = PositionalEmbedding(\n",
    "            emb_dim=d_model, max_length=max_length)\n",
    "        \n",
    "        # 判断target是否要和source共享WordEmbedding\n",
    "        if weight_sharing:\n",
    "            assert src_vocab_size == trg_vocab_size, (\n",
    "                \"Vocabularies in source and target should be same for weight sharing.\"\n",
    "            )\n",
    "            self.trg_word_embedding = self.src_word_embedding\n",
    "            self.trg_pos_embedding = self.src_pos_embedding\n",
    "        else:\n",
    "            self.trg_word_embedding = WordEmbedding(\n",
    "                vocab_size=trg_vocab_size, emb_dim=d_model, bos_id=self.bos_id)\n",
    "            self.trg_pos_embedding = PositionalEmbedding(\n",
    "                emb_dim=d_model, max_length=max_length)\n",
    "\n",
    "        # 声明Encoder层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=d_inner_hid,\n",
    "            dropout=dropout,\n",
    "            activation='relu',\n",
    "            normalize_before=True,\n",
    "            bias_attr=[False, True])\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        # 声明Encoder\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer, num_layers=n_layer, norm=encoder_norm)\n",
    "\n",
    "        # 声明Decoder层\n",
    "        decoder_layer = DecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=d_inner_hid,\n",
    "            dropout=dropout,\n",
    "            activation='relu',\n",
    "            normalize_before=True,\n",
    "            bias_attr=[False, False, True])\n",
    "        decoder_norm = nn.LayerNorm(d_model)\n",
    "        # 声明Decoder\n",
    "        self.decoder = Decoder(\n",
    "            decoder_layer=decoder_layer, num_layers=n_layer, norm=decoder_norm)\n",
    "\n",
    "        if weight_sharing:\n",
    "            self.linear = lambda x: paddle.matmul(\n",
    "                x=x, y=self.trg_word_embedding.word_embedding.weight, transpose_y=True)\n",
    "        else:\n",
    "            self.linear = nn.Linear(\n",
    "                in_features=d_model,\n",
    "                out_features=trg_vocab_size,\n",
    "                bias_attr=False)\n",
    "\n",
    "    def forward(self, src_word, trg_word):\n",
    "        src_max_len = paddle.shape(src_word)[-1]\n",
    "        trg_max_len = paddle.shape(trg_word)[-1]\n",
    "        base_attn_bias = paddle.cast(\n",
    "            src_word == self.bos_id,\n",
    "            dtype=paddle.get_default_dtype()).unsqueeze([1, 2]) * -1e9\n",
    "        # 计算source端的attention mask\n",
    "        src_slf_attn_bias = base_attn_bias\n",
    "        src_slf_attn_bias.stop_gradient = True\n",
    "        # 计算target端的attention mask\n",
    "        trg_slf_attn_bias = paddle.tensor.triu(\n",
    "            (paddle.ones(\n",
    "                (trg_max_len, trg_max_len),\n",
    "                dtype=paddle.get_default_dtype()) * -np.inf),\n",
    "            1)\n",
    "        trg_slf_attn_bias.stop_gradient = True\n",
    "        # 计算encoder-decoder的attention mask\n",
    "        trg_src_attn_bias = paddle.tile(base_attn_bias, [1, 1, trg_max_len, 1])\n",
    "        src_pos = paddle.cast(\n",
    "            src_word != self.bos_id, dtype=\"int64\") * paddle.arange(\n",
    "                start=0, end=src_max_len)\n",
    "        trg_pos = paddle.cast(\n",
    "            trg_word != self.bos_id, dtype=\"int64\") * paddle.arange(\n",
    "                start=0, end=trg_max_len)\n",
    "        # 计算source的word embedding\n",
    "        src_emb = self.src_word_embedding(src_word)\n",
    "        # 计算source的position embedding\n",
    "        src_pos_emb = self.src_pos_embedding(src_pos)\n",
    "        # 得到最终Embedding：word embedding + position embedding\n",
    "        src_emb = src_emb + src_pos_emb\n",
    "        enc_input = F.dropout(\n",
    "            src_emb, p=self.dropout,\n",
    "            training=self.training) if self.dropout else src_emb\n",
    "        with paddle.static.amp.fp16_guard():\n",
    "            # 下面是添加了waitk策略的部分\n",
    "            if self.waitk >= src_max_len or self.waitk == -1:\n",
    "                # 整句模型，和API一致\n",
    "                enc_outputs = [\n",
    "                    self.encoder(\n",
    "                        enc_input, src_mask=src_slf_attn_bias)\n",
    "                ]\n",
    "            else:\n",
    "                # Wait-k策略\n",
    "                enc_outputs = []\n",
    "                for i in range(self.waitk, src_max_len + 1):\n",
    "                    # 分别将子句送入encoder\n",
    "                    enc_output = self.encoder(\n",
    "                        enc_input[:, :i, :],\n",
    "                        src_mask=src_slf_attn_bias[:, :, :, :i])\n",
    "                    enc_outputs.append(enc_output)\n",
    "            # 计算target的word embedding\n",
    "            trg_emb = self.trg_word_embedding(trg_word)\n",
    "            # 计算target的position embedding\n",
    "            trg_pos_emb = self.trg_pos_embedding(trg_pos)\n",
    "            # 得到最终Embedding：word embedding + position embedding\n",
    "            trg_emb = trg_emb + trg_pos_emb\n",
    "            dec_input = F.dropout(\n",
    "                trg_emb, p=self.dropout,\n",
    "                training=self.training) if self.dropout else trg_emb\n",
    "            # 送入Decoder，拿到输出\n",
    "            dec_output = self.decoder(\n",
    "                dec_input,\n",
    "                enc_outputs,\n",
    "                tgt_mask=trg_slf_attn_bias,\n",
    "                memory_mask=trg_src_attn_bias)\n",
    "            # 经过全连接层拿到最终输出\n",
    "            predict = self.linear(dec_output)\n",
    "\n",
    "        return predict\n",
    "\n",
    "    def greedy_search(self, src_word, max_len=256, waitk=-1):\n",
    "        src_max_len = paddle.shape(src_word)[-1]\n",
    "        base_attn_bias = paddle.cast(\n",
    "            src_word == self.bos_id,\n",
    "            dtype=paddle.get_default_dtype()).unsqueeze([1, 2]) * -1e9\n",
    "        # 计算source端的attention mask\n",
    "        src_slf_attn_bias = base_attn_bias\n",
    "        src_slf_attn_bias.stop_gradient = True\n",
    "        # 计算target端的attention mask\n",
    "        trg_src_attn_bias = paddle.tile(base_attn_bias, [1, 1, 1, 1])\n",
    "        src_pos = paddle.cast(\n",
    "            src_word != self.bos_id, dtype=\"int64\") * paddle.arange(\n",
    "                start=0, end=src_max_len)\n",
    "        # 计算source的word embedding\n",
    "        src_emb = self.src_word_embedding(src_word)\n",
    "        # 计算source的position embedding\n",
    "        src_pos_emb = self.src_pos_embedding(src_pos)\n",
    "        # 得到最终Embedding：word embedding + position embedding\n",
    "        src_emb = src_emb + src_pos_emb\n",
    "        enc_input = F.dropout(\n",
    "            src_emb, p=self.dropout,\n",
    "            training=self.training) if self.dropout else src_emb\n",
    "        # 下面是添加了waitk策略的部分\n",
    "        if waitk < 0 or waitk > src_max_len:\n",
    "            # 整句模型\n",
    "            enc_outputs = [self.encoder(enc_input, src_mask=src_slf_attn_bias)]\n",
    "        else:\n",
    "            # waitk策略\n",
    "            enc_outputs = []\n",
    "            # 依次将source子句送入Encoder，拿到输出\n",
    "            for i in range(waitk, src_max_len + 1):\n",
    "                enc_output = self.encoder(\n",
    "                    enc_input[:, :i, :],\n",
    "                    src_mask=src_slf_attn_bias[:, :, :, :i])\n",
    "                enc_outputs.append(enc_output)\n",
    "\n",
    "        batch_size = enc_outputs[-1].shape[0]\n",
    "        max_len = (\n",
    "            enc_outputs[-1].shape[1] + 20) if max_len is None else max_len\n",
    "        end_token_tensor = paddle.full(\n",
    "            shape=[batch_size, 1], fill_value=self.eos_id, dtype=\"int64\")\n",
    "\n",
    "        predict_ids = []\n",
    "        # 初始化概率\n",
    "        log_probs = paddle.full(\n",
    "            shape=[batch_size, 1], fill_value=0, dtype=\"float32\")\n",
    "        # 初始化trg_word\n",
    "        trg_word = paddle.full(\n",
    "            shape=[batch_size, 1], fill_value=self.bos_id, dtype=\"int64\")\n",
    "\n",
    "        # 初始化caches：包括StaticCache和IncrementalCache\n",
    "        caches = self.decoder.gen_cache(enc_outputs[-1], do_zip=False)\n",
    "\n",
    "        for i in range(max_len):\n",
    "            trg_pos = paddle.full(\n",
    "                shape=trg_word.shape, fill_value=i, dtype=\"int64\")\n",
    "            # 计算target的word embedding\n",
    "            trg_emb = self.trg_word_embedding(trg_word)\n",
    "            # 计算target的position embedding\n",
    "            trg_pos_emb = self.trg_pos_embedding(trg_pos)\n",
    "            # 得到最终Embedding：word embedding + position embedding\n",
    "            trg_emb = trg_emb + trg_pos_emb\n",
    "            dec_input = F.dropout(\n",
    "                trg_emb, p=self.dropout,\n",
    "                training=self.training) if self.dropout else trg_emb\n",
    "\n",
    "            if waitk < 0 or i >= len(enc_outputs):\n",
    "                # 整句模型\n",
    "                _e = enc_outputs[-1]\n",
    "                dec_output, caches = self.decoder(\n",
    "                    dec_input, [_e], None,\n",
    "                    trg_src_attn_bias[:, :, :, :_e.shape[1]], caches)\n",
    "            else:\n",
    "                _e = enc_outputs[i]\n",
    "                # 每次将子句的encoder输出送进去解码\n",
    "                dec_output, caches = self.decoder(\n",
    "                    dec_input, [_e], None,\n",
    "                    trg_src_attn_bias[:, :, :, :_e.shape[1]], caches)\n",
    "\n",
    "            dec_output = paddle.reshape(\n",
    "                dec_output, shape=[-1, dec_output.shape[-1]])\n",
    "\n",
    "            logits = self.linear(dec_output)\n",
    "            # 拿到当前这一步的概率，并加到上一步的概率上\n",
    "            step_log_probs = paddle.log(F.softmax(logits, axis=-1))\n",
    "            log_probs = paddle.add(x=step_log_probs, y=log_probs)\n",
    "            scores = log_probs\n",
    "            # 获取得分最高的概率和下标\n",
    "            topk_scores, topk_indices = paddle.topk(x=scores, k=1)\n",
    "            \n",
    "            # 判断是否遇到结束符\n",
    "            finished = paddle.equal(topk_indices, end_token_tensor)\n",
    "            # 更新trg_word\n",
    "            trg_word = topk_indices\n",
    "            # 更新概率log_probs\n",
    "            log_probs = topk_scores\n",
    "            \n",
    "            # 将结果保留到predict_ids\n",
    "            predict_ids.append(topk_indices)\n",
    "\n",
    "            if paddle.all(finished).numpy():\n",
    "                break\n",
    "        \n",
    "        # 将predict_ids里面的结果堆叠成Tensor\n",
    "        predict_ids = paddle.stack(predict_ids, axis=0)\n",
    "        finished_seq = paddle.transpose(predict_ids, [1, 2, 0])\n",
    "        finished_scores = topk_scores\n",
    "\n",
    "        return finished_seq, finished_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.训练模型\n",
    "运行`do_train`函数，\n",
    "在`do_train`函数中，配置优化器、损失函数，以及评价指标（Perplexity，即困惑度，常用来衡量语言模型优劣，也可用于机器翻译、文本生成等任务）。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/46df720d17b64f93a64ff52fa943219dea54c53c1d7f47c8a79f482c39fa7201\" width=\"600\" height=\"300\" ></center>\n",
    "<br><center>图12：训练模型 </center></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10,\n",
      " 'beam_size': 1,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.997,\n",
      " 'bos_idx': 0,\n",
      " 'd_inner_hid': 2048,\n",
      " 'd_model': 512,\n",
      " 'device': 'gpu',\n",
      " 'dropout': 0.1,\n",
      " 'eos_idx': 1,\n",
      " 'epoch': 1,\n",
      " 'eps': '1e-9',\n",
      " 'init_from_params': 'trained_models/nist_zhen_full_w5/',\n",
      " 'label_smooth_eps': 0.1,\n",
      " 'learning_rate': 2.0,\n",
      " 'max_length': 256,\n",
      " 'max_out_len': 256,\n",
      " 'n_best': 1,\n",
      " 'n_head': 8,\n",
      " 'n_layer': 6,\n",
      " 'output_file': 'train_dev_test/predict.txt',\n",
      " 'predict_file': 'train_dev_test/test_08.zh.bpe',\n",
      " 'print_step': 10,\n",
      " 'random_seed': 42,\n",
      " 'save_model': 'trained_models',\n",
      " 'save_step': 20,\n",
      " 'shuffle': True,\n",
      " 'shuffle_batch': True,\n",
      " 'special_token': ['<s>', '<e>', '<unk>'],\n",
      " 'src_vocab_fpath': 'train_dev_test/nist.20k.zh.vocab',\n",
      " 'src_vocab_size': 10000,\n",
      " 'training_file': 'train_dev_test/demo.train.zhen.bpe',\n",
      " 'trg_vocab_fpath': 'train_dev_test/nist.10k.en.vocab',\n",
      " 'trg_vocab_size': 10000,\n",
      " 'unk_idx': 2,\n",
      " 'use_amp': False,\n",
      " 'validation_file': 'train_dev_test/demo.dev.zhen.bpe',\n",
      " 'waitk': 5,\n",
      " 'warmup_steps': 8000,\n",
      " 'weight_sharing': False}\n"
     ]
    }
   ],
   "source": [
    "# 读入参数\n",
    "yaml_file = 'transformer.yaml'\n",
    "with open(yaml_file, 'rt') as f:\n",
    "    args = AttrDict(yaml.safe_load(f))\n",
    "    pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train(args):\n",
    "    # 设置在GPU/CPU/XPU上运行\n",
    "    paddle.set_device(args.device)\n",
    "\n",
    "    # 设置随机种子\n",
    "    random_seed = eval(str(args.random_seed))\n",
    "    if random_seed is not None:\n",
    "        paddle.seed(random_seed)\n",
    "\n",
    "    # 获取Dataloader\n",
    "    (train_loader), (eval_loader) = create_data_loader(\n",
    "        args, places=paddle.get_device())\n",
    "\n",
    "    # 声明模型\n",
    "    transformer = SimultaneousTransformer(\n",
    "        args.src_vocab_size, args.trg_vocab_size, args.max_length + 1,\n",
    "        args.n_layer, args.n_head, args.d_model, args.d_inner_hid, args.dropout,\n",
    "        args.weight_sharing, args.bos_idx, args.eos_idx, args.waitk)\n",
    "    \n",
    "\n",
    "    print('waitk=', args.waitk)\n",
    "\n",
    "    # 定义Loss\n",
    "    criterion = CrossEntropyCriterion(args.label_smooth_eps, args.bos_idx)\n",
    "\n",
    "    # 定义学习率的衰减策略\n",
    "    scheduler = paddle.optimizer.lr.NoamDecay(args.d_model, args.warmup_steps,\n",
    "                                              args.learning_rate)\n",
    "    # 定义优化器\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "        learning_rate=scheduler,\n",
    "        beta1=args.beta1,\n",
    "        beta2=args.beta2,\n",
    "        epsilon=float(args.eps),\n",
    "        parameters=transformer.parameters())\n",
    "\n",
    "    step_idx = 0\n",
    "\n",
    "    # 按epoch迭代训练\n",
    "    for pass_id in range(args.epoch):\n",
    "        batch_id = 0\n",
    "        for input_data in train_loader:\n",
    "            # 从训练集Dataloader按batch取数据\n",
    "            (src_word, trg_word, lbl_word) = input_data\n",
    "      \n",
    "            # 获得模型输出的logits \n",
    "            logits = transformer(src_word=src_word, trg_word=trg_word)\n",
    "\n",
    "            # 计算loss\n",
    "            sum_cost, avg_cost, token_num = criterion(logits, lbl_word)\n",
    "\n",
    "            # 计算梯度\n",
    "            avg_cost.backward() \n",
    "            # 更新参数\n",
    "            optimizer.step() \n",
    "            # 梯度清零\n",
    "            optimizer.clear_grad() \n",
    "\n",
    "            if (step_idx + 1) % args.print_step == 0 or step_idx == 0:\n",
    "                total_avg_cost = avg_cost.numpy()\n",
    "                # 打印log\n",
    "                logger.info(\n",
    "                    \"step_idx: %d, epoch: %d, batch: %d, avg loss: %f, \"\n",
    "                    \" ppl: %f \" %\n",
    "                    (step_idx, pass_id, batch_id, total_avg_cost,\n",
    "                        np.exp([min(total_avg_cost, 100)])))\n",
    "\n",
    "            if (step_idx + 1) % args.save_step == 0:\n",
    "                # 验证\n",
    "                transformer.eval()\n",
    "                total_sum_cost = 0\n",
    "                total_token_num = 0\n",
    "                with paddle.no_grad():\n",
    "                    for input_data in eval_loader:\n",
    "                        # 从验证集Dataloader按batch取数据\n",
    "                        (src_word, trg_word, lbl_word) = input_data\n",
    "                        # 获得模型输出的logits \n",
    "                        logits = transformer(\n",
    "                            src_word=src_word, trg_word=trg_word)\n",
    "                        # 计算loss\n",
    "                        sum_cost, avg_cost, token_num = criterion(logits,\n",
    "                                                                  lbl_word)\n",
    "                        total_sum_cost += sum_cost.numpy()\n",
    "                        total_token_num += token_num.numpy()\n",
    "                        total_avg_cost = total_sum_cost / total_token_num\n",
    "                    # 打印log\n",
    "                    logger.info(\"validation, step_idx: %d, avg loss: %f, \"\n",
    "                                \" ppl: %f\" %\n",
    "                                (step_idx, total_avg_cost,\n",
    "                                 np.exp([min(total_avg_cost, 100)])))\n",
    "                transformer.train()\n",
    "\n",
    "                if args.save_model:\n",
    "                    # 保存中间模型\n",
    "                    model_dir = os.path.join(args.save_model,\n",
    "                                             \"step_\" + str(step_idx))\n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.makedirs(model_dir)\n",
    "                    # 保存模型参数\n",
    "                    paddle.save(transformer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "                    # 保存优化器参数\n",
    "                    paddle.save(optimizer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdopt\"))\n",
    "\n",
    "            batch_id += 1\n",
    "            step_idx += 1\n",
    "            scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        # 保存最终模型\n",
    "        model_dir = os.path.join(args.save_model, \"step_final\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        # 保存模型参数\n",
    "        paddle.save(transformer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "        # 保存优化器参数\n",
    "        paddle.save(optimizer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdopt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waitk= 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-21 22:24:29,342] [    INFO] - step_idx: 0, epoch: 0, batch: 0, avg loss: 9.265658,  ppl: 10568.766602 \n",
      "[2021-06-21 22:24:59,984] [    INFO] - step_idx: 9, epoch: 0, batch: 9, avg loss: 9.233420,  ppl: 10233.484375 \n",
      "[2021-06-21 22:25:27,962] [    INFO] - step_idx: 19, epoch: 0, batch: 19, avg loss: 9.175573,  ppl: 9658.304688 \n",
      "[2021-06-21 22:25:43,529] [    INFO] - validation, step_idx: 19, avg loss: 9.170717,  ppl: 9611.516602\n"
     ]
    }
   ],
   "source": [
    "do_train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. 预测和评估\n",
    "模型最终训练的效果一般可通过测试集来进行测试，同传类似机器翻译场景，一般计算BLEU值。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/e0ab4ed332f54e62b5a203e20e599b450e2b97b23e674534b582d65b0e5ac6b4\" width=\"600\" height=\"300\" ></center>\n",
    "<br><center>图13： 预测和评估 </center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def do_predict(args):\n",
    "    \n",
    "    paddle.set_device(args.device)\n",
    "\n",
    "    # 获取Dataloader\n",
    "    test_loader, to_tokens = create_infer_loader(args)\n",
    "\n",
    "    # 声明模型\n",
    "    transformer = SimultaneousTransformer(\n",
    "        args.src_vocab_size, args.trg_vocab_size, args.max_length + 1,\n",
    "        args.n_layer, args.n_head, args.d_model, args.d_inner_hid, args.dropout,\n",
    "        args.weight_sharing, args.bos_idx, args.eos_idx, args.waitk)\n",
    "\n",
    "    # 加载预训练模型\n",
    "    assert args.init_from_params, (\n",
    "        \"Please set init_from_params to load the infer model.\")\n",
    "\n",
    "    model_dict = paddle.load(\n",
    "        os.path.join(args.init_from_params, \"transformer.pdparams\"))\n",
    "\n",
    "    # 避免长度大于训练时候设定的长度，这里重新设定 \n",
    "    model_dict[\"src_pos_embedding.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "    model_dict[\"trg_pos_embedding.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "\n",
    "    transformer.load_dict(model_dict)\n",
    "\n",
    "    # 设置评估模式\n",
    "    transformer.eval()\n",
    "\n",
    "    f = open(args.output_file, \"w\", encoding='utf8')\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for input_data in test_loader:\n",
    "            \n",
    "            (src_word, ) = input_data\n",
    "\n",
    "            finished_seq, finished_scores = transformer.greedy_search(\n",
    "                src_word, max_len=args.max_out_len, waitk=args.waitk)\n",
    "            finished_seq = finished_seq.numpy()\n",
    "            finished_scores = finished_scores.numpy()\n",
    "            for idx, ins in enumerate(finished_seq):\n",
    "                for beam_idx, beam in enumerate(ins):\n",
    "                    if beam_idx >= args.n_best:\n",
    "                        break\n",
    "                    id_list = post_process_seq(beam, args.bos_idx, args.eos_idx)\n",
    "                    word_list = to_tokens(id_list)\n",
    "                    sequence = ' '.join(word_list) + \"\\n\"\n",
    "                    f.write(sequence)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/data/vocab.py:217: UserWarning: The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \n",
      "  \"The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \"\n"
     ]
    }
   ],
   "source": [
    "do_predict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型评估\n",
    "预测结果中每行输出是对应行输入的得分最高的翻译，对于使用 BPE 的数据，预测出的翻译结果也将是 BPE 表示的数据，要还原成原始的数据（这里指 tokenize 后的数据）才能进行正确的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 36.29, 72.0/45.2/28.8/18.5 (BP=1.000, ratio=1.025, hyp_len=23631, ref_len=23049)\r\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\r\n"
     ]
    }
   ],
   "source": [
    "# 还原 predict.txt 中的预测结果为 tokenize 后的数据\n",
    "! sed -r 's/(@@ )|(@@ ?$)//g' train_dev_test/predict.txt > train_dev_test/predict.tok.txt\n",
    "# BLEU评估工具来源于 https://github.com/moses-smt/mosesdecoder.git\n",
    "! tar -zxf mosesdecoder.tar.gz\n",
    "#计算multi-bleu\n",
    "! perl mosesdecoder/scripts/generic/multi-bleu.perl train_dev_test/test_08.en.* < train_dev_test/predict.tok.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
