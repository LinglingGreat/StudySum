{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "近年来，基于Transformer结构使用海量数据自监督训练得到的预训练模型不断刷新着自然语言处理各项任务的最好成绩，同时被不断刷新的还有模型规模，大力出奇迹不再只是玩梗。不断上升的模型规模给预测部署带来了巨大困难。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/992898f7b1eb48ea95a84bfb0fe87fa74a5e16b56aa44f65a8116c88e5491a54\" width=700 hspace='10'/>\n",
    "</p>\n",
    "\n",
    "\n",
    "模型压缩技术的发展使得这个问题得到了缓解。模型压缩能够保证一定精度的情况下，降低模型大小，进而减少推理时间，同时提升内存和计算效率。\n",
    "\n",
    "当前模型压缩的基本方法主要包括量化、裁剪和蒸馏。量化和裁剪通常需要更为底层的支持，如低比特和稀疏矩阵运算的支持；相比之下，蒸馏是更为简单有效的模型压缩方法。通过模型蒸馏技术，ERNIE-Tiny在4倍提速的同时模型效果只有少量下降；非Transformer结构的BOW/CNN/RNN简单模型（速度成百上千倍于ERNIE模型）效果也可以有效提升。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/71b64bd7c7b24642ac0cb4428523f9fbbe8ac0ffe7b94c9a9bea4370f3454454\" width=700 hspace='10'/>\n",
    "</p>\n",
    "\n",
    "该项目基于PaddleNLP围绕模型蒸馏进行实践教学，包含以下内容：\n",
    "1. 如何通过PaddleNLP快速使用通用蒸馏模型ERNIE-Tiny在特定任务微调训练\n",
    "2. 如何使用PaddleNLP快速实现特定任务上使用ERNIE模型蒸馏Bi-LSTM模型\n",
    "3. 产出小模型后如何使用Paddle Inference进行预测部署\n",
    "\n",
    "## 环境准备\n",
    "\n",
    "- PaddlePaddle 安装\n",
    "  \n",
    "  本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考[安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html)进行安装\n",
    "\n",
    "- PaddleNLP 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.3)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ERNIE-Tiny 微调\n",
    "\n",
    "ERNIE-Tiny是使用ERNIE 2.0 Base模型经通用蒸馏得到的轻量级模型，蒸馏时使用蒸馏信号（知识）包括ERNIE教师模型的预测结果（logits或软标签，这能够表示更细粒度的类别概率信息，提供信息量更大的知识）和中间各层的结果（包括中间层的输出表征和attention分布）。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2b24b5d2086448c1b20e051cdff0122d6322aee9aa774c33b2968fc48f72a58d\" width=60% hspace='10'/>\n",
    "</p>\n",
    "\n",
    "它更浅（12层->3层transformer block）、更短（字粒度->subword粒度缩短输入长度），并加大宽度（768->1024 hidden size）弥补模型变浅带来的效果损失，在4倍提速的同时模型效果只有少量下降。直接使用ERNIE-Tiny在下游任务上微调即可得到兼顾效果与性能的模型。\n",
    "\n",
    "使用PaddleNLP可以快速实现ERNIE-Tiny在特定任务上的微调训练，方法与此前实践课程中基本无二，只需将模型换成ERNIE-Tiny即可，这里只给出这些代码，更完整的内容可以参考此前教程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-24 16:46:45,921] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/vocab.txt\n",
      "[2021-06-24 16:46:45,926] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/spm_cased_simp_sampled.model\n",
      "[2021-06-24 16:46:45,929] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/dict.wordseg.pickle\n",
      "[2021-06-24 16:46:52,046] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-tiny/ernie_tiny.pdparams\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import ErnieTinyTokenizer, ErnieForSequenceClassification\n",
    "\n",
    "# 创建Ernie Tiny模型使用的tokenzier\n",
    "tokenizer = ErnieTinyTokenizer.from_pretrained('ernie-tiny')\n",
    "# 创建使用Ernie Tiny预训练模型的句子分类模型\n",
    "model = ErnieForSequenceClassification.from_pretrained('ernie-tiny', num_classes=2)\n",
    "# 打印查看Ernie Tiny\n",
    "print(model.ernie.config['num_hidden_layers'])\n",
    "print(model.ernie.config['hidden_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ERNIE 蒸馏 Bi-LSTM\n",
    "\n",
    "虽然ERNIE-Tiny相比ERNIE模型有4倍提速，但这在一些性能要求苛刻的部署场景中是不够的，大量CPU和低时延的场景只能使用轻量级的BOW/CNN/RNN模型，模型蒸馏同样可以用来提升这些模型的效果。\n",
    "\n",
    "这部分参考论文 [Distilling Task-Specific Knowledge from BERT into Simple Neural Networks](https://arxiv.org/abs/1903.12136) 实现在特定任务上使用复杂大模型蒸馏简单模型。这里的任务数据集使用中文情感分类数据集chnsenticorp；教师模型使用ERNIE微调得到的模型，学生模型使用Bi-LSTM模型；蒸馏信号（知识）使用教师模型输出的logits；另外通过数据增强扩充数据并使用教师模型预测获取更多知识。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/faef98bde6924bd6b44045f3423ea322a1e90250387b4de59b8022359a809f0e\" width=\"50%\" height=200\"/>\n",
    "</p>\n",
    "\n",
    "对于教师模型的训练不再赘述，只需将第一部分微调训练中的模型换为教师模型即可，这里只对蒸馏训练学生模型的内容进行介绍。 蒸馏训练的过程也同之前按照 `数据准备 -> 模型定义 -> 优化策略 -> 迭代训练`四步说明；略有不同的只是在数据准备中加入了数据增强，在优化目标中考虑教师模型预测产生的软标签。\n",
    "\n",
    "### 数据准备\n",
    "\n",
    "数据准备流程如下：\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/06401adbddb84815b2d7c60ae6ad21f3eb80ee7b43bd44038ba98271f9a021b0\" width=\"800\" height=200\"/>\n",
    "</p>\n",
    "\n",
    "#### 加载数据集\n",
    "\n",
    "使用PaddleNLP提供的`load_dataset`API，即可一键完成数据集加载，返回包含了相应数据集的`MapDataset`对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1, 'qid': ''}\n",
      "{'text': '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'label': 1, 'qid': ''}\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# 获取内置的数据集\n",
    "train_ds, dev_ds = load_dataset('chnsenticorp', splits=[\"train\", \"dev\"])\n",
    "# 打印查看数据集部分数据\n",
    "for i in range(2):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 数据增强\n",
    "\n",
    "异构网络难以直接使用网络的中间内容作为知识，考虑通过数据增强扩充数据并使用教师模型获取更多的软标签作为知识，参照论文中给出的数据增强方法，这里实现了以下两种策略：\n",
    "\n",
    "- Masking，即以一定的概率将句子中的token替换成[MASK]。（类似图像领域的随机噪声）\n",
    "- n-gram sampling，即以一定的概率从句子中采样n-gram作为样本，其中n的范围可进行设置。（类似图像领域的随机裁剪）\n",
    "\n",
    "在实现中，数据增强基于词（whole word）粒度进行，使用jieba分词。jieba分词也是学生模型Bi-LSTM使用的tokenize方式，顺带将tokenize处理也一并在这里实现；另外教师模型ERNIE使用了不同的tokenize方式（ErnieTokenizer），结果中也将包含这两种tokenize后的数据。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/58fd83b9b4804008a3ed954d2a2599e1eb7e890916b34f8c9c41782918258edc\" width=\"80%\" height=\"200\"/> <br />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-24 16:47:20,422] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jieba\n",
    "from itertools import chain\n",
    "from paddlenlp.transformers import ErnieTokenizer\n",
    "\n",
    "# 教师模型Ernie使用的tokenizer\n",
    "tokenizer = ErnieTokenizer.from_pretrained(\"ernie-1.0\")\n",
    "\n",
    "def apply_data_augmentation(data,\n",
    "                            n_iter=2,\n",
    "                            p_mask=0.1,\n",
    "                            p_ng=0.25,\n",
    "                            ngram_range=(2, 10)):\n",
    "    \"\"\"\n",
    "    数据增强函数\n",
    "    Args:\n",
    "        data：待数据增强的数据集； n_iter： 每条样本进行数据增强的次数；  p_mask：每个token被mask的概率；\n",
    "        p_ng：每条样本进行n-gram采样的概率；  ngram_range：n-gram中n的区间\n",
    "    \"\"\"\n",
    "    # 固定seed便于演示复现\n",
    "    np.random.seed(2021)\n",
    "\n",
    "    # 存放扩充后的数据\n",
    "    new_data = []\n",
    "    # 循环对数据集的每条样本进行数据增强\n",
    "    for example in data:\n",
    "        # 使用jieba分词，基于词粒度进行数据增强\n",
    "        words = [word for word in jieba.cut(example['text'])]\n",
    "        # 学生模型使用jieba分词结果，教师模型使用ErnieTokenizer结果\n",
    "        lstm_tokens, ernie_tokens = words, tokenizer.tokenize(example['text'])\n",
    "        # 将原样本数据加入扩充数据集\n",
    "        new_data.append({\n",
    "            \"lstm_tokens\": lstm_tokens,\n",
    "            \"ernie_tokens\": ernie_tokens,\n",
    "            \"label\": example['label']\n",
    "        })\n",
    "        for _ in range(n_iter):\n",
    "            # 存放数据增强后学生模型和教师模型的tokenize结果\n",
    "            lstm_tokens, ernie_tokens = [], []\n",
    "            # 1. Masking\n",
    "            for word in words:\n",
    "                # 基于词粒度，词内容整体list处理\n",
    "                if np.random.rand() < p_mask:\n",
    "                    lstm_tokens.append(['[UNK]'])\n",
    "                    ernie_tokens.append([tokenizer.mask_token])\n",
    "                else:\n",
    "                    lstm_tokens.append([word])\n",
    "                    ernie_tokens.append(tokenizer.tokenize(word))\n",
    "            # 2. N-gram sampling\n",
    "            if np.random.rand() < p_ng:\n",
    "                ngram_len = min(np.random.randint(ngram_range[0], ngram_range[1] + 1), len(words))\n",
    "                start = np.random.randint(0, len(words) - ngram_len + 1)\n",
    "                lstm_tokens = lstm_tokens[start:start + ngram_len]\n",
    "                ernie_tokens = ernie_tokens[start:start + ngram_len]\n",
    "\n",
    "            # 展开得到tokenize的结果：\n",
    "            # lstm:[[房间], [太小]] -> [房间, 太小] ernie:[[房, 间], [太, 小]] -> [房, 间, 太, 小]\n",
    "            lstm_tokens, ernie_tokens = list(chain(*lstm_tokens)), list(chain(*ernie_tokens))\n",
    "            # 将新样本加入扩充数据集\n",
    "            new_data.append({\n",
    "                \"lstm_tokens\": lstm_tokens,\n",
    "                \"ernie_tokens\": ernie_tokens,\n",
    "                \"label\": example['label']\n",
    "            })\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "实现数据增强策略之后，可以使用数据集对象的`map()`方法完成数据增强的操作。`map()`将使用当前数据集作为参数调用该函数（`batched=True`时）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.920 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lstm_tokens': ['选择', '珠江', '花园', '的', '原因', '就是', '方便', '，', '有', '电动', '扶梯', '直接', '到达', '海边', '，', '周围', '餐馆', '、', '食廊', '、', '商场', '、', '超市', '、', '摊位', '一应俱全', '。', '酒店', '装修', '一般', '，', '但', '还', '算', '整洁', '。', ' ', '泳池', '在', '大堂', '的', '屋顶', '，', '因此', '很小', '，', '不过', '女儿', '倒', '是', '喜欢', '。', ' ', '包', '的', '早餐', '是', '西式', '的', '，', '还', '算', '丰富', '。', ' ', '服务', '吗', '，', '一般'], 'ernie_tokens': ['选', '择', '珠', '江', '花', '园', '的', '原', '因', '就', '是', '方', '便', '，', '有', '电', '动', '扶', '梯', '直', '接', '到', '达', '海', '边', '，', '周', '围', '餐', '馆', '、', '食', '廊', '、', '商', '场', '、', '超', '市', '、', '摊', '位', '一', '应', '俱', '全', '。', '酒', '店', '装', '修', '一', '般', '，', '但', '还', '算', '整', '洁', '。', '泳', '池', '在', '大', '堂', '的', '屋', '顶', '，', '因', '此', '很', '小', '，', '不', '过', '女', '儿', '倒', '是', '喜', '欢', '。', '包', '的', '早', '餐', '是', '西', '式', '的', '，', '还', '算', '丰', '富', '。', '服', '务', '吗', '，', '一', '般'], 'label': 1}\n",
      "{'lstm_tokens': ['选择', '珠江', '花园', '的', '原因', '就是', '方便', '，', '有', '电动', '[UNK]', '[UNK]', '到达', '海边', '[UNK]', '周围', '餐馆', '、', '食廊', '、', '商场', '、', '超市', '、', '摊位', '一应俱全', '。', '酒店', '装修', '[UNK]', '，', '但', '还', '算', '整洁', '。', ' ', '泳池', '在', '大堂', '的', '屋顶', '，', '因此', '很小', '，', '不过', '女儿', '倒', '是', '喜欢', '。', ' ', '包', '的', '早餐', '是', '西式', '的', '，', '[UNK]', '算', '丰富', '。', ' ', '服务', '[UNK]', '，', '一般'], 'ernie_tokens': ['选', '择', '珠', '江', '花', '园', '的', '原', '因', '就', '是', '方', '便', '，', '有', '电', '动', '[MASK]', '[MASK]', '到', '达', '海', '边', '[MASK]', '周', '围', '餐', '馆', '、', '食', '廊', '、', '商', '场', '、', '超', '市', '、', '摊', '位', '一', '应', '俱', '全', '。', '酒', '店', '装', '修', '[MASK]', '，', '但', '还', '算', '整', '洁', '。', '泳', '池', '在', '大', '堂', '的', '屋', '顶', '，', '因', '此', '很', '小', '，', '不', '过', '女', '儿', '倒', '是', '喜', '欢', '。', '包', '的', '早', '餐', '是', '西', '式', '的', '，', '[MASK]', '算', '丰', '富', '。', '服', '务', '[MASK]', '，', '一', '般'], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# 执行数据增强，`batched=True`时执行`data_aug_fn(train_ds)`\n",
    "train_ds = train_ds.map(apply_data_augmentation, batched=True)\n",
    "\n",
    "# 打印查看数据增强后的部分结果\n",
    "for i in range(2):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### tokenize 与 id 化\n",
    "\n",
    "获得数据增强扩充的数据集后，需要将文本数据转换为模型使用的id数据，包括tokenize和id化处理。由于tokenize处理已经在数据增强过程中一并完成，下面实现中可选的进行tokenize。另外由于学生模型Bi-LSTM和教师模型ERNIE使用了不同的tokenize方式，对应也需要两个不同的转换处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.data import Vocab\n",
    "\n",
    "# 学生模型id转换使用的词典\n",
    "vocab = Vocab.load_vocabulary(\n",
    "    filepath='senta_word_dict_subset.txt',\n",
    "    unk_token='[UNK]',\n",
    "    pad_token='[PAD]')\n",
    "\n",
    "def convert_example_for_lstm(example, max_seq_length=128, is_tokenized=True):\n",
    "    \"\"\"\n",
    "    将单条样本转成学生模型（Bi-LSTM）需要的输入\n",
    "    \"\"\"\n",
    "    # tokenize分词\n",
    "    words = example['lstm_tokens'] if is_tokenized else list(jieba.cut(example['text']))\n",
    "    # 使用vocab转为id数据\n",
    "    input_ids = [vocab[word] for word in words][:max_seq_length]\n",
    "    valid_length = np.array(len(input_ids), dtype='int64')\n",
    "    return input_ids, valid_length, np.array(example['label'], dtype=\"int64\")\n",
    "\n",
    "def convert_example_for_ernie(example, max_seq_length=128):\n",
    "    \"\"\"\n",
    "    将单条样本转成教师模型（ERNIE）需要的输入\n",
    "    \"\"\"\n",
    "    example = tokenizer(example['ernie_tokens'], max_seq_len=max_seq_length, is_split_into_words=True)\n",
    "    return example['input_ids'], example['token_type_ids']\n",
    "\n",
    "def convert_example_for_distill(example):\n",
    "    \"\"\"\n",
    "    将单条样本同时转成大小模型均需要的输入\n",
    "    \"\"\"\n",
    "    # 得到Ernie的输入\n",
    "    ernie_inputs = convert_example_for_ernie(example)\n",
    "    # 得到Bi-LSTM的输入\n",
    "    lstm_inputs = convert_example_for_lstm(example)\n",
    "    return ernie_inputs + lstm_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "之后同样使用数据集的`map()`方法完成转换处理。注意，不同于上面数据增强的操作，这里的转换函数作用于单条样本（对应`batched=False`）。另外这里也将转换的操作延迟到实际取数据时进行，这可以通过设置`lazy=True`实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 352, 790, 1252, 409, 283, 509, 5, 250, 196, 113, 10, 58, 518, 4, 9, 128, 70, 1495, 1855, 339, 293, 45, 302, 233, 554, 4, 544, 637, 1134, 774, 6, 494, 2068, 6, 278, 191, 6, 634, 99, 6, 2678, 144, 7, 149, 1573, 62, 12043, 661, 737, 371, 435, 7, 689, 4, 255, 201, 559, 407, 1308, 12043, 2275, 1110, 11, 19, 842, 5, 1207, 878, 4, 196, 198, 321, 96, 4, 16, 93, 291, 464, 1099, 10, 692, 811, 12043, 392, 5, 748, 1134, 10, 213, 220, 5, 4, 201, 559, 723, 595, 12043, 231, 112, 1114, 4, 7, 689, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9706, 6985, 5435, 23774, 22611, 3344, 26701, 12025, 23587, 14290, 10625, 10718, 7068, 15185, 12025, 277, 12926, 8654, 13652, 8654, 1069, 8654, 18774, 8654, 13786, 17418, 2412, 7729, 9070, 19588, 12025, 6052, 18047, 5398, 14850, 2412, 1, 25463, 28417, 18905, 23774, 25923, 12025, 29203, 1, 12025, 20801, 5771, 16023, 18299, 4389, 2412, 1, 6433, 23774, 23554, 18299, 2259, 23774, 12025, 18047, 5398, 16963, 2412, 1, 20176, 15138, 12025, 19588], array(69), array(1))\n",
      "([1, 352, 790, 1252, 409, 283, 509, 5, 250, 196, 113, 10, 58, 518, 4, 9, 128, 70, 3, 3, 45, 302, 233, 554, 3, 544, 637, 1134, 774, 6, 494, 2068, 6, 278, 191, 6, 634, 99, 6, 2678, 144, 7, 149, 1573, 62, 12043, 661, 737, 371, 435, 3, 4, 255, 201, 559, 407, 1308, 12043, 2275, 1110, 11, 19, 842, 5, 1207, 878, 4, 196, 198, 321, 96, 4, 16, 93, 291, 464, 1099, 10, 692, 811, 12043, 392, 5, 748, 1134, 10, 213, 220, 5, 4, 3, 559, 723, 595, 12043, 231, 112, 3, 4, 7, 689, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9706, 6985, 5435, 23774, 22611, 3344, 26701, 12025, 23587, 14290, 1, 1, 7068, 15185, 1, 277, 12926, 8654, 13652, 8654, 1069, 8654, 18774, 8654, 13786, 17418, 2412, 7729, 9070, 1, 12025, 6052, 18047, 5398, 14850, 2412, 1, 25463, 28417, 18905, 23774, 25923, 12025, 29203, 1, 12025, 20801, 5771, 16023, 18299, 4389, 2412, 1, 6433, 23774, 23554, 18299, 2259, 23774, 12025, 1, 5398, 16963, 2412, 1, 20176, 1, 12025, 19588], array(69), array(1))\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# 训练集转换，`lazy=True`时在实际取数据时进行转换\n",
    "train_ds = train_ds.map(convert_example_for_distill, lazy=True)\n",
    "\n",
    "# 验证集转换\n",
    "dev_ds = dev_ds.map(partial(convert_example_for_lstm, is_tokenized=False), lazy=True)\n",
    "\n",
    "# 打印查看id化后的部分结果\n",
    "for i in range(2):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 构造batch数据\n",
    "\n",
    "每条样本转换为模型使用的id数据之后，还需要将数据组织成batch输入。这包括两个操作：\n",
    "\n",
    "1. 将多条样本组成batch，这可以通过Paddle的`paddle.io.BatchSampler`接口实现。（batch_sampler组件）\n",
    "2. 将batch内的数据的各字段进行补齐等操作（tensor化），这可以通过`paddlenlp.data`下的`Pad`、`Stack`等接口实现。（batchify_fn组件）\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/30e43d4659384375a2a2c1b890ca5a995c4324d7168e49cebf1d2a1e99161f7d\" width=700 hspace='10'/>\n",
    "</p>\n",
    "\n",
    "在数据集、batch_sampler 组件和 batchify_fn 组件都定义完成之后，可以使用`paddle.io.DataLoader`构造batch数据的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "\n",
    "# 定义训练集上的batch sampler\n",
    "train_batch_sampler = paddle.io.BatchSampler(\n",
    "    train_ds, batch_size=32, shuffle=True)\n",
    "# 定义训练集上的batchify_fn，用于对每一个特征字段进行处理\n",
    "train_batchify_fn = Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),       # ERNIE: input ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # ERNIE: segment ids\n",
    "    Pad(axis=0, pad_val=vocab['PAD']),                 # Bi-LSTM: input ids\n",
    "    Stack(dtype=\"int64\"),                              # Bi-LSTM: sequence length\n",
    "    Stack(dtype=\"int64\")                               # label\n",
    ")\n",
    "# 构造训练集的dataloader\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    collate_fn=train_batchify_fn)\n",
    "\n",
    "# 定义验证集上的batch sampler\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\n",
    "    dev_ds, batch_size=32, shuffle=False)\n",
    "# 定义验证集上的batchify_fn，用于对每一个特征字段进行处理\n",
    "dev_batchify_fn = Tuple(\n",
    "    Pad(axis=0, pad_val=vocab['PAD']),                 # Bi-LSTM: input ids\n",
    "    Stack(dtype=\"int64\"),                              # Bi-LSTM: sequence length\n",
    "    Stack(dtype=\"int64\")                               # label\n",
    ")\n",
    "# 构造验证集的dataloader\n",
    "dev_data_loader = paddle.io.DataLoader(\n",
    "    dataset=dev_ds,\n",
    "    batch_sampler=dev_batch_sampler,\n",
    "    collate_fn=dev_batchify_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "到这里数据集准备就全部完成了，下一步我们需要实现模型组网。\n",
    "\n",
    "\n",
    "### 模型定义\n",
    "\n",
    "蒸馏训练中的教师模型和学生模型分别为ERNIE和Bi-LSTM\n",
    "\n",
    "#### ERNIE 教师模型\n",
    "\n",
    "目前PaddleNLP已经内置了包括ERNIE在内的多种基于预训练模型的常用任务的下游网络，这些网络在`paddlenlp.transformers`下，均可实现一键调用。这里直接加载提前训练好的教师模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import ErnieForSequenceClassification\n",
    "\n",
    "# 导入已微调训练好的教师模型\n",
    "teacher = ErnieForSequenceClassification.from_pretrained(\"/home/aistudio/data/data88390/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Bi-LSTM 学生模型\n",
    "\n",
    "参照论文中的结构进行Bi-LSTM模型实现：embedding层后经过一个双向LSTM，将两个方向最后的hidden state拼接后送入带有tanh激活函数的线性变换层，最后由分类层输出预测结果。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/043b1f35c78c4b8092f3d6ebc45564becf903458aa164f5d8e1764b44cc44889\" width=\"50%\" height=\"100%\"/> <br />\n",
    "</p>\n",
    "\n",
    "其中a表示输入的embeddings，b表示双向LSTM，c、d分别表示反向和前向的隐藏状态，e、g表示两个全连接层，其中e中带有激活函数，f是隐藏层表示，h是网络的logit输出，i表示softmax激活函数，j是最终输出的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.initializer as I\n",
    "\n",
    "class BiLSTM(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_dim,\n",
    "                 hidden_size,\n",
    "                 output_dim,\n",
    "                 num_layers=1,\n",
    "                 dropout_prob=0.0,\n",
    "                 padding_idx=0,\n",
    "                 init_scale=0.1):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedder = nn.Embedding(vocab_size, embed_dim, padding_idx)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            'bidirect', # 双向LSTM\n",
    "            dropout=dropout_prob)\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_size * 2,\n",
    "            hidden_size,\n",
    "            weight_attr=paddle.ParamAttr(initializer=I.Uniform(\n",
    "                low=-init_scale, high=init_scale)))\n",
    "\n",
    "        self.output_layer = nn.Linear(\n",
    "            hidden_size,\n",
    "            output_dim,\n",
    "            weight_attr=paddle.ParamAttr(initializer=I.Uniform(\n",
    "                low=-init_scale, high=init_scale)))\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        # 对文本输入接入Embedding层\n",
    "        x_embed = self.embedder(x)\n",
    "        # 文本表示、文本长度作为双向LSTM的输入，经过计算得到LSTM的输出和终态表示\n",
    "        lstm_out, (hidden, _) = self.lstm(\n",
    "            x_embed, sequence_length=seq_len)\n",
    "        # 将终态两个方向最后一层的隐状态拼接在一起\n",
    "        out = paddle.concat((hidden[-2, :, :], hidden[-1, :, :]), axis=1)\n",
    "        # 经过一层线性层和Tanh激活函数\n",
    "        out = paddle.tanh(self.fc(out))\n",
    "        # 经过最后一层线性层得到logit并返回\n",
    "        logits = self.output_layer(out)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# 根据超参创建Bi-LSTM学生模型\n",
    "emb_dim = 300\n",
    "hidden_size = 300\n",
    "vocab_size = 29496\n",
    "output_dim = 2\n",
    "padding_idx = 0\n",
    "num_layers = 1\n",
    "dropout_prob = 0.1\n",
    "student = BiLSTM(vocab_size, emb_dim, hidden_size,\n",
    "            output_dim, num_layers, dropout_prob,\n",
    "            padding_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 优化策略与模型训练\n",
    "\n",
    "完成模型定义后，下一步创建优化目标和优化器并迭代数据进行蒸馏训练。\n",
    "\n",
    "相比于此前的模型训练，这里的蒸馏训练以最小化学生模型和教师模型软标签预测结果的均方误差损失为优化目标。单步训练过程也多出一个执行教师模型的前向预测获取软标签的步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1, epoch: 0, batch: 0, loss: 8.757569\n",
      "global step 2, epoch: 0, batch: 1, loss: 7.154593\n",
      "The best accuracy is: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义损失函数\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = paddle.optimizer.Adadelta(\n",
    "    learning_rate=1.0, rho=0.95, parameters=student.parameters())\n",
    "\n",
    "# 教师模型设置为eval模式\n",
    "teacher.eval()\n",
    "\n",
    "# 定义评估指标与评估函数\n",
    "metric = paddle.metric.Accuracy()\n",
    "best_acc = 0\n",
    "def evaluate(model, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        input_ids, seq_len, labels = batch\n",
    "        logits = model(input_ids, seq_len)\n",
    "        # 每个step调用compute和update\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "    # 最后调用accumulate得到最后的评价指标（ACC）值\n",
    "    res = metric.accumulate()\n",
    "    model.train()\n",
    "    return res\n",
    "\n",
    "global_step = 0\n",
    "eval_freq = 200\n",
    "epochs = 6\n",
    "max_step = 2\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(train_data_loader):\n",
    "        global_step += 1\n",
    "        # 从data loader中取出一个batch data\n",
    "        teacher_input_ids, teacher_segment_ids, student_input_ids, seq_len, labels = batch\n",
    "\n",
    "        # 教师模型执行前向计算，获取logits作为蒸馏信号。`no_grad`下的内容将不进行梯度计算\n",
    "        with paddle.no_grad():\n",
    "            teacher_logits = teacher(teacher_input_ids, teacher_segment_ids)\n",
    "\n",
    "        # 学生模型执行前向计算\n",
    "        logits = student(student_input_ids, seq_len)\n",
    "\n",
    "        # 计算学生模型和教师模型logits输出的均方误差损失\n",
    "        loss = mse_loss(logits, teacher_logits)\n",
    "\n",
    "        # 学生模型执行反向计算获取梯度，梯度计算及参数更新、优化器更新\n",
    "        loss.backward()\n",
    "        # 优化器更新学生模型的参数权重，然后清空梯度\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        # 打印日志\n",
    "        print(\"global step %d, epoch: %d, batch: %d, loss: %f\" % (global_step, epoch, i, loss))\n",
    "        #  对当前的模型进行评估并保存\n",
    "        if global_step % eval_freq == 0:\n",
    "            acc = evaluate(student, metric, dev_data_loader)\n",
    "            print(\"accuracy at step %d: %s, \" % (global_step, acc))\n",
    "            if best_acc < acc:\n",
    "                paddle.save(\n",
    "                    student.state_dict(),\n",
    "                    os.path.join(\"trained_models\",\n",
    "                        \"step_\" + str(global_step) + \".pdparams\"))\n",
    "                best_acc = acc\n",
    "        if global_step == max_step: break\n",
    "    if global_step == max_step: break\n",
    "print(\"The best accuracy is: %s\" % (best_acc,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下面是ERNIE模型、Bi-LSTM模型以及蒸馏得到的Bi-LSTM模型在ChnSentiCorp的验证集上的准确率指标：\n",
    "\n",
    "|                   | Accuracy(%) |\n",
    "| ----------------- | ----------- |\n",
    "| ERNIE-1.0         | 95.55       |\n",
    "| Bi-LSTM           | 92.00       |\n",
    "| Distilled Bi-LSTM | 93.333      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 预测部署\n",
    "\n",
    "模型训练完成之后接下来我们实现模型的预测部署。虽然训练阶段使用的动态图模式有诸多优点，包括Python风格的编程体验（使用RNN等包含控制流的网络时尤为明显）、友好的debug交互机制等。但Python动态图模式无法更好的满足预测部署阶段的性能要求，同时也限制了部署环境。\n",
    "\n",
    "静态图是预测部署通常采用的方式。通过静态图中预先定义的网络结构，一方面无需像动态图那样执行开销较大的Python代码；另一方面，预先固定的图结构也为基于图的优化提供了可能，这些能够有效提升预测部署的性能。常用的基于图的优化策略有内存复用和算子融合，这需要预测引擎的支持。下面是算子融合的一个示例（将Transformer Block的FFN中的`矩阵乘->加bias->relu激活`替换为单个算子）：\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/88ec0e7f9622453582c9f5d7a865ff8eb5aff0194b154cee875bf6af4d69a7db)\n",
    "\n",
    "\n",
    "高性能预测部署需要静态图模型导出和预测引擎两方面的支持，这里分别介绍。\n",
    "\n",
    "### 动转静导出模型\n",
    "\n",
    "基于静态图的预测部署要求将动态图的模型转换为静态图形式的模型（网络结构和参数权重）。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/0ddf501ed8654531abc6379d52b03b28d3eb2e928fe648e5b02d6b3a4a4e03d0\" width=\"800\" height=200\"/>\n",
    "</p>\n",
    "\n",
    "Paddle静态图形式的模型（由变量和算子构成的网络结构）使用`Program`来存放，`Program`的构造可以通过Paddle的静态图模式说明，静态图模式下网络构建执行的各API会将输入输出变量和使用的算子添加到`Program`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ // block 0\n",
      "    var x : LOD_TENSOR.shape(-1, 128).dtype(float32).stop_gradient(True)\n",
      "    persist trainable param linear_0.w_0 : LOD_TENSOR.shape(128, 256).dtype(float32).stop_gradient(False)\n",
      "    var linear_1.tmp_0 : LOD_TENSOR.shape(-1, 256).dtype(float32).stop_gradient(False)\n",
      "\n",
      "    {Out=['linear_1.tmp_0']} = matmul(inputs={X=['x'], Y=['linear_0.w_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, alpha = 1.0, force_fp32_output = False, fused_reshape_Out = [], fused_reshape_X = [], fused_reshape_Y = [], fused_transpose_Out = [], fused_transpose_X = [], fused_transpose_Y = [], head_number = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], transpose_X = False, transpose_Y = False, use_mkldnn = False, use_quantizer = False)\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "# 默认为动态图模式，这里开启静态图模式\n",
    "paddle.enable_static()\n",
    "# 定义输入变量，静态图下变量只是一个符号化表示，并不像动态图 Tensor 那样持有实际数据\n",
    "x = paddle.static.data(shape=[None, 128], dtype='float32', name='x')\n",
    "linear = paddle.nn.Linear(128, 256, bias_attr=False)\n",
    "# 定义计算网络，输入和输出也都是符号化表示\n",
    "y = linear(x)\n",
    "# 打印 program\n",
    "print(paddle.static.default_main_program())\n",
    "# 关闭静态图模式\n",
    "paddle.disable_static()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "结合Paddle的静态图机制，Paddle提供了从动态图模型转换并导出静态图模型（包括网络结构和参数权重）的功能，通过`jit.to_static`和`jit.save`完成。\n",
    "\n",
    "1. `paddle.jit.to_static` 完成动态图模型到静态图模型的转换。\n",
    "\n",
    "- 网络结构：将动态图模型的forward函数转写（重点将Python控制流转换为Paddle对应API的调用），然后以静态图模式执行，生成Program。\n",
    "- 参数权重：将动态图模型的参数在生成Program时对应到其中的变量上。\n",
    "\n",
    "动转静时还需要使用`InputSpec`提供模型输入的描述信息（shape、dtype和name）保证Program构建过程中形状和数据类型的正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    }
   ],
   "source": [
    "# 设置log输出转写的代码内容\n",
    "# paddle.jit.set_code_level(100)\n",
    "\n",
    "# 加载动态图模型\n",
    "param_state_dict = paddle.load(\"best_model_7380_933.pdparams\")\n",
    "student.set_state_dict(param_state_dict)\n",
    "\n",
    "# 动转静，通过`input_spec`给出模型所需输入数据的描述，shape中的None代表可变的大小，类似上面静态图模式中的`paddle.static.data`\n",
    "model = paddle.jit.to_static(\n",
    "    student,\n",
    "    input_spec=[\n",
    "        paddle.static.InputSpec(\n",
    "            shape=[None, None], dtype=\"int64\"),  # input_ids: [batch_size, max_seq_len]\n",
    "        paddle.static.InputSpec(\n",
    "            shape=[None], dtype=\"int64\")  # length: [batch_size]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ // block 0\n",
      "    var x : LOD_TENSOR.shape(-1, -1).dtype(int64).stop_gradient(False)\n",
      "    var seq_len : LOD_TENSOR.shape(-1,).dtype(int64).stop_gradient(False)\n",
      "    persist trainable param embedding_6.w_0 : LOD_TENSOR.shape(29496, 300).dtype(float32).stop_gradient(False)\n",
      "    var embedding_0.tmp_0 : LOD_TENSOR.shape(-1, -1, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_0.w_0 : LOD_TENSOR.shape(1200, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_0.w_1 : LOD_TENSOR.shape(1200, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_0.b_0 : LOD_TENSOR.shape(1200,).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_0.b_1 : LOD_TENSOR.shape(1200,).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_1.w_0 : LOD_TENSOR.shape(1200, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_1.w_1 : LOD_TENSOR.shape(1200, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_1.b_0 : LOD_TENSOR.shape(1200,).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param lstm_cell_1.b_1 : LOD_TENSOR.shape(1200,).dtype(float32).stop_gradient(False)\n",
      "    persist var lstm_0._generated_var_0 : LOD_TENSOR.shape(128, 32, 600).dtype(uint8).stop_gradient(False)\n",
      "    var fill_constant_batch_size_like_0.tmp_0 : LOD_TENSOR.shape(2, -1, 300).dtype(float32).stop_gradient(True)\n",
      "    var fill_constant_batch_size_like_1.tmp_0 : LOD_TENSOR.shape(2, -1, 300).dtype(float32).stop_gradient(True)\n",
      "    var transpose_0.tmp_0 : LOD_TENSOR.shape(-1, -1, 300).dtype(float32).stop_gradient(False)\n",
      "    var transpose_0.tmp_1 : LOD_TENSOR.shape(0, -1, -1, 300).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_0 : LOD_TENSOR.shape(-1, -1, 600).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_1 : LOD_TENSOR.shape(2, -1, 300).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_2 : LOD_TENSOR.shape(2, -1, 300).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_3 : LOD_TENSOR.shape().dtype(uint8).stop_gradient(True)\n",
      "    var transpose_1.tmp_0 : LOD_TENSOR.shape(-1, -1, 600).dtype(float32).stop_gradient(False)\n",
      "    var transpose_1.tmp_1 : LOD_TENSOR.shape(0, -1, -1, 600).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_1_slice_0 : LOD_TENSOR.shape(-1, 300).dtype(float32).stop_gradient(False)\n",
      "    var lstm_0.tmp_1_slice_1 : LOD_TENSOR.shape(-1, 300).dtype(float32).stop_gradient(False)\n",
      "    var concat_0.tmp_0 : LOD_TENSOR.shape(-1, 600).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param linear_94.w_0 : LOD_TENSOR.shape(600, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param linear_94.b_0 : LOD_TENSOR.shape(300,).dtype(float32).stop_gradient(False)\n",
      "    var linear_0.tmp_0 : LOD_TENSOR.shape(-1, 300).dtype(float32).stop_gradient(False)\n",
      "    var linear_0.tmp_1 : LOD_TENSOR.shape(-1, 300).dtype(float32).stop_gradient(False)\n",
      "    var tanh_0.tmp_0 : LOD_TENSOR.shape(-1, 300).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param linear_95.w_0 : LOD_TENSOR.shape(300, 2).dtype(float32).stop_gradient(False)\n",
      "    persist trainable param linear_95.b_0 : LOD_TENSOR.shape(2,).dtype(float32).stop_gradient(False)\n",
      "    var linear_1.tmp_0 : LOD_TENSOR.shape(-1, 2).dtype(float32).stop_gradient(False)\n",
      "    var linear_1.tmp_1 : LOD_TENSOR.shape(-1, 2).dtype(float32).stop_gradient(False)\n",
      "\n",
      "    {Out=['embedding_0.tmp_0']} = lookup_table_v2(inputs={Ids=['x'], W=['embedding_6.w_0']}, epmap = [], height_sections = [], is_distributed = False, is_sparse = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], padding_idx = 0, remote_prefetch = False, table_names = [], trainer_id = 0)\n",
      "    {Out=['fill_constant_batch_size_like_0.tmp_0']} = fill_constant_batch_size_like(inputs={Input=['embedding_0.tmp_0']}, dtype = 5, force_cpu = False, input_dim_idx = 0, op_device = , op_namescope = /, op_role = 0, op_role_var = [], output_dim_idx = 1, shape = [2, -1, 300], str_value = 0.0, value = 0.0)\n",
      "    {Out=['fill_constant_batch_size_like_1.tmp_0']} = fill_constant_batch_size_like(inputs={Input=['embedding_0.tmp_0']}, dtype = 5, force_cpu = False, input_dim_idx = 0, op_device = , op_namescope = /, op_role = 0, op_role_var = [], output_dim_idx = 1, shape = [2, -1, 300], str_value = 0.0, value = 0.0)\n",
      "    {Out=['transpose_0.tmp_0'], XShape=['transpose_0.tmp_1']} = transpose2(inputs={X=['embedding_0.tmp_0']}, axis = [1, 0, 2], data_format = AnyLayout, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False)\n",
      "    {DropoutState=['lstm_0._generated_var_0'], Out=['lstm_0.tmp_0'], Reserve=['lstm_0.tmp_3'], State=['lstm_0.tmp_1', 'lstm_0.tmp_2']} = rnn(inputs={Input=['transpose_0.tmp_0'], PreState=['fill_constant_batch_size_like_0.tmp_0', 'fill_constant_batch_size_like_1.tmp_0'], SequenceLength=['seq_len'], WeightList=['lstm_cell_0.w_0', 'lstm_cell_0.w_1', 'lstm_cell_1.w_0', 'lstm_cell_1.w_1', 'lstm_cell_0.b_0', 'lstm_cell_0.b_1', 'lstm_cell_1.b_0', 'lstm_cell_1.b_1']}, dropout_prob = 0.10000000149011612, hidden_size = 300, input_size = 300, is_bidirec = True, is_test = False, mode = LSTM, num_layers = 1, op_device = , op_namescope = /, op_role = 0, op_role_var = [], seed = 0)\n",
      "    {Out=['transpose_1.tmp_0'], XShape=['transpose_1.tmp_1']} = transpose2(inputs={X=['lstm_0.tmp_0']}, axis = [1, 0, 2], data_format = AnyLayout, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False)\n",
      "    {Out=['lstm_0.tmp_1_slice_0']} = slice(inputs={EndsTensor=[], EndsTensorList=[], Input=['lstm_0.tmp_1'], StartsTensor=[], StartsTensorList=[]}, axes = [0], decrease_axis = [0], ends = [-1], infer_flags = [1], op_device = , op_namescope = /, op_role = 0, op_role_var = [], starts = [-2])\n",
      "    {Out=['lstm_0.tmp_1_slice_1']} = slice(inputs={EndsTensor=[], EndsTensorList=[], Input=['lstm_0.tmp_1'], StartsTensor=[], StartsTensorList=[]}, axes = [0], decrease_axis = [0], ends = [10000000], infer_flags = [1], op_device = , op_namescope = /, op_role = 0, op_role_var = [], starts = [-1])\n",
      "    {Out=['concat_0.tmp_0']} = concat(inputs={AxisTensor=[], X=['lstm_0.tmp_1_slice_0', 'lstm_0.tmp_1_slice_1']}, axis = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False)\n",
      "    {Out=['linear_0.tmp_0']} = matmul(inputs={X=['concat_0.tmp_0'], Y=['linear_94.w_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, alpha = 1.0, force_fp32_output = False, fused_reshape_Out = [], fused_reshape_X = [], fused_reshape_Y = [], fused_transpose_Out = [], fused_transpose_X = [], fused_transpose_Y = [], head_number = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], transpose_X = False, transpose_Y = False, use_mkldnn = False, use_quantizer = False)\n",
      "    {Out=['linear_0.tmp_1']} = elementwise_add(inputs={X=['linear_0.tmp_0'], Y=['linear_94.b_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, axis = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False, x_data_format = , y_data_format = )\n",
      "    {Out=['tanh_0.tmp_0']} = tanh(inputs={X=['linear_0.tmp_1']}, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_cudnn = False, use_mkldnn = False)\n",
      "    {Out=['linear_1.tmp_0']} = matmul(inputs={X=['tanh_0.tmp_0'], Y=['linear_95.w_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, alpha = 1.0, force_fp32_output = False, fused_reshape_Out = [], fused_reshape_X = [], fused_reshape_Y = [], fused_transpose_Out = [], fused_transpose_X = [], fused_transpose_Y = [], head_number = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], transpose_X = False, transpose_Y = False, use_mkldnn = False, use_quantizer = False)\n",
      "    {Out=['linear_1.tmp_1']} = elementwise_add(inputs={X=['linear_1.tmp_0'], Y=['linear_95.b_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, axis = 1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False, x_data_format = , y_data_format = )\n",
      "}\n",
      "\n",
      "[var x : LOD_TENSOR.shape(-1, -1).dtype(int64).stop_gradient(False), var seq_len : LOD_TENSOR.shape(-1,).dtype(int64).stop_gradient(False)]\n",
      "embedding_6.w_0\n",
      "<bound method PyCapsule.value of Parameter containing:\n",
      "Tensor(shape=[29496, 300], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,  0.        ,  0.        ],\n",
      "        [ 0.11659081, -0.04384097, -0.04026616, ..., -0.05641207, -0.23784846, -0.09599022],\n",
      "        [-0.01071034, -0.00254965,  0.01612471, ..., -0.00325200, -0.02263010, -0.00263259],\n",
      "        ...,\n",
      "        [-0.00839648,  0.00858942,  0.00404084, ..., -0.01468238, -0.00842635,  0.01307028],\n",
      "        [ 0.01002004, -0.00883020,  0.00299168, ..., -0.00572370,  0.01096750, -0.00613657],\n",
      "        [-0.02629061,  0.04087983, -0.06212689, ..., -0.03645510,  0.02588729, -0.01578910]])>\n"
     ]
    }
   ],
   "source": [
    "# 打印动转静产生的Program以及输入变量\n",
    "print(model.forward.concrete_program.main_program)\n",
    "print(model.forward.inputs)\n",
    "# 打印模型参数权重内容\n",
    "print(model.forward.concrete_program.parameters[0].name)\n",
    "print(model.forward.concrete_program.parameters[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. `paddle.jit.save` 完成静态图模型（网络结构和参数权重）的序列化保存。\n",
    "\n",
    "- 网络结构：以`.pdmodel`为扩展名的文件，可以使用visualdl来可视化。\n",
    "- 参数权重：以`.pdiparams`为扩展名的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pdiparams.info', 'model.pdiparams', 'model.pdmodel']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 保存动转静后的模型，得到 infer_model/model.pdmodel 和 infer_model/model.pdiparams 文件\n",
    "paddle.jit.save(model, \"infer_model/model\")\n",
    "os.listdir(\"infer_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### 使用推理库预测\n",
    "\n",
    "获得静态图模型之后，我们使用Paddle Inference进行预测部署。Paddle Inference是飞桨的原生推理库，作用于服务器端和云端，提供高性能的推理能力。\n",
    "\n",
    "Paddle Inference采用 Predictor 进行预测。Predictor 是一个高性能预测引擎，该引擎通过对计算图的分析，完成对计算图的一系列的优化（如OP的融合、内存/显存的优化、 MKLDNN，TensorRT 等底层加速库的支持等），能够大大提升预测性能。另外Paddle Inference提供了Python、C++、GO等多语言的API，可以根据实际环境需要进行选择，为了便于演示这里使用Python API来完成，其已在安装的Paddle包中集成，直接使用即可。使用 Paddle Inference 开发 Python 预测程序仅需以下步骤：\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/f367c74dfd0b4d5b9219bfcc562fd848797bc696e6cb423189f969d7d42f79d5\" width=\"800\" height=200\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.6722751,  1.4945102]], dtype=float32)]\n",
      "[[-1.6722751  1.4945102]]\n",
      "Predictor inference time:  1.3288991451263428\n",
      "Dygraph model inference time:  1.4340496063232422\n"
     ]
    }
   ],
   "source": [
    "import paddle.inference as paddle_infer\n",
    "\n",
    "# 1. 创建配置对象，设置预测模型路径 \n",
    "config = paddle_infer.Config(\"infer_model/model.pdmodel\", \"infer_model/model.pdiparams\")\n",
    "# 启用 GPU 进行预测 - 初始化 GPU 显存 100M, Deivce_ID 为 0\n",
    "# config.enable_use_gpu(100, 0)\n",
    "config.disable_gpu()\n",
    "# 2. 根据配置内容创建推理引擎\n",
    "predictor = paddle_infer.create_predictor(config)\n",
    "# 3. 设置输入数据\n",
    "# 获取输入句柄\n",
    "input_handles = [\n",
    "            predictor.get_input_handle(name)\n",
    "            for name in predictor.get_input_names()\n",
    "        ]\n",
    "# 获取输入数据\n",
    "data = dev_batchify_fn([dev_ds[0]])\n",
    "# 设置输入数据\n",
    "for input_field, input_handle in zip(data, input_handles):\n",
    "    input_handle.copy_from_cpu(input_field)\n",
    "\n",
    "# 4. 执行预测\n",
    "predictor.run()\n",
    "\n",
    "# 5. 获取预测结果\n",
    "# 获取输出句柄\n",
    "output_handles = [\n",
    "            predictor.get_output_handle(name)\n",
    "            for name in predictor.get_output_names()\n",
    "        ]\n",
    "# 从输出句柄获取预测结果\n",
    "output = [output_handle.copy_to_cpu() for output_handle in output_handles]\n",
    "# 打印预测结果\n",
    "print(output)\n",
    "\n",
    "# 打印直接使用动态图模型预测的结果\n",
    "print(student(*data[:-1]).numpy())\n",
    "\n",
    "# Predictor和动态图模型预测速度对照\n",
    "import time\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    for input_field, input_handle in zip(data, input_handles):\n",
    "        input_handle.copy_from_cpu(input_field)\n",
    "    predictor.run()\n",
    "    output = [output_handle.copy_to_cpu() for output_handle in output_handles]\n",
    "print(\"Predictor inference time: \", time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    output = student(*data[:-1]).numpy()\n",
    "print(\"Dygraph model inference time: \", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "更为详细的内容可以从 [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) 获取，欢迎大家使用和贡献，也希望大家多多支持，顺手点个小小的Star~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
