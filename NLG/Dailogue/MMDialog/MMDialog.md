---
title: MMDialog
created: 2022-11-14
tags: 对话/数据集 对话/多模态 
type: 论文
---

## 论文基本信息

**论文标题：**

MMDialog：A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation

**论文链接：**

https://arxiv.org/abs/2211.05719

**数据集链接：**

https://github.com/victorsungo/MMDialog

**本文提出了首个百万量级的多模态开放域多轮对话英文数据集 MMDialog**



## 核心亮点

## 主要收获

## 个人评价

## 研究背景

目前构建多模态对话系统的方法主要依赖大规模的数据驱动，因此研究者们陆续提出了一些包含视觉信息的对话数据集。例如，i）面向视觉问答的 Visual Dialog [1]，该类数据集给定包含图片的 context 做为条件，进行基于该条件的提问与解答；ii）面向 Image-Grounding 对话的数据集 IGC [2] 和 Image-Chat [3]，即给定某些图片，交谈者对图片中的相关内容展开对话；iii）MMChat [4]，则由给定图片展开对话，但后续聊天主题并不仅限于图片内容；  iv）基于影视图文片段构建的 OpenViDial [5]，它截取了视频中的连续图片帧和对应字幕；v）面向多模态对话中图片分享行为的 PhotoChat [6]，等。

尽管认识到以上多模态对话语料库的多样性，但是现有数据集仍然存在局限性，例如：[1,2,3,4,5] 的对话回复仅为单模态文本；[1] 仅为针对特定图片内容的提问与解答，场景与任务的定义比较单一；[2][3] 则是从给定图像的对话中派生出来的，这种会话中讨论的主题通常只由给定图像触发和支撑，回复的内容只有文本信息，这与人类日常对话的习惯并不完全一致 -- 在一次完整的对话中，人类不仅会围绕某张图片展开讨论，也会随时发散话题，讨论其他内容，也可能再次分享并讨论其他图片；[4] 仅在对话开始阶段为图片，但后续对话及回复只包含文本模态；[5] 的字幕对话 turn 和帧图片 context 是从电影和电视剧中提取的，其中每个对话 turn 都与发生的相应帧图片配对，而并非源自真正的多模态对话场景；[6] 由众包标注，但已比较接近于现实生活中的多模态对话，但它仍然受到数据规模较小（仅 1.2 万个对话 session）、缺乏领域多样性（89 种 objects）、图片数量稀疏（每个 session 只有 1 张图片）的限制，这阻碍了对多模态开放域对话建模的进一步探索。 

为了解决上述问题，我们提出了 MMDialog，它是一个大规模的多模态开放域对话数据集，包含 108 万个完整对话 session，超过 4000 个对话主题，以及 153 万张非重复图像，每个对话 session 平均 2.59 张图像，且可以位于对话过程的任何位置。显然，在日常生活中，人们可以在对话的任何阶段自由选择任何话题和模态进行沟通，而 MMDialog 很好地具备了这种特色。 

MMDialog 丰富且真实的人类对话内容收集自一个英文在线社交平台（注：该过程完全符合该平台对于学术研究数据的采集和分享规定，且已对用户隐私脱敏及数据信息加密处理）。

## 数据集

据我们所知，MMDialog 是第一个百万规模的英文开放域多模态对话语料库，我们希望 MMDialog 海量的真实对话与图像信息能为相关研究提供更多的支持。以下为 MMDialog 与 PhotoChat 的统计对比，可以看到，前者相对于后者拥有 88 倍的 session 数量，47 倍的主题丰富度，以及 140 倍的图片数量。

![](img/Pasted%20image%2020221114094446.png)

以下为 MMDialog 的训练、验证、测试集的统计结果，我们分别随机选择 10000 个 session 作为验证与测试集，并将剩余数据作为训练集。

![](img/Pasted%20image%2020221114094525.png)

为了保证数据质量，我们决定提取带有某种标签的对话（例如“#travel”、“#friends”、“#golf”），因为标签往往概括了文本话语和视觉媒体的主要主题。具体地，我们人工筛选出 4184 个流行的标签，且保证每个标签至少收集 1000 个对话，这样我们的数据集不仅满足开放域属性，而且可以确保较大的规模。 

然后，我们利用以上标签集合作为种子来构建多轮对话。第一步，对于每个标签，我们抓取包含相应标签的 turn，并只保留那些包含至少一个图像的 turn 做为锚点；第二步，我们定位该锚点所在的整段对话；第三步，对于每个锚，我们查找所有其他相关 turn：i）从锚往下搜索直到叶节点，ii）从锚往上搜索直到根节点；iii）由于每个锚点都有可能包括多个回复，所以我们递归地跟踪每个 turn 链以恢复整个对话的树结构。

## **生成与检索tasks**

![](img/Pasted%20image%2020221114095411.png)

![](img/Pasted%20image%2020221114095427.png)

![](img/Pasted%20image%2020221114095440.png)

## **两种基线模型**

![](img/Pasted%20image%2020221114095513.png)

![](img/Pasted%20image%2020221114095528.png)


