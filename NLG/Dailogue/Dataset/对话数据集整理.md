---
title: 对话数据集整理
created: 2022-08-15
tags: [数据集/对话]

---


# 对话数据集整理

## 公开数据集

### C3KG-中文常识对话知识图谱

发布时间：2022年

论文链接：[C3KG: A Chinese Commonsense Conversation Knowledge Graph](https://arxiv.org/abs/2204.02549 "C3KG: A Chinese Commonsense Conversation Knowledge Graph")

数据集链接：[https://github.com/xiaomi/c3kg](https://github.com/xiaomi/c3kg "https://github.com/xiaomi/c3kg")

数据集语言：中文

数据集模态：文本

数据集描述：该文章是小米AI实验室发表在ACL2022会议上的一篇论文，因为现有的常识知识库是以孤立的方式组织元组，这对于常识对话模型目标规划是不够的。 作者创建了第一个结合了社会常识知识和对话流信息的**中文常识对话知识图谱**。作者收集了日常场景中的大规模多轮对话， 并手动注释对话的情感信息。 基于这些标注信息，可以提取 ATOMIC（知识库） 中与对话相关的事件，并使用不同的对话流将它们连接起来。 通过这种用对话相关的知识来增强 ATOMIC，有助于聊天机器人挑选出有用的常识性知识，并丢弃掉那些对与对话流不相关的知识。

评论：质量还不错，可以用来做多轮对话的finetune

```text
[{"sens": "小许，你今天来的比平时晚呀？是身体不舒服吗？", "label": "others", "intent": "询问"}, {"sens": "呜呜，昨晚空调开的太低，一大早起来头就特别疼。", "label": "悲伤", "intent": "描述"}, {"sens": "怪不得我看你走路都摇摇晃晃的。吃过感冒药了吗？", "label": "others", "intent": "询问"}, {"sens": "吃过了，现在已经好多了，就是有点想睡觉。", "label": "others", "intent": "描述"}, {"sens": "唉，你说你，工作那么拼干嘛，生病了就休息一天吗？", "label": "others", "intent": "询问"}, {"sens": "没办法，生活所迫呀！", "label": "others", "intent": "others"}, {"sens": "为什么这么说？是家里面发生了什么事吗？", "label": "others", "intent": "询问"}, {"sens": "也没啥事，就是我弟弟已经到了适婚的年龄，我得为他攒点彩礼钱。", "label": "others", "intent": "描述"}, {"sens": "这也太不像话了吧！都已经成年了还不能承担起自己的责任吗？", "label": "生气", "intent": "观点"}, {"sens": "唉，他在家里面被爸妈娇生惯养惯了，没事的，我已经习惯了。", "label": "others", "intent": "描述"}, {"sens": "那好吧！家家有本难念的经，那你好好照顾自己。", "label": "others", "intent": "建议"}, {"sens": "好，今天的工作安排多吗？", "label": "others", "intent": "others"}, {"sens": "还好，就有一些琐事，我待会顺便帮你做了吧，你多休息会。", "label": "others", "intent": "建议"}, {"sens": "那真的是太感谢你了。", "label": "开心", "intent": "others"}, {"sens": "噢，突然想起来今天不是周三吗，我们还要参加一个例会。", "label": "others", "intent": "others"}, {"sens": "好好好，我知道了，到时候我和你们一起去。", "label": "others", "intent": "others"}]
```

### chatterbot\_corpus-多语言高质量翻译

发布时间：2018年

论文链接：无

数据集链接：[https://github.com/gunthercox/chatterbot-corpus](https://github.com/gunthercox/chatterbot-corpus "https://github.com/gunthercox/chatterbot-corpus")

数据集语言：多语言

数据集模态：文本

数据集描述：按类型领域分类，质量较高。多语言对话数据集。

评论：虽然数据质量较高，但是中文是翻译过来的（翻译的不是很好）

### CPED

发布时间：2022年

论文链接：[CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI](https://arxiv.org/pdf/2205.14727v1.pdf "CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI")

数据集链接：[https://github.com/scutcyr/CPED](https://github.com/scutcyr/CPED "https://github.com/scutcyr/CPED")

数据集语言：中文

数据集模态：视频、音频、文本

数据集描述：人类的语言表达是基于对情景的主观识解，而不是客观的真实条件，这意味着说话人的个性和情感经过认知处理后对会话有着重要的影响。为了在会话生成过程中同时考虑个性和情感，CPED由与情感和个性相关的多源知识组成。这些知识包括性别、大五人格特征、13种情绪、19种对话行为和10个场景，包含超过12K段对话，将给中文对话理解与生成领域提供一个更有挑战性的任务。任务设置见https\://paperswithcode.com/dataset/cped。

评论：数据来源于电视剧，会有很多人物名字，父母关于孩子的对话等

### Crosswoz-任务型

发布时间：2020年

论文链接：[CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset](https://arxiv.org/abs/2002.11893 "CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset")

数据集链接：[https://github.com/thu-coai/CrossWOZ](https://github.com/thu-coai/CrossWOZ "https://github.com/thu-coai/CrossWOZ")

数据集语言：中文

数据集模态：文本

数据集描述：2020年由清华大学人工智能研究院发布的CrossWOZ包含 6K 个对话，102K 个句子，涉及 5 个领域（景点、酒店、餐馆、地铁、出租）。平均每个对话涉及 3.2 个领域，远超之前的多领域对话数据集，增添了对话管理的难度。截至2020年，是第一个大规模中文对话数据集。可以用于研究任务型对话系统中各个方面，比如NLU、DST、对话策略学习、NLG都可以，也可以用于对话上下文补全的研究。

评论：适合任务型对话

### 百度DuConv-知识对话

发布时间：2019年

论文链接：[Proactive Human-Machine Conversation with Explicit Conversation Goals](https://arxiv.org/abs/1906.05572 "Proactive Human-Machine Conversation with Explicit Conversation Goals")

数据集链接：[https://github.com/Cindy-xdZhang/ACL-duconv](https://github.com/Cindy-xdZhang/ACL-duconv "https://github.com/Cindy-xdZhang/ACL-duconv")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：[https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv](https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv "https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-DuConv")，给定一个对话目标 g 和一组与主题相关的背景知识，系统期望为当前对话输出一个话语，在给定目标的指导下保持对话的连贯性和信息量。在对话过程中，系统需要主动将对话从一个话题引导到另一个话题。对话目标g是这样给出的：“Start->Topic\_A->TOPIC\_B”，这意味着机器应该将对话从任何开始状态引导到主题A，然后到主题B。给定的背景知识包括与主题A相关的知识和主题B，以及这两个主题之间的关系。

评论：

### 百度DuRecDial-对话推荐

发布时间：2020年

论文链接：[Towards Conversational Recommendation over Multi-Type Dialogs](https://arxiv.org/pdf/2005.03954.pdf "Towards Conversational Recommendation over Multi-Type Dialogs")

数据集链接：[https://baidu-nlp.bj.bcebos.com/DuRecDial.zip](https://baidu-nlp.bj.bcebos.com/DuRecDial.zip "https://baidu-nlp.bj.bcebos.com/DuRecDial.zip")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：DuRecDial包含多种类型的对话(推荐对话、闲聊、任务导向对话和QA)，来自7个领域(电影、明星、音乐、新闻、食物、poi和天气)的10.2k对话，以及156K个utterances。DuRecDial是首个融合多种对话类型的对话推荐数据集，它包含多种对话类型、多领域和丰富对话逻辑(考虑用户实时反馈)。在每个对话中，推荐者(bot)使用丰富的交互行为主动引导一个多类型对话不断接近推荐目标。DuRecDial旨在考察模型是否可以在对话过程中基于用户兴趣以及用户的实时反馈，主动给用户做出合理的推荐。

评论：

### ECM(ESTC)-情感对话

发布时间：2018年

论文链接：[Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory](https://arxiv.org/abs/1704.01074 "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory")

数据集链接：[https://github.com/thu-coai/ecm](https://github.com/thu-coai/ecm "https://github.com/thu-coai/ecm")，[https://www.luge.ai/#/luge/dataDetail?id=37](https://www.luge.ai/#/luge/dataDetail?id=37 "https://www.luge.ai/#/luge/dataDetail?id=37")

数据集语言：中文

数据集模态：文本

数据集描述：ECM是一个大规模的中文情感对话数据集，旨在考察模型是否可以在对话过程中充分利用情感信息，并生成具有正确情感倾向、且与上下文相关的对话回复。ESTC数据集是在STC数据集的基础上，使用一个训练好的文本情感分类器得到，通过文本情感分类器，自动标注了6类情感标签，常用于中文情感对话生成任务。

评论：单轮对话，感觉质量一般

### ESConv-情绪支持策略对话

发布时间：2021年

论文链接：[**Towards Emotional Support Dialog Systems**](https://arxiv.org/abs/2106.01144 "Towards Emotional Support Dialog Systems")

数据集链接：[https://github.com/thu-coai/Emotional-Support-Conversation](https://github.com/thu-coai/Emotional-Support-Conversation "https://github.com/thu-coai/Emotional-Support-Conversation")

数据集语言：英文

数据集模态：文本

数据集描述：标注语句的情绪支持策略

评论：

### KdConv-知识驱动对话

发布时间：

论文链接：[{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation](https://arxiv.org/abs/2004.04100 "{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation")

数据集链接：[https://github.com/thu-coai/KdConv](https://github.com/thu-coai/KdConv "https://github.com/thu-coai/KdConv")

数据集语言：中文

数据集模态：文本

数据集描述：KdConv是中文多领域知识驱动对话数据集。KdConv 包含来自**三个**领域（电影、音乐和旅行）的**4.5K**对话和**86K**话语，平均轮数为**19.0**。这些对话包含对相关主题的深入讨论和多个主题之间的自然过渡，同时语料库还可以用于探索迁移学习和领域适应。

评论：回复时会参考知识库进行回答

### KvPI-对话回复一致性

发布时间：2020年

论文链接：**Proﬁle Consistency Identiﬁcation for Open-domain Dialogue Agents**. [\[Paper\]](https://www.aclweb.org/anthology/2020.emnlp-main.539.pdf "\[Paper]")

数据集链接：[https://github.com/songhaoyu/KvPI](https://github.com/songhaoyu/KvPI "https://github.com/songhaoyu/KvPI")

数据集语言：中文

数据集模态：文本

数据集描述：一致性问题是当前开放域对话面临的主要问题之一。已有的研究工作主要探索了如何将属性信息融合到对话回复中，但是很少有人研究如何理解、识别对话系统的回复与其预设属性之间的一致性关系。为了研究这一问题，在这项工作中我们构建了一个大规模的人工标注数据集KvPI（Key-value Profile consistency Identification）。该数据集包含了超过11万组的单轮对话及其键值对属性信息，并且对回复和属性信息之间的一致性关系进行了人工标注。该数据集的一条基本数据元组包含了键值对角色信息，单轮对话输入-回复对，领域信息，人工抽取的对话回复角色信息以及人工标注的角色一致性标签。考虑数据收集以及公开信息等诸多因素，我们在角色信息中引入了性别、地点和星座三种常见的基本属性。

评论：单轮对话

### LCCC-large-综合数据

发布时间：2020年

论文链接：[A Large-Scale Chinese Short-Text Conversation Dataset](https://arxiv.org/abs/2008.03946 "A Large-Scale Chinese Short-Text Conversation Dataset")

数据集链接：[https://github.com/thu-coai/CDial-GPT](https://github.com/thu-coai/CDial-GPT "https://github.com/thu-coai/CDial-GPT")

数据集语言：中文

数据集模态：文本

数据集描述：LCCC-base 数据集中的原始对话数据来自于微博对话，LCCC-large 数据集中的原始对话数据在这些微博对话的基础上融合了其他开源对话数据集

| 数据集                                                                                                                       | 总对话轮次 | 对话示例                                                         |
| ------------------------------------------------------------------------------------------------------------------------- | ----- | ------------------------------------------------------------ |
| Weibo Corpus                                                                                                              | 79M   | Q:火锅我在重庆成都吃了七八顿火锅 A: 哈哈哈哈！那我的嘴巴 可能要烂掉！                       |
| [PTT Gossiping Corpus](https://github.com/zake7749/Gossiping-Chinese-Corpus "PTT Gossiping Corpus")                       | 0.4M  | Q:为什么乡民总是欺负国高中生呢QQ A:如果以为选好科系就会变成比尔盖兹那不如退学吧                  |
| [Subtitle Corpus](https://github.com/skdjfla/dgk_lost_conv "Subtitle Corpus")                                             | 2.74M | Q:京戏里头的人都是不自由的 A:他们让人拿笼子给套起来了了                               |
| [Xiaohuangji Corpus](https://github.com/skdjfla/dgk_lost_conv "Xiaohuangji Corpus")                                       | 0.45M | Q:你谈过恋爱么 A:谈过，哎，别提了，伤心..                                     |
| [Tieba Corpus](https://github.com/codemayq/chinese_chatbot_corpus "Tieba Corpus")                                         | 2.32M | Q:前排，鲁迷们都起床了吧 A:标题说助攻，但是看了那球，真是活生生的讽刺了                       |
| [Qingyun Corpus](https://github.com/codemayq/chinese_chatbot_corpus "Qingyun Corpus")                                     | 0.1M  | Q:看来你很爱钱 A:噢是吗？那么你也差不多了                                      |
| [Douban Conversation Corpus](https://github.com/MarkWuNLP/MultiTurnResponseSelection "Douban Conversation Corpus")        | 0.5M  | Q:看原版英文电影学纯正英语 A:大爱老友记反复看了好多次 了 Q:一样光盘都快被我看花了 A:那你现在的英语应该不错了 |
| [E-commerical Conversation Corpus](https://github.com/cooelf/DeepUtteranceAggregation "E-commerical Conversation Corpus") | 0.5M  | Q:这个会不会聚划算 A:暂时没有哦 Q:后期会不会有 A:不一定哦亲多多关注我们哦                   |
| [Chinese Chat Corpus](https://github.com/yangjianxin1/GPT2-chitchat "Chinese Chat Corpus")                                | 0.5M  | Q: 我今天腿都废了，你们过节，我搬砖 A: 辛苦啊，圣诞节还去赚大钱了加油 Q: 毕竟是没男朋友的人，什么节都是一样的 |

评论：

### LUGE-Dialogue-综合数据

发布时间：2021年

论文链接：

数据集链接：[https://www.luge.ai/#/luge/dataDetail?id=26](https://www.luge.ai/#/luge/dataDetail?id=26 "https://www.luge.ai/#/luge/dataDetail?id=26")

数据集语言：中文

数据集模态：文本

数据集描述：本数据集旨在全面评测基于统一生成模型建模不同对话技能的整体效果，包括内容丰富度，多轮连贯性，知识准确率，对话主动性。 

其中收集了一系列公开的开放域对话数据集，并对数据集进行了统一的整理以及提供了统一的评测方式，期望从多个技能、多个领域的角度对模型效果进行综合评价。该开源数据集旨在为研究人员和开发者提供学术和技术交流的平台，进一步提升开放域对话的研究水平，推动自然语言理解和人工智能领域技术的应用和发展。 

同时，我们还收集并提供了开源的中文对话数据，参赛队可以基于这些对话数据构建自己的对话模型： 

1.知识对话相关数据：百度的DuConv \[1]。

2.推荐对话相关数据：百度的DuRecDial \[2]。 

3.画像对话数据：百度的画像数据集(DuPersona)。 

4.其他对话数据：华为的微博数据 \[3] ，北航和微软的豆瓣多轮对话 \[4]，清华的LCCC数据集\[5]，清华情感对话数据\[6]，腾讯的检索辅助生成对话数据集 \[7] ，清华的KdConv \[8]。

| 对话技能名称 | 数据集                                | 训练集样例数量  | 开发集样例数量 | 测试集样例数量 | 单/多轮 | 领域                    |
| ------ | ---------------------------------- | -------- | ------- | ------- | ---- | --------------------- |
| 知识对话   | 百度DuConv                           | 19858    | 2000    | 5000    | 多轮   | 电影                    |
| 推荐对话   | 百度DuRecDial                        | 6618     | 946     | 4645    | 多轮   | 明星、电影、音乐、新闻、天气、美食、POI |
| 画像对话   | 百度画像数据集(Chinese Persona Chat, CPC) | 23000    | 1500    | 3000    | 多轮   | 开放域                   |
| 其他     | 微博数据                               | 3103764  | 1500    | 3000    | 多轮   | 开放域                   |
| 其他     | 豆瓣多轮对话                             | 500000   | 25001   | 1186    | 单轮   | 开放域                   |
| 其他     | 清华LCCC                             | 11987759 | 20000   | 10000   | 多轮   | 开放域                   |
| 其他     | 清华情感数据集                            | 899207   | 110000  | 110000  | 单轮   | 开放域                   |
| 其他     | 腾讯检索辅助生成对话数据集                      | 5498480  | 107332  | 156706  | 单轮   | 开放域                   |
| 其他     | 清华kdConv                           | 3000     | 300     | 2751    | 多轮   | 电影、音乐、旅游              |

### 腾讯NaturalConv

发布时间：2021年

论文链接：[NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation](https://arxiv.org/pdf/2103.02548.pdf "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation")

数据集链接：[https://ai.tencent.com/ailab/nlp/dialogue/#datasets](https://ai.tencent.com/ailab/nlp/dialogue/#datasets "https://ai.tencent.com/ailab/nlp/dialogue/#datasets")，[https://github.com/naturalconv/NaturalConvDataSet](https://github.com/naturalconv/NaturalConvDataSet "https://github.com/naturalconv/NaturalConvDataSet")

数据集语言：中文

数据集模态：文本

数据集描述：NaturalConv是腾讯2021年发布的中文对话数据集，是基于话题驱动的中文对话生成。它更接近于类人对话，具有自然属性，包括场景假设、自由话题扩展、问候语等完整的自然环境。它包含约400K语句和19.9K对话，涉及多个领域（包括但不限于体育、娱乐、科技）。平均轮数为20，明显长于其他语料库。NaturalConv提供了一个评估在自然环境下生成对话能力的基准。该语料库不仅可以赋能未来基于文档的对话生成研究，还可以赋能不同场景下的对话风格和策略学习。

```text
{'dialog_id': '6499_1', 'document_id': 6499, 'content': ['你好！', '你好啊！', '你也是来看明星走红毯的嘛？', '对啊，我本来是来三亚旅游的，听说这里举办电影节，就想过来见见世面。', '那你可是来对了，这次可以说是众星云集，明星可以看到你想吐的。', '那我可要好好等等看完红毯仪式了，不知道有没有我的沈腾叔叔。', '这种级别的电影节肯定有他啊，再怎么说别人现在票房总量累计也是超过100亿的。', '我最开始喜欢他是从2012年春晚他的小品，“郝建”贱贱的小样子太好笑了。', '我也是他的粉丝，他每年春晚的小品的台词我都可以背出来，主要是太经典了。', '而且他现在在电影大荧幕里面表现的也不错，他们开心麻花出品的电影每一部都是精品。', '有句话不是说沈腾什么都不用干，就站在那里，你就想笑。', '哈哈哈，确实，他那张脸就会让人不由自主想笑，他一开口我就忍不住了。', '这次听说沈腾就是带着新作品过来的，不知道是什么类型的。', '我知道，他之前采访的时候说了，叫《全民狂欢》，应该也是一部喜剧电影。', '虽然也很期待，但还是希望能看到他能演演不同类型的电影和角色，毕竟在好的演员同类型也会看腻的。', '说的也对，我觉他可以试试都市剧，就演那种不着调的角色很适合他。话说你这次是来看那个明星的？', '我是来等迪丽热巴的，他可是我的女神，简直就是仙女下凡。', '我也觉得她长得很漂亮，特别是那双眼睛，很有灵气。', '啊，我的迪丽热巴来了，我的先过去了，拜拜。', '再见。']}
```

### nus-sms-corpus

发布时间：2015年

论文链接：[Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus](http://link.springer.com/article/10.1007/s10579-012-9197-9 "Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus")

数据集链接：[https://github.com/kite1988/nus-sms-corpus](https://github.com/kite1988/nus-sms-corpus "https://github.com/kite1988/nus-sms-corpus")

数据集语言：中文，英文

数据集模态：文本

数据集描述：这是在新加坡国立大学计算机科学系收集的用于研究的SMS（短消息服务）消息的语料库。 该数据集包括2015年3月9日从语料库中提取的67,093条SMS消息。 这些消息主要来自新加坡人，主要来自大学的学生。这些信息来自志愿者，他们知道他们的贡献将公之于众。 
数据收集器机会性地收集尽可能多的关于消息及其发送者的元数据，以便实现不同类型的分析。

### OpenSubData

发布时间：2009年

论文链接：[http://www.lrec-conf.org/proceedings/lrec2016/pdf/947\_Paper.pdf](http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf "http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf")

数据集链接：[http://nlp.stanford.edu/data/OpenSubData.tar](http://nlp.stanford.edu/data/OpenSubData.tar "http://nlp.stanford.edu/data/OpenSubData.tar")

数据集链接2：[https://opus.nlpl.eu/OpenSubtitles-v2018.php](https://opus.nlpl.eu/OpenSubtitles-v2018.php "https://opus.nlpl.eu/OpenSubtitles-v2018.php")

数据集语言：多语言（62种语言）

数据集模态：文本

数据集描述：OpenSubtitles主要用于开放域对话生成，包含2.6 billion语句。文件很大，读取方式[https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei\_dataset.py](https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei_dataset.py "https://github.com/chenyangh/DialogueGenerationWithEmotion/blob/master/jiwei_dataset.py")

### M^3 ED

发布时间：2022年

论文链接：[https://aclanthology.org/2022.acl-long.391/](https://aclanthology.org/2022.acl-long.391/ "https://aclanthology.org/2022.acl-long.391/")

数据集链接：[https://github.com/aim3-ruc/rucm3ed](https://github.com/aim3-ruc/rucm3ed "https://github.com/aim3-ruc/rucm3ed")

数据集语言：中文

数据集模态：视频、音频、文本

数据集描述：与MELD数据集类似，但其数据来源于56部电视剧，人物更加丰富。文章构建了一个大规模高质量的多模态、多场景、多标签情感对话数据集，从56部中文电视剧，大约500集中选取900多个对话片段，并对对话中的每句话进行多情感标签的标注，共标注24,449句话。文章采用主流的6类基本情感标注（高兴、惊讶、伤心、生气、厌恶，害怕）以及正常无明显情感，共7类离散情感。从数据来源选取，对话片段选取，情感标注，标注后处理等方面进行严格把控，以保证数据的质量，最终得到标注者间一致性0.59，高于MELD 的0.43、IEMOCAP的0.48 以及MSP-IMPROV 中的0.49。

### STC

发布时间：2015年

论文链接：[https://www.aclweb.org/anthology/P15-1152/](https://www.aclweb.org/anthology/P15-1152/ "https://www.aclweb.org/anthology/P15-1152/")

数据集链接：[https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip](https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip "https://coai-dataset.oss-cn-beijing.aliyuncs.com/STC-corpus.zip")

数据集语言：中文

数据集模态：文本

数据集描述：STC是从微博爬取的语料构造的短文本对话(Short-Text Conversation)数据集，包含4.4 million个对话，。这里的数据集下载链接来自项目CDial-GPT。

### PchatbotW

发布时间：2021年

论文链接：[https://arxiv.org/abs/2009.13284](https://arxiv.org/abs/2009.13284 "https://arxiv.org/abs/2009.13284")

数据集链接：[https://github.com/qhjqhj00/Pchatbot](https://github.com/qhjqhj00/Pchatbot "https://github.com/qhjqhj00/Pchatbot")

数据集语言：中文

数据集模态：文本

数据集描述：PchatbotW主要从微博爬取得到，包括了139,448,339个对话、 278,896,678，并且提供了时间戳和用户ID两种个性信息，可以隐式地建模说话者的个性。这是一个大规模的用于开发个性化对话模型的数据集。在这个数据集中，我们保留了匿名的用户ID和会话时间戳，可以检索用户的对话历史记录并用于建立丰富的用户个人资料。依据对话历史，我们可以让聊天机器人从历史对话中学习语言和语义信息，并根据所学知识生成个性化回复。Pchatbot有两个子集，名为PchatbotW(爬取微博数据构建)和PchatbotL(爬取司法论坛构建)。



### Persona-画像对话数据

发布时间：2020年

论文链接：

数据集链接：[https://www.luge.ai/#/luge/dataDetail?id=38](https://www.luge.ai/#/luge/dataDetail?id=38 "https://www.luge.ai/#/luge/dataDetail?id=38")

数据集语言：中文

数据集模态：文本

数据集描述：画像对话数据集，考察对话模型在闲聊场景中是否可以生成符合对话历史和画像信息，且自然流畅、信息丰富的机器回复。有人物画像的对话数据集。

```
{"p1_persona": ["我 喜欢 旅行", "最喜欢 的 颜色 是 绿色", "我 喜欢 汽车", "我 喜欢 猫"], "p2_persona": ["我 是 个 夜猫子", "我 有 一只 哈巴狗 ， 它 是 最 忠诚 的 动物", "我 住在 镇上 ， 附近 有 商店", "我 是 学 法律 的 研究生", "我 有时 喜欢 和 朋友们 在 公园 玩 飞盘"], "conversation": ["p1 : 你好 呀 。", "p2 : 你好 呀 ， 在 干 吗 呢 ？", "p1 : 我 在 给 我 的 小猫 喂食 呢 。", "p2 : 听 你 这么说 ， 你 喜欢 小猫 喽 ？", "p1 : 对 的 呀 ， 我 非常 喜欢 小猫 呢 ， 觉得 小猫 很可爱 。", "p2 : 我 也 觉得 小猫 很可爱 呢 ， 毛茸茸 的 呢 ， 特别 可爱 。", "p1 : 那 你 是 从事 什么 工作 的 呢 ？", "p2 : 我 是 一名 大学生 呢 。", "p1 : 那 你 学 的 是 什么 专业 呢 ？", "p2 : 我 学 的 是 法律 呢 ， 现在 正在 读 研究生 呢 。", "p1 : 哇塞 ， 那 你 的 知识 一定 很 渊博 啊 ？", "p2 : 是 的 呢 ， 我 学 了 很多 关于 法律 方面 的 知识 呢 。", "p1 : 那 你们 的 律师费 也 不 便宜 啊 ， 打 赢 一场 官司 需要 很多 律师费 呢 。", "p2 : 律师费 还行 吧 ， 那 要 看 什么 官司 呢 。", "p1 : 好 吧 ， 那 你 喜欢 运动 吗 ？", "p2 : 不 喜欢 ， 我 比较 懒 ， 不 喜欢 运动 。"]}
```

### PersonalDialog

发布时间：2019年

论文链接：[https://arxiv.org/abs/1901.09672](https://arxiv.org/abs/1901.09672 "https://arxiv.org/abs/1901.09672")

数据集链接：[https://github.com/silverriver/PersonalDilaog](https://github.com/silverriver/PersonalDilaog "https://github.com/silverriver/PersonalDilaog")，
Please contact \[<zhengyinhe1@163.com>] for the PersonalDialog dataset，一部分在[https://huggingface.co/datasets/silver/personal\_dialog](https://huggingface.co/datasets/silver/personal_dialog "https://huggingface.co/datasets/silver/personal_dialog")

数据集语言：中文

数据集模态：文本

数据集描述：该数据集包括20.83M个对话、56.25M个句子，对于每个说话人，提供了5种个性特征(Age, Gender, Location, Interest, self descriptions)。

数据示例：https://huggingface.co/datasets/silver/personal_dialog

### PsyQA-中文心理健康支持问答数据

发布时间：

论文链接：[PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support](https://arxiv.org/abs/2106.01702 "PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support")

数据集链接：[https://github.com/thu-coai/PsyQA](https://github.com/thu-coai/PsyQA "https://github.com/thu-coai/PsyQA")，需要申请

数据集语言：中文

数据集模态：文本

数据集描述：一个用于生成心理健康支持长篇咨询文本的中文数据集，该数据集主要收集了壹心理社区的问答数据，标注了6种助人策略，总共包括了22346个问题以及56063个回复。

评论：

```text
{
"question": "去爱一个事事让着你的人，是一种不可能的期待吗？",
"description": "去爱一个事事让着你的人？有这样的人么？是一种不可能的期待么？",
"keywords": "恋爱,恋爱经营",
"answers": [
{
"answer_text": "你好，首先回答你关于有没有事事让着你的人，如果你真的去找这样的人还是基本上能够找到的，并不算是非常不可能的期待。在我的所见所谓中就看到过不止有一个这样的人。但你要说你还能去爱一个这样的人，那就太不容易了，就变成了比较困难的事情，为什么这样说，通常常见的情况是你爱的人不爱你，爱你的人你又不爱，所以常常难以两全。当然相爱的情况还是很多的，但相爱又要他事事让着你，唔，这就有点麻烦了。无论如何两个人在一起首先是两个相互独立的个体，总有一些自己不同于任何的需要和想法，因为爱，两个人会磨合会有拖鞋和退让，互相拉锯，关系才能保持平衡，如果是只有一方做完全的退让，关系就是失衡的，短暂的时间可以因为爱而维系，但长期关系是很难维持下去的。嗯，所以总结来说，你的期待有点理想化了。",
"has_label": true,
"labels_sequence": [
{
"start": 0,
"end": 78,
"type": "Interpretation"
},
{
"start": 78,
"end": 190,
"type": "Interpretation"
},
{
"start": 190,
"end": 313,
"type": "Interpretation"
},
{
"start": 313,
"end": 332,
"type": "Interpretation"
}
]
}
],
"questionID": 4394
}
```

### Retrieval\_Generation\_Chat\-tecent

发布时间：2019年

论文链接：[Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework](https://www.aclweb.org/anthology/D19-1195 "Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework")

数据集链接：[https://ai.tencent.com/ailab/nlp/dialogue/](https://ai.tencent.com/ailab/nlp/dialogue/ "https://ai.tencent.com/ailab/nlp/dialogue/")，[https://www.luge.ai/#/luge/dataDetail?id=36](https://www.luge.ai/#/luge/dataDetail?id=36 "https://www.luge.ai/#/luge/dataDetail?id=36")

数据集语言：中文

数据集模态：文本

数据集描述：Tencent是一个大规模的检索辅助生成的中文开放域对话数据集，旨在考察模型在闲聊场景中，是否可以生成流畅的、与上下文相关的对话回复。

评论：

```
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 合适 不|巨蟹座 太 强势 了
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 合适 么|觉得 不 合适 ~
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|巨蟹 和 白羊 合适 吗|这个 没试 过 , 还 真不知道 呢
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 不 和|为什么 不 和 ! ? 我 挺 喜欢 巨蟹 的
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹|白羊 和 巨蟹 , 有 希望 不 。 。 诶 。 貌似 白羊 比较 爱 天蝎 和 摩 羯 。 。 伤心 啦
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 和 巨蟹 不 和 吗|和 摩羯合 吗
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 巨蟹|觉得 巨蟹 男 还行 吧
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 。 。 巨蟹|讨厌 巨蟹座
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 巨蟹 。 巨蟹 白羊|东土 大唐 形象大使 发来 慰问 贺电
白羊   和   巨蟹   合适   不|巨蟹座   太   强势   了|白羊 的 我 和 巨蟹 的 他|白羊 的 沙发

```

### Stylistic

发布时间：

论文链接：Stylistic Dialogue Generation via Information-Guided Reinforcement Learning Strategy

数据集链接：

数据集语言：中文

数据集模态：文本

数据集描述：单轮对话

评论：

### Ubuntu对话语料库

发布时间：

论文链接：

数据集链接：[https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886](https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886 "https://tianchi.aliyun.com/dataset/dataDetail?dataId=89886")

数据集语言：英文

数据集模态：文本

数据集描述：Ubuntu对话语料库包括从Ubuntu聊天记录中提取的近一百万个两人对话，用于获得针对与Ubuntu相关的各种问题的技术支持。每次对话平均8轮，至少3轮。所有对话均以文本形式（而非音频）进行。

完整的数据集包含93万个对话和超过1亿个单词。该数据集包含分布在.csv文件中的该数据集的样本。该数据集包含超过2.69亿个单词的文本，分布超过了2600万圈。

## 未开放下载

### EVA数据集



## 模版

发布时间：

论文链接：

数据集链接：

数据集语言：中文

数据集模态：文本

数据集描述：

评论：

## 参考

[https://blog.csdn.net/m0\_37201243/article/details/120051649](https://blog.csdn.net/m0_37201243/article/details/120051649 "https://blog.csdn.net/m0_37201243/article/details/120051649")

[https://blog.csdn.net/Thanours/article/details/118368742](https://blog.csdn.net/Thanours/article/details/118368742 "https://blog.csdn.net/Thanours/article/details/118368742")

[https://www.luge.ai/#/](https://www.luge.ai/#/ "https://www.luge.ai/#/")
