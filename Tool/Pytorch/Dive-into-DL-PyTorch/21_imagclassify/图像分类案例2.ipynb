{"cells":[{"cell_type":"markdown","metadata":{"graffitiCellId":"id_9pjlvx1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"36C1910C967E43B1B111E5E53259C1E2","mdEditEnable":false},"source":"#  Kaggle上的狗品种识别（ImageNet Dogs）"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_nnzrhp8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"C843FCEE167D421B8A497FB92B60FAB6","mdEditEnable":false},"source":"在本节中，我们将解决Kaggle竞赛中的犬种识别挑战，比赛的网址是https://www.kaggle.com/c/dog-breed-identification 在这项比赛中，我们尝试确定120种不同的狗。该比赛中使用的数据集实际上是著名的ImageNet数据集的子集。"},{"cell_type":"code","execution_count":1,"metadata":{"graffitiCellId":"id_fypnm12","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2B43D410B3AE4BF18C12E4719E86D5C2","collapsed":false,"scrolled":false},"outputs":[],"source":"# 在本节notebook中，使用后续设置的参数在完整训练集上训练模型，大致需要40-50分钟\n# 请大家合理安排GPU时长，尽量只在训练时切换到GPU资源\n# 也可以在Kaggle上访问本节notebook：\n# https://www.kaggle.com/boyuai/boyu-d2l-dog-breed-identification-imagenet-dogs\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport os\nimport shutil\nimport time\nimport pandas as pd\nimport random"},{"cell_type":"code","execution_count":2,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"FE7EE6AB8B95437784CEDB3668B6FC69","collapsed":false,"scrolled":false},"outputs":[],"source":"# 设置随机数种子\nrandom.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"EAC79BE16D3E4EEC85AE5824764583DF","mdEditEnable":false},"source":"## 整理数据集"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"AAABF1FBFDA740CC8C4FA4C2AB4EF063","mdEditEnable":false},"source":"我们可以从比赛网址上下载数据集，其目录结构为：\n\n```\n| Dog Breed Identification\n    | train\n    |   | 000bec180eb18c7604dcecc8fe0dba07.jpg\n    |   | 00a338a92e4e7bf543340dc849230e75.jpg\n    |   | ...\n    | test\n    |   | 00a3edd22dc7859c487a64777fc8d093.jpg\n    |   | 00a6892e5c7f92c1f465e213fd904582.jpg\n    |   | ...\n    | labels.csv\n    | sample_submission.csv\n```\n\ntrain和test目录下分别是训练集和测试集的图像，训练集包含10,222张图像，测试集包含10,357张图像，图像格式都是JPEG，每张图像的文件名是一个唯一的id。labels.csv包含训练集图像的标签，文件包含10,222行，每行包含两列，第一列是图像id，第二列是狗的类别。狗的类别一共有120种。\n\n我们希望对数据进行整理，方便后续的读取，我们的主要目标是：\n\n* 从训练集中划分出验证数据集，用于调整超参数。划分之后，数据集应该包含4个部分：划分后的训练集、划分后的验证集、完整训练集、完整测试集\n* 对于4个部分，建立4个文件夹：train, valid, train_valid, test。在上述文件夹中，对每个类别都建立一个文件夹，在其中存放属于该类别的图像。前三个部分的标签已知，所以各有120个子文件夹，而测试集的标签未知，所以仅建立一个名为unknown的子文件夹，存放所有测试数据。\n\n我们希望整理后的数据集目录结构为：\n```\n| train_valid_test\n    | train\n    |   | affenpinscher\n    |   |   | 00ca18751837cd6a22813f8e221f7819.jpg\n    |   |   | ...\n    |   | afghan_hound\n    |   |   | 0a4f1e17d720cdff35814651402b7cf4.jpg\n    |   |   | ...\n    |   | ...\n    | valid\n    |   | affenpinscher\n    |   |   | 56af8255b46eb1fa5722f37729525405.jpg\n    |   |   | ...\n    |   | afghan_hound\n    |   |   | 0df400016a7e7ab4abff824bf2743f02.jpg\n    |   |   | ...\n    |   | ...\n    | train_valid\n    |   | affenpinscher\n    |   |   | 00ca18751837cd6a22813f8e221f7819.jpg\n    |   |   | ...\n    |   | afghan_hound\n    |   |   | 0a4f1e17d720cdff35814651402b7cf4.jpg\n    |   |   | ...\n    |   | ...\n    | test\n    |   | unknown\n    |   |   | 00a3edd22dc7859c487a64777fc8d093.jpg\n    |   |   | ...\n```"},{"cell_type":"code","execution_count":3,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8EE3AFAC71D143C98206EF76C4A7F576","collapsed":false,"scrolled":false},"outputs":[],"source":"data_dir = '/home/kesci/input/Kaggle_Dog6357/dog-breed-identification'  # 数据集目录\nlabel_file, train_dir, test_dir = 'labels.csv', 'train', 'test'  # data_dir中的文件夹、文件\nnew_data_dir = './train_valid_test'  # 整理之后的数据存放的目录\nvalid_ratio = 0.1  # 验证集所占比例"},{"cell_type":"code","execution_count":4,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"749C44BBB8434C16AC8EAEB22AA1C9ED","collapsed":false,"scrolled":false},"outputs":[],"source":"def mkdir_if_not_exist(path):\n    # 若目录path不存在，则创建目录\n    if not os.path.exists(os.path.join(*path)):\n        os.makedirs(os.path.join(*path))\n        \ndef reorg_dog_data(data_dir, label_file, train_dir, test_dir, new_data_dir, valid_ratio):\n    # 读取训练数据标签\n    labels = pd.read_csv(os.path.join(data_dir, label_file))\n    id2label = {Id: label for Id, label in labels.values}  # (key: value): (id: label)\n\n    # 随机打乱训练数据\n    train_files = os.listdir(os.path.join(data_dir, train_dir))\n    random.shuffle(train_files)    \n\n    # 原训练集\n    valid_ds_size = int(len(train_files) * valid_ratio)  # 验证集大小\n    for i, file in enumerate(train_files):\n        img_id = file.split('.')[0]  # file是形式为id.jpg的字符串\n        img_label = id2label[img_id]\n        if i < valid_ds_size:\n            mkdir_if_not_exist([new_data_dir, 'valid', img_label])\n            shutil.copy(os.path.join(data_dir, train_dir, file),\n                        os.path.join(new_data_dir, 'valid', img_label))\n        else:\n            mkdir_if_not_exist([new_data_dir, 'train', img_label])\n            shutil.copy(os.path.join(data_dir, train_dir, file),\n                        os.path.join(new_data_dir, 'train', img_label))\n        mkdir_if_not_exist([new_data_dir, 'train_valid', img_label])\n        shutil.copy(os.path.join(data_dir, train_dir, file),\n                    os.path.join(new_data_dir, 'train_valid', img_label))\n\n    # 测试集\n    mkdir_if_not_exist([new_data_dir, 'test', 'unknown'])\n    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n                    os.path.join(new_data_dir, 'test', 'unknown'))"},{"cell_type":"code","execution_count":5,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"E16AEEFA70874141961C0FD88895B9EF","collapsed":false,"scrolled":false},"outputs":[],"source":"reorg_dog_data(data_dir, label_file, train_dir, test_dir, new_data_dir, valid_ratio)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_nib4akb","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6C567C4F30C3475DB4628406B698CBEB","mdEditEnable":false},"source":"## 图像增强"},{"cell_type":"code","execution_count":6,"metadata":{"graffitiCellId":"id_pdfj7om","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"750224C414DC431CB769A8702E255EAB","collapsed":false,"scrolled":false},"outputs":[],"source":"transform_train = transforms.Compose([\n    # 随机对图像裁剪出面积为原图像面积0.08~1倍、且高和宽之比在3/4~4/3的图像，再放缩为高和宽均为224像素的新图像\n    transforms.RandomResizedCrop(224, scale=(0.08, 1.0),  \n                                 ratio=(3.0/4.0, 4.0/3.0)),\n    # 以0.5的概率随机水平翻转\n    transforms.RandomHorizontalFlip(),\n    # 随机更改亮度、对比度和饱和度\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n    transforms.ToTensor(),\n    # 对各个通道做标准化，(0.485, 0.456, 0.406)和(0.229, 0.224, 0.225)是在ImageNet上计算得的各通道均值与方差\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet上的均值和方差\n])\n\n# 在测试集上的图像增强只做确定性的操作\ntransform_test = transforms.Compose([\n    transforms.Resize(256),\n    # 将图像中央的高和宽均为224的正方形区域裁剪出来\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A322F202B2D94BC68A886AFCA3510333","mdEditEnable":false},"source":"## 读取数据"},{"cell_type":"code","execution_count":7,"metadata":{"graffitiCellId":"id_xtlsjze","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"52DB31C52D0E49C58B1269EA8D251F45","collapsed":false,"scrolled":false},"outputs":[],"source":"# new_data_dir目录下有train, valid, train_valid, test四个目录\n# 这四个目录中，每个子目录表示一种类别，目录中是属于该类别的所有图像\ntrain_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'train'),\n                                            transform=transform_train)\nvalid_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'valid'),\n                                            transform=transform_test)\ntrain_valid_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'train_valid'),\n                                            transform=transform_train)\ntest_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'test'),\n                                            transform=transform_test)"},{"cell_type":"code","execution_count":8,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"13D59A2CAD1444AE84BAAC3C293EF681","collapsed":false,"scrolled":false},"outputs":[],"source":"batch_size = 128\ntrain_iter = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\ntrain_valid_iter = torch.utils.data.DataLoader(train_valid_ds, batch_size=batch_size, shuffle=True)\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)  # shuffle=False"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B1A0DA4055D14E17A3AD0C04C99E204A","mdEditEnable":false},"source":"## 定义模型\n\n这个比赛的数据属于ImageNet数据集的子集，我们使用微调的方法，选用在ImageNet完整数据集上预训练的模型来抽取图像特征，以作为自定义小规模输出网络的输入。\n\n此处我们使用与训练的ResNet-34模型，直接复用预训练模型在输出层的输入，即抽取的特征，然后我们重新定义输出层，本次我们仅对重定义的输出层的参数进行训练，而对于用于抽取特征的部分，我们保留预训练模型的参数。"},{"cell_type":"code","execution_count":9,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"475191DACA434C1F865914AD665041FA","collapsed":false,"scrolled":false},"outputs":[],"source":"def get_net(device):\n    finetune_net = models.resnet34(pretrained=False)  # 预训练的resnet34网络\n    finetune_net.load_state_dict(torch.load('/home/kesci/input/resnet347742/resnet34-333f7ec4.pth'))\n    for param in finetune_net.parameters():  # 冻结参数\n        param.requires_grad = False\n    # 原finetune_net.fc是一个输入单元数为512，输出单元数为1000的全连接层\n    # 替换掉原finetune_net.fc，新finetuen_net.fc中的模型参数会记录梯度\n    finetune_net.fc = nn.Sequential(\n        nn.Linear(in_features=512, out_features=256),\n        nn.ReLU(),\n        nn.Linear(in_features=256, out_features=120)  # 120是输出类别数\n    )\n    return finetune_net"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"5EAFA81D26A34F0C83E3DE44270C8C21","mdEditEnable":false},"source":"## 定义训练函数"},{"cell_type":"code","execution_count":10,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D5A6471E5B7C492C86D66BA578F7A1BE","collapsed":false,"scrolled":false},"outputs":[],"source":"def evaluate_loss_acc(data_iter, net, device):\n    # 计算data_iter上的平均损失与准确率\n    loss = nn.CrossEntropyLoss()\n    is_training = net.training  # Bool net是否处于train模式\n    net.eval()\n    l_sum, acc_sum, n = 0, 0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l_sum += l.item() * y.shape[0]\n            acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n            n += y.shape[0]\n    net.train(is_training)  # 恢复net的train/eval状态\n    return l_sum / n, acc_sum / n"},{"cell_type":"code","execution_count":11,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"01092780EA624512BCB57A85B5ADBC2A","collapsed":false,"scrolled":false},"outputs":[],"source":"def train(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period,\n          lr_decay):\n    loss = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.fc.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n    net = net.to(device)\n    for epoch in range(num_epochs):\n        train_l_sum, n, start = 0.0, 0, time.time()\n        if epoch > 0 and epoch % lr_period == 0:  # 每lr_period个epoch，学习率衰减一次\n            lr = lr * lr_decay\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n        for X, y in train_iter:\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n        time_s = \"time %.2f sec\" % (time.time() - start)\n        if valid_iter is not None:\n            valid_loss, valid_acc = evaluate_loss_acc(valid_iter, net, device)\n            epoch_s = (\"epoch %d, train loss %f, valid loss %f, valid acc %f, \"\n                       % (epoch + 1, train_l_sum / n, valid_loss, valid_acc))\n        else:\n            epoch_s = (\"epoch %d, train loss %f, \"\n                       % (epoch + 1, train_l_sum / n))\n        print(epoch_s + time_s + ', lr ' + str(lr))"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A737995D19A34C1ABDF8A1F57B3CBB99","mdEditEnable":false},"source":"## 调参"},{"cell_type":"code","execution_count":12,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1B48EF6702B14C1E9FBC9E16BA3EE4A4","collapsed":false,"scrolled":false},"outputs":[],"source":"num_epochs, lr_period, lr_decay = 20, 10, 0.1\nlr, wd = 0.03, 1e-4\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"},{"cell_type":"code","execution_count":13,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A6DF8EB7CB434980B07D3795A7F093A3","collapsed":false,"scrolled":false},"outputs":[],"source":"net = get_net(device)\ntrain(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay)"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9828385FE5B84A3A8E0246F2FC41DF55","mdEditEnable":false},"source":"## 在完整数据集上训练模型"},{"cell_type":"code","execution_count":14,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"24E7689CCE9948E18114BDCEE88D7F1D","collapsed":false,"scrolled":false},"outputs":[],"source":"# 使用上面的参数设置，在完整数据集上训练模型大致需要40-50分钟的时间\nnet = get_net(device)\ntrain(net, train_valid_iter, None, num_epochs, lr, wd, device, lr_period, lr_decay)"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8454359E77EA4653B30FCA248E209666","mdEditEnable":false},"source":"## 对测试集分类并提交结果\n\n用训练好的模型对测试数据进行预测。比赛要求对测试集中的每张图片，都要预测其属于各个类别的概率。"},{"cell_type":"code","execution_count":15,"metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"38D8D088E69B48349899C01802C0439D","collapsed":false,"scrolled":false},"outputs":[],"source":"preds = []\nfor X, _ in test_iter:\n    X = X.to(device)\n    output = net(X)\n    output = torch.softmax(output, dim=1)\n    preds += output.tolist()\nids = sorted(os.listdir(os.path.join(new_data_dir, 'test/unknown')))\nwith open('submission.csv', 'w') as f:\n    f.write('id,' + ','.join(train_valid_ds.classes) + '\\n')\n    for i, output in zip(ids, preds):\n        f.write(i.split('.')[0] + ',' + ','.join(\n            [str(num) for num in output]) + '\\n')"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}