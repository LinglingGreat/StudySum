

## 数据分桶

分桶是离散化的常用方法，将连续型特征离线化为一系列 0/1 的离散特征；

**当数值特征跨越不同的数量级的时候** ，模型可能会只对大的特征值敏感，这种情况可以考虑分桶操作。

**分桶操作可以看作是对数值变量的离散化** ，之后通过二值化进行 one-hot 编码。

分桶方法分为无监督分桶和有监督分桶。  
（1）常用的无监督分桶方法有等频分桶、等距分桶和聚类分桶。  
（2） 有监督分桶主要有best-ks分桶和卡方分桶。

分桶的数量和宽度可以根据业务领域的经验来指定，但也有一些常规的做法：

1. **等距分桶** 。每个桶的宽度是固定的，即值域范围是固定的，比如是 0-99，100-199，200-299等；**这种适合样本分布比较均匀的情况** ，避免出现有的桶的数量很少，而有的桶数量过多的情况；

2. **等频分桶** ，也称为分位数分桶。也就是每个桶有一样多的样本，但可能出现数值相差太大的样本放在同个桶的情况；

3. **模型分桶** 。使用模型找到最佳分桶，比如**聚类** ，将特征分成多个类别，或者**树模型** ，这种非线性模型天生具有对连续型特征切分的能力，利用特征分割点进行离散化。

**分桶的优点** ：

- 分桶后得到的稀疏向量，内积乘法运算速度更快，计算结果更方便存储；

- 对异常数据有很强的鲁棒性

**需要注意的是** ：

- 要让桶内的属性取值变化对样本标签的影响基本在一个不大的范围，即不能出现单个桶内，样本标签输出变化很大的情况；

- 每个桶内都有足够的样本，如果样本太少，随机性太大，不具有统计意义上的说服力；

- 每个桶内的样本进行分布均匀；

### **等距分桶** 

对于等距分桶的操作：

- **当数字跨越多个数量级时，最好用10个幂（或任何常数的幂）来分组** ：0－9、10-99、100-999、100-9999等。

- **容器宽度呈指数增长** ，从O（10）、O（100）到O（1000）和以上。要从计数映射到bin，**取计数的log值** 。

**对数变换是处理具有重尾分布的正数的有力工具** 。（重尾分布在尾部范围内的概率比高斯分布的概率大）。它将分布在高端的长尾压缩成较短的尾部，并将低端扩展成较长的头部。

下面是展示的代码例子：

数值较少的例子：

```python
import numpy as np
# 生成 20 个 0-99 之间的随机整数
small_counts = np.random.randint(0, 100, 20)

# 进行分箱操作, 通过对数据除以 10 分到 0-9 总共 9 个箱里，
# 返回的结果就是对应数据应该划分到的箱的编号
np.floor_divide(small_counts, 10)
```


数据之间的间隔较大的例子：

```python
# 构造一个间隔更大的数组例子，可以通过取对数 log10 来进行分箱
large_counts = [296, 8286, 64011, 80, 3, 725, 867, 2215, 7689, 11495, 91897, 44, 28, 7971, 926, 122, 22222]
np.floor(np.log10(large_counts))
```


### **等频分桶** 

对于等频分桶，也称为按分位数分桶，为了计算分位数和映射数据到分位数箱，我们可以使用 `Pandas` 库。`pandas.DataFrame.quantile` 和 `pandas.Series.quantile` 用于计算分位数。`pandas.qcut` 将数据映射到所需数量的分位数。

代码例子如下：

```python
large_counts = [296, 8286, 64011, 80, 3, 725, 867, 2215, 7689, 11495, 91897, 44, 28, 7971, 926, 122, 22222]
# 将数据映射到所需数量的分位数
pd.qcut(large_counts, 4, labels=False)
# 计算指定分位数点的数据
large_counts_series = pd.Series(large_counts)
large_counts_series.quantile([0.25, 0.5, 0.75])
```

### 卡方分桶

卡方分箱是自底向上的(即基于合并的)数据离散化方法。

它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。

基本思想:对于精确的离散化，相对类频率在一个区间内应当完全一致。因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。

分桶步骤：

第0步：预先设定一个卡方的阈值；

第一步：初始化

根据要离散的属性对实例进行排序：每个实例属于一个区间

第二步：合并区间
（1）计算每一对相邻区间的卡方值；
（2）将卡方值最小的一对区间合并

$X2=∑2i=1∑2j=1(Aij−Eij)2EijX2=∑i=12∑j=12(Aij−Eij)2E_{ij}X^2=∑_{i=1}^2∑_{j=1}^2\frac{(Aij-Eij)^2}{Eij}$

 Cj是第j类样本在全体中的比例。  

注意：初始化时需要对实例进行排序，在排序的基础上进行合并。  

**卡方阈值的确定**：

根据显著性水平和自由度得到卡方值

自由度比类别数量小1，例如：有3类，自由度为2，则90%置信度（10%显著性水平）下，卡方的值为4.6。

**阈值的意义**：

类别和属性独立时，有90%的可能性，计算得到的卡方值会小于4.6。

大于阈值4.6的卡方值就说明属性和类不是相互独立的，不能合并。如果阈值选的大，区间合并就会进行很多次，离散后的区间数量大、区间大。

注：

（1）ChiMerge算法推荐使用0.9、0.95、0.99置信度，最大区间数取10到15之间。

（2）也可以不考虑卡方阈值，此时可以考虑最小区间数或者最大区间数。指定区间数量的上限和下限 ，最多几个区间，最少几个区间。

（3）对于类别型变量，需要分桶时需要按照某种方式进行排序。


## 参考资料

[数据分桶](https://blog.csdn.net/fang156239305/article/details/107315666/)

