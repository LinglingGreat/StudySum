## 什么是异常检测

**异常检测（又称为离群点检测）**是找出其行为很不同于预期对象的过程。这种对象称为离群点或异常点。异常点是一个数据对象，它显著不同于其他数据对象，好像它是被不同的机制产生的一样。

异常检测可以描述成这样一个问题：

给定训练数据$\{x^1, x^2, ..., x^N\}$，我们试图训练出一个模型，模型能够检测输入数据$x$和训练数据是否相似。如果相似则$x$是正常点(normal)，如果不相似则$x$是异常点(anomaly)。不同的异常检测方法对于“相似”有着不同的定义方式。

注意，“异常检测”这个词表面上看好像是检测出那些不好的，因为异常通常代表负面的意思。但是其实异常检测不一定是找不好的对象，它只是找不同于训练数据的对象。异常检测在不同的领域有不同的叫法，例如anomaly detection, outlier detection, novelty detection。

异常检测的应用很广泛，比如在信用卡的欺诈检测中，如果信用卡被盗，交易模式通常会显著改变，异常检测则可以用来识别那些非常不同于正常情况的交易。异常检测还可以用在如机器故障检测、疾病检测、公共安全、网络入侵检测、图像分析等应用中。

另外，**异常点不同于噪声数据**。噪声是随观测变量的随机误差或方差。一般而言，噪声在数据分析中不是令人感兴趣的。与许多其他数据分析和数据挖掘任务一样，应该在异常检测前就删除噪声。

异常点是有趣的，因为怀疑产生它们的机制不同于产生其他数据的机制。因此，在异常检测时，重要的是搞清楚为什么检测到的异常点被某种其他机制产生。通常这样做：在其余数据上做各种假设，并且证明检测到的异常点显著违反了这些假设。

**异常类型**通常可以分为三类：全局异常点、情境（或条件）异常点和集体异常点。全局异常点（global outlier）显著地偏离数据集中的其余对象，例如在交易审计系统中，不遵守常规的交易可能被视为全局异常点，应该搁置以便进一步考察。情境异常点（contextual outlier）是该数据点在某个情境下显著偏离其它数据点的情况。在情境异常点检测中，一个对象是否是异常点不仅与行为属性有关，而且还跟情境属性有关。集体异常点（collective outlier）是作为整体显著偏离整个数据集的数据子集，即这里的异常点指的不是单个点，而是一群点。 

**如何做异常检测呢？**一种直观的想法是做分类，如果我们有足够的正常数据和足够的异常数据，那么我们训练一个二分类器就可以了。但是这样存在一些问题：

1.无法穷举异常数据所有的类型。假设我们的正常数据是小猫的图片，那么小狗的图片、小羊的图片、花的图片、人物的图片都是异常的，即所有非小猫的图片都是异常的，这显然无法穷举。

2.一般情况下收集异常数据很困难。

## 统计学方法

统计学方法对数据的正常性做出假定。**它们假定正常的数据对象由一个统计模型产生，而不遵守该模型的数据是异常点。**统计学方法的有效性高度依赖于对给定数据所做的统计模型假定是否成立。

异常检测的统计学方法的一般思想是：学习一个拟合给定数据集的生成模型，然后识别该模型低概率区域中的对象，把它们作为异常点。

即利用统计学方法建立一个模型，然后考虑对象有多大可能符合该模型。

根据如何指定和学习模型，异常检测的统计学方法可以划分为两个主要类型：参数方法和非参数方法。

**参数方法**假定正常的数据对象被一个以$\Theta$为参数的参数分布产生。该参数分布的概率密度函数$f(x,\Theta)$给出对象$x$被该分布产生的概率。该值越小，$x$越可能是异常点。

**非参数方法**并不假定先验统计模型，而是试图从输入数据确定模型。非参数方法通常假定参数的个数和性质都是灵活的，不预先确定（所以非参数方法并不是说模型是完全无参的，完全无参的情况下从数据学习模型是不可能的）。

### 参数方法

**1.基于正态分布的一元异常点检测**

仅涉及一个属性或变量的数据称为一元数据。我们假定数据由正态分布产生，然后可以由输入数据学习正态分布的参数，并把低概率的点识别为异常点。

假定输入数据集为$\{x^{(1)}, x^{(2)}, ..., x^{(m)}\}$，数据集中的样本服从正态分布，即$x^{(i)}\sim N(\mu, \sigma^2)$，我们可以根据样本求出参数$\mu$和$\sigma$。

$\mu=\frac 1m\sum_{i=1}^m x^{(i)}$

$\sigma^2=\frac 1m\sum_{i=1}^m (x^{(i)}-\mu)^2$

求出参数之后，我们就可以根据概率密度函数计算数据点服从该分布的概率。正态分布的概率密度函数为

$p(x)=\frac 1{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})$

如果计算出来的概率低于阈值，就可以认为该数据点为异常点。

阈值是个经验值，可以选择在验证集上使得评估指标值最大（也就是效果最好）的阈值取值作为最终阈值。

例如常用的3sigma原则中，如果数据点超过范围$(\mu-3\sigma, \mu+3\sigma)$，那么这些点很有可能是异常点。

这个方法还可以用于可视化。箱线图对数据分布做了一个简单的统计可视化，利用数据集的上下四分位数（Q1和Q3）、中点等形成。异常点常被定义为小于Q1－1.5IQR或大于Q3+1.5IQR的那些数据。

用Python画一个简单的箱线图：

```python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data = np.random.randn(50000) * 20 + 20
sns.boxplot(data=data)
```



**2.多元异常点检测**

涉及两个或多个属性或变量的数据称为多元数据。许多一元异常点检测方法都可以扩充，用来处理多元数据。其核心思想是把多元异常点检测任务转换成一元异常点检测问题。例如基于正态分布的一元异常点检测扩充到多元情形时，可以求出每一维度的均值和标准差。对于第$j$维：

$\mu_j=\frac 1m\sum_{i=1}^m x_j^{(i)}$

$\sigma_j^2=\frac 1m\sum_{i=1}^m (x_j^{(i)}-\mu_j)^2$

计算概率时的概率密度函数为

$p(x)=\prod_{j=1}^n p(x_j;\mu_j,\sigma_j^2)=\prod_{j=1}^n\frac 1{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$

这是在各个维度的特征之间相互独立的情况下。如果特征之间有相关性，就要用到多元高斯分布了。

**3.使用混合参数分布**

在许多情况下假定数据是由正态分布产生的。当实际数据很复杂时，这种假定过于简单，可以假定数据是被混合参数分布产生的。

### 非参数方法

在异常检测的非参数方法中，“正常数据”的模型从输入数据学习，而不是假定一个先验。通常，非参数方法对数据做较少假定，因而在更多情况下都可以使用。

**例子：使用直方图检测异常点。**

直方图是一种频繁使用的非参数统计模型，可以用来检测异常点。该过程包括如下两步：

步骤1：构造直方图。使用输入数据（训练数据）构造一个直方图。该直方图可以是一元的，或者多元的（如果输入数据是多维的）。

尽管非参数方法并不假定任何先验统计模型，但是通常确实要求用户提供参数，以便由数据学习。例如，用户必须指定直方图的类型（等宽的或等深的）和其他参数（直方图中的箱数或每个箱的大小等）。与参数方法不同，这些参数并不指定数据分布的类型。

步骤2：检测异常点。为了确定一个对象是否是异常点，可以对照直方图检查它。在最简单的方法中，如果该对象落入直方图的一个箱中，则该对象被看作正常的，否则被认为是异常点。

对于更复杂的方法，可以使用直方图赋予每个对象一个异常点得分。例如令对象的异常点得分为该对象落入的箱的容积的倒数。

使用直方图作为异常点检测的非参数模型的一个缺点是，很难选择一个合适的箱尺寸。一方面，如果箱尺寸太小，则许多正常对象都会落入空的或稀疏的箱中，因而被误识别为异常点。另一方面，如果箱尺寸太大，则异常点对象可能渗入某些频繁的箱中，因而“假扮”成正常的。



总结：异常检测的统计学方法由数据学习模型，以区别正常的数据对象和异常点。使用统计学方法的一个优点是，异常检测可以是统计上无可非议的。当然，仅当对数据所做的统计假定满足实际约束时才为真。

作业：你还知道什么异常检测的统计学方法呢？用你的理解简述一下该方法。

## 参考资料

李宏毅老师的机器学习课程

吴恩达老师的机器学习课程





