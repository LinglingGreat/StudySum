{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec之Skip-Gram模型-中文文本版\n",
    "\n",
    "下面代码将用TensorFlow实现Word2Vec中的Skip-Gram模型。\n",
    "\n",
    "关于Skip-Gram模型请参考上一篇[知乎专栏文章](https://zhuanlan.zhihu.com/p/27234078)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 加载数据\n",
    "\n",
    "数据集使用的是来自Matt Mahoney的维基百科文章，数据集已经被清洗过，去除了特殊符号等，并不是全量数据，只是部分数据，所以实际上最后训练出的结果很一般（语料不够）。\n",
    "\n",
    "如果想获取更全的语料数据，可以访问以下网站，这是gensim中Word2Vec提供的语料：\n",
    "\n",
    "- 来自Matt Mahoney预处理后的[文本子集](http://mattmahoney.net/dc/enwik9.zip)，里面包含了10亿个字符。\n",
    "- 与第一条一样的经过预处理的[文本数据](http://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2)，但是包含了30个亿的字符。\n",
    "- 多种语言的[训练文本](http://www.statmt.org/wmt11/translation-task.html#download)。\n",
    "- [UMBC webbase corpus](http://ebiquity.umbc.edu/redirect/to/resource/id/351/UMBC-webbase-corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/Javasplittedwords') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 数据预处理\n",
    "\n",
    "数据预处理过程主要包括：\n",
    "\n",
    "- 替换文本中特殊符号并去除低频词\n",
    "- 对文本分词\n",
    "- 构建语料\n",
    "- 单词映射表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 筛选低频词\n",
    "words_count = Counter(words)\n",
    "words = [w for w in words if words_count[w] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建映射表\n",
    "vocab = set(words)\n",
    "vocab_to_int = {w: c for c, w in enumerate(vocab)}\n",
    "int_to_vocab = {c: w for c, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 8623686\n",
      "unique words: 6791\n"
     ]
    }
   ],
   "source": [
    "print(\"total words: {}\".format(len(words)))\n",
    "print(\"unique words: {}\".format(len(set(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对原文本进行vocab到int的转换\n",
    "int_words = [vocab_to_int[w] for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 采样\n",
    "\n",
    "对停用词进行采样，例如“the”， “of”以及“for”这类单词进行剔除。剔除这些单词以后能够加快我们的训练过程，同时减少训练过程中的噪音。\n",
    "\n",
    "我们采用以下公式:\n",
    "$$ P(w_i) = 1 - \\sqrt{\\frac{t}{f(w_i)}} $$\n",
    "\n",
    "其中$ t $是一个阈值参数，一般为1e-3至1e-5。  \n",
    "$f(w_i)$ 是单词 $w_i$ 在整个数据集中的出现频次。  \n",
    "$P(w_i)$ 是单词被删除的概率。\n",
    "\n",
    ">这个公式和论文中描述的那个公式有一些不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 1e-5 # t值\n",
    "threshold = 0.9 # 剔除概率阈值\n",
    "\n",
    "# 统计单词出现频次\n",
    "int_word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "# 计算单词频率\n",
    "word_freqs = {w: c/total_count for w, c in int_word_counts.items()}\n",
    "# 计算被删除的概率\n",
    "prob_drop = {w: 1 - np.sqrt(t / word_freqs[w]) for w in int_word_counts}\n",
    "# 对单词进行采样\n",
    "train_words = [w for w in int_words if prob_drop[w] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883241"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 构造batch\n",
    "\n",
    "Skip-Gram模型是通过输入词来预测上下文。因此我们要构造我们的训练样本，具体思想请参考知乎专栏，这里不再重复。\n",
    "\n",
    "对于一个给定词，离它越近的词可能与它越相关，离它越远的词越不相关，这里我们设置窗口大小为5，对于每个训练单词，我们还会在[1:5]之间随机生成一个整数R，用R作为我们最终选择output word的窗口大小。这里之所以多加了一步随机数的窗口重新选择步骤，是为了能够让模型更聚焦于当前input word的邻近词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_targets(words, idx, window_size=5):\n",
    "    '''\n",
    "    获得input word的上下文单词列表\n",
    "    \n",
    "    参数\n",
    "    ---\n",
    "    words: 单词列表\n",
    "    idx: input word的索引号\n",
    "    window_size: 窗口大小\n",
    "    '''\n",
    "    target_window = np.random.randint(1, window_size+1)\n",
    "    # 这里要考虑input word前面单词不够的情况\n",
    "    start_point = idx - target_window if (idx - target_window) > 0 else 0\n",
    "    end_point = idx + target_window\n",
    "    # output words(即窗口中的上下文单词)\n",
    "    targets = set(words[start_point: idx] + words[idx+1: end_point+1])\n",
    "    return list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(words, batch_size, window_size=5):\n",
    "    '''\n",
    "    构造一个获取batch的生成器\n",
    "    '''\n",
    "    n_batches = len(words) // batch_size\n",
    "    \n",
    "    # 仅取full batches\n",
    "    words = words[:n_batches*batch_size]\n",
    "    \n",
    "    for idx in range(0, len(words), batch_size):\n",
    "        x, y = [], []\n",
    "        batch = words[idx: idx+batch_size]\n",
    "        for i in range(len(batch)):\n",
    "            batch_x = batch[i]\n",
    "            batch_y = get_targets(batch, i, window_size)\n",
    "            # 由于一个input word会对应多个output word，因此需要长度统一\n",
    "            x.extend([batch_x]*len(batch_y))\n",
    "            y.extend(batch_y)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 构建网络\n",
    "\n",
    "该部分主要包括：\n",
    "\n",
    "- 输入层\n",
    "- Embedding\n",
    "- Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, shape=[None], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, shape=[None, None], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "嵌入矩阵的矩阵形状为 $ vocab\\_size\\times hidden\\_units\\_size$ \n",
    "\n",
    "TensorFlow中的tf.nn.embedding_lookup函数可以实现lookup的计算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(int_to_vocab)\n",
    "embedding_size = 200 # 嵌入维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    # 嵌入层权重矩阵\n",
    "    embedding = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1, 1))\n",
    "    # 实现lookup\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling\n",
    "\n",
    "负采样主要是为了解决梯度下降计算速度慢的问题，详情同样参考我的上一篇知乎专栏文章。\n",
    "\n",
    "TensorFlow中的tf.nn.sampled_softmax_loss会在softmax层上进行采样计算损失，计算出的loss要比full softmax loss低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sampled = 100\n",
    "\n",
    "with train_graph.as_default():\n",
    "    softmax_w = tf.Variable(tf.truncated_normal([vocab_size, embedding_size], stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(vocab_size))\n",
    "    \n",
    "    # 计算negative sampling下的损失\n",
    "    loss = tf.nn.sampled_softmax_loss(softmax_w, softmax_b, labels, embed, n_sampled, vocab_size)\n",
    "    \n",
    "    cost = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证\n",
    "\n",
    "为了更加直观的看到我们训练的结果，我们将查看训练出的相近语义的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    # 随机挑选一些单词\n",
    "    ## From Thushan Ganegedara's implementation\n",
    "    valid_size = 7 # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "    valid_examples = [vocab_to_int['word'], \n",
    "                      vocab_to_int['ppt'], \n",
    "                      vocab_to_int['熟悉'],\n",
    "                      vocab_to_int['java'], \n",
    "                      vocab_to_int['能力'], \n",
    "                      vocab_to_int['逻辑思维'],\n",
    "                      vocab_to_int['了解']]\n",
    "    \n",
    "    valid_size = len(valid_examples)\n",
    "    # 验证单词集\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # 计算每个词向量的模并进行单位化\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))\n",
    "    normalized_embedding = embedding / norm\n",
    "    # 查找验证单词的词向量\n",
    "    valid_embedding = tf.nn.embedding_lookup(normalized_embedding, valid_dataset)\n",
    "    # 计算余弦相似度\n",
    "    similarity = tf.matmul(valid_embedding, tf.transpose(normalized_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 100 Avg. Training loss: 3.8901 0.1061 sec/batch\n",
      "Epoch 1/10 Iteration: 200 Avg. Training loss: 3.7713 0.0992 sec/batch\n",
      "Epoch 1/10 Iteration: 300 Avg. Training loss: 3.4199 0.0923 sec/batch\n",
      "Epoch 1/10 Iteration: 400 Avg. Training loss: 3.3403 0.1041 sec/batch\n",
      "Epoch 1/10 Iteration: 500 Avg. Training loss: 3.4817 0.1069 sec/batch\n",
      "Epoch 1/10 Iteration: 600 Avg. Training loss: 3.1479 0.1065 sec/batch\n",
      "Epoch 1/10 Iteration: 700 Avg. Training loss: 2.7737 0.1067 sec/batch\n",
      "Epoch 1/10 Iteration: 800 Avg. Training loss: 2.7500 0.1023 sec/batch\n",
      "Epoch 1/10 Iteration: 900 Avg. Training loss: 3.0976 0.1019 sec/batch\n",
      "Epoch 1/10 Iteration: 1000 Avg. Training loss: 2.9936 0.0999 sec/batch\n",
      "Nearest to [word]: 公关, 机构, 诚恳, 革新, 内涵, 培训讲师, 主播, 同行,\n",
      "Nearest to [ppt]: 官网, 新产品, 汇总, 前期, 小说, 技术开发, 操, 新媒体营销,\n",
      "Nearest to [熟悉]: 不拘泥, 态度, 考试, 所需, 麻将, 年初, 经纪人, 科目,\n",
      "Nearest to [java]: 最优, 信用卡, 竞争力, 全力, 录入, 热爱工作, 重庆, 建筑,\n",
      "Nearest to [能力]: 人事管理, 报警, 上传下达, 成交, 新闻报道, 计算机, 算清, 同理,\n",
      "Nearest to [逻辑思维]: 绩效考核, 自动控制, 前台, 登录, 厂商, 态度端正, 部件, email,\n",
      "Nearest to [了解]: 专情, 分析方法, 高强, 求职, 极客, 完整, 调研, 方向和,\n",
      "Epoch 1/10 Iteration: 1100 Avg. Training loss: 3.0001 0.1061 sec/batch\n",
      "Epoch 1/10 Iteration: 1200 Avg. Training loss: 2.8105 0.1082 sec/batch\n",
      "Epoch 1/10 Iteration: 1300 Avg. Training loss: 2.8203 0.1066 sec/batch\n",
      "Epoch 1/10 Iteration: 1400 Avg. Training loss: 2.9437 0.1011 sec/batch\n",
      "Epoch 1/10 Iteration: 1500 Avg. Training loss: 2.7218 0.1010 sec/batch\n",
      "Epoch 1/10 Iteration: 1600 Avg. Training loss: 2.7688 0.1044 sec/batch\n",
      "Epoch 1/10 Iteration: 1700 Avg. Training loss: 3.1067 0.1042 sec/batch\n",
      "Epoch 1/10 Iteration: 1800 Avg. Training loss: 2.8744 0.1088 sec/batch\n",
      "Epoch 1/10 Iteration: 1900 Avg. Training loss: 2.5588 0.0980 sec/batch\n",
      "Epoch 1/10 Iteration: 2000 Avg. Training loss: 2.6229 0.0957 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 宏观, 机构, 版主, 条理清晰, 中英文, 参加,\n",
      "Nearest to [ppt]: 官网, 操, 会计师, 小说, 会计学, 前期, 新产品, 汇总,\n",
      "Nearest to [熟悉]: 不拘泥, 态度, 所需, 考试, 麻将, 经纪人, 格式, jquery,\n",
      "Nearest to [java]: 信用卡, 竞争力, 最优, 全力, 录入, 热爱工作, 切入点, 重庆,\n",
      "Nearest to [能力]: 人事管理, 新闻报道, 上传下达, 成交, 报警, 计算机, 同理, 读者,\n",
      "Nearest to [逻辑思维]: 登录, 自动控制, 绩效考核, email, 态度端正, 语言表达, 厂商, 前台,\n",
      "Nearest to [了解]: 分析方法, 专情, 高强, 极客, 求职, 调研, 完整, 方向和,\n",
      "Epoch 1/10 Iteration: 2100 Avg. Training loss: 2.8406 0.1024 sec/batch\n",
      "Epoch 1/10 Iteration: 2200 Avg. Training loss: 2.6292 0.1021 sec/batch\n",
      "Epoch 1/10 Iteration: 2300 Avg. Training loss: 2.5925 0.1025 sec/batch\n",
      "Epoch 1/10 Iteration: 2400 Avg. Training loss: 2.6037 0.1025 sec/batch\n",
      "Epoch 1/10 Iteration: 2500 Avg. Training loss: 2.7787 0.1000 sec/batch\n",
      "Epoch 1/10 Iteration: 2600 Avg. Training loss: 2.4620 0.1048 sec/batch\n",
      "Epoch 1/10 Iteration: 2700 Avg. Training loss: 2.4601 0.1059 sec/batch\n",
      "Epoch 1/10 Iteration: 2800 Avg. Training loss: 2.5236 0.1024 sec/batch\n",
      "Epoch 1/10 Iteration: 2900 Avg. Training loss: 2.5481 0.1056 sec/batch\n",
      "Epoch 1/10 Iteration: 3000 Avg. Training loss: 2.7527 0.1098 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 条理清晰, 引见, 宏观, 版主, 机构, 中英文,\n",
      "Nearest to [ppt]: 操, 新产品, 会计学, 会计师, 前期, 官网, 网络资源, 调节,\n",
      "Nearest to [熟悉]: 不拘泥, 态度, 所需, 格式, 考试, 麻将, 缺陷, 经纪人,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 最优, 热爱工作, 录入, 切入点, 建筑,\n",
      "Nearest to [能力]: 成交, 新闻报道, 人事管理, 上传下达, 报警, 计算机, 读者, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 语言表达, email, 学科, 态度端正, 绩效考核, 起来,\n",
      "Nearest to [了解]: 分析方法, 完整, 专情, 极客, 调研, 求职, 高强, 方向和,\n",
      "Epoch 1/10 Iteration: 3100 Avg. Training loss: 2.3768 0.1091 sec/batch\n",
      "Epoch 1/10 Iteration: 3200 Avg. Training loss: 2.5342 0.1139 sec/batch\n",
      "Epoch 1/10 Iteration: 3300 Avg. Training loss: 2.7307 0.1018 sec/batch\n",
      "Epoch 1/10 Iteration: 3400 Avg. Training loss: 2.3602 0.1121 sec/batch\n",
      "Epoch 1/10 Iteration: 3500 Avg. Training loss: 2.2916 0.1086 sec/batch\n",
      "Epoch 1/10 Iteration: 3600 Avg. Training loss: 2.4891 0.1052 sec/batch\n",
      "Epoch 1/10 Iteration: 3700 Avg. Training loss: 2.4484 0.1061 sec/batch\n",
      "Epoch 1/10 Iteration: 3800 Avg. Training loss: 2.5521 0.0996 sec/batch\n",
      "Epoch 2/10 Iteration: 3900 Avg. Training loss: 2.3787 0.0168 sec/batch\n",
      "Epoch 2/10 Iteration: 4000 Avg. Training loss: 2.2664 0.1070 sec/batch\n",
      "Nearest to [word]: 熟练应用, 条理清晰, 诚恳, 中英文, 版主, 引见, 宏观, 公关,\n",
      "Nearest to [ppt]: 会计学, 操, 新产品, 会计师, 词性, 操作, scala, 出品,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 所需, 态度, 考试, 麻将, 缺陷, 经纪人,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 建筑, 最优, 录入, 热爱工作, 方面,\n",
      "Nearest to [能力]: 成交, 新闻报道, 计算机, 同理, 读者, 估值, 人事管理, 报警,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 语言表达, 学科, email, 态度端正, 体系结构, 前台,\n",
      "Nearest to [了解]: 分析方法, 极客, 完整, 专情, 调研, 求职, 方向和, 高强,\n",
      "Epoch 2/10 Iteration: 4100 Avg. Training loss: 2.6017 0.1041 sec/batch\n",
      "Epoch 2/10 Iteration: 4200 Avg. Training loss: 2.2467 0.1075 sec/batch\n",
      "Epoch 2/10 Iteration: 4300 Avg. Training loss: 2.5482 0.1047 sec/batch\n",
      "Epoch 2/10 Iteration: 4400 Avg. Training loss: 2.5638 0.1040 sec/batch\n",
      "Epoch 2/10 Iteration: 4500 Avg. Training loss: 2.4796 0.1094 sec/batch\n",
      "Epoch 2/10 Iteration: 4600 Avg. Training loss: 2.3531 0.1032 sec/batch\n",
      "Epoch 2/10 Iteration: 4700 Avg. Training loss: 2.2179 0.1117 sec/batch\n",
      "Epoch 2/10 Iteration: 4800 Avg. Training loss: 2.6368 0.1131 sec/batch\n",
      "Epoch 2/10 Iteration: 4900 Avg. Training loss: 2.4986 0.1100 sec/batch\n",
      "Epoch 2/10 Iteration: 5000 Avg. Training loss: 2.5481 0.1061 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 条理清晰, 版主, 中英文, 公关, 引见, 五官,\n",
      "Nearest to [ppt]: 网络资源, 会计学, 官网, 操, 词性, 前期, 操作, 出品,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 所需, 麻将, 缺陷, 考试, 态度, 记录,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 建筑, 最优, 热爱工作, 切入点, 研发管理,\n",
      "Nearest to [能力]: 成交, 新闻报道, 读者, 计算机, 估值, 宝, 同理, 人事管理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 学科, 态度端正, email, 前台, 程序设计,\n",
      "Nearest to [了解]: 分析方法, 极客, 专情, 方向和, 求职, 完整, 调研, 高强,\n",
      "Epoch 2/10 Iteration: 5100 Avg. Training loss: 2.3680 0.1084 sec/batch\n",
      "Epoch 2/10 Iteration: 5200 Avg. Training loss: 2.5972 0.1009 sec/batch\n",
      "Epoch 2/10 Iteration: 5300 Avg. Training loss: 2.6703 0.1004 sec/batch\n",
      "Epoch 2/10 Iteration: 5400 Avg. Training loss: 2.5245 0.1097 sec/batch\n",
      "Epoch 2/10 Iteration: 5500 Avg. Training loss: 2.3114 0.1089 sec/batch\n",
      "Epoch 2/10 Iteration: 5600 Avg. Training loss: 2.4815 0.1119 sec/batch\n",
      "Epoch 2/10 Iteration: 5700 Avg. Training loss: 2.3145 0.1051 sec/batch\n",
      "Epoch 2/10 Iteration: 5800 Avg. Training loss: 2.3483 0.1044 sec/batch\n",
      "Epoch 2/10 Iteration: 5900 Avg. Training loss: 2.4539 0.1075 sec/batch\n",
      "Epoch 2/10 Iteration: 6000 Avg. Training loss: 2.4814 0.1020 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 引见, 条理清晰, 中英文, 交予, 版主, 宏观,\n",
      "Nearest to [ppt]: 会计学, 操, 网络资源, 新产品, 前期, 操作, 文字处理, 词性,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 所需, 缺陷, 考试, 麻将, 态度, jquery,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 建筑, 切入点, 热爱工作, 研发管理, 重庆,\n",
      "Nearest to [能力]: 成交, 新闻报道, 读者, 宝, 估值, 计算机, 人事管理, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 学科, 易用性, 态度端正, 绩效考核, 措施,\n",
      "Nearest to [了解]: 分析方法, 极客, 方向和, 专情, 求职, 调研, 高强, 完整,\n",
      "Epoch 2/10 Iteration: 6100 Avg. Training loss: 2.4182 0.1059 sec/batch\n",
      "Epoch 2/10 Iteration: 6200 Avg. Training loss: 2.3543 0.1016 sec/batch\n",
      "Epoch 2/10 Iteration: 6300 Avg. Training loss: 2.4256 0.0988 sec/batch\n",
      "Epoch 2/10 Iteration: 6400 Avg. Training loss: 2.5505 0.1009 sec/batch\n",
      "Epoch 2/10 Iteration: 6500 Avg. Training loss: 2.3274 0.0977 sec/batch\n",
      "Epoch 2/10 Iteration: 6600 Avg. Training loss: 2.2954 0.1005 sec/batch\n",
      "Epoch 2/10 Iteration: 6700 Avg. Training loss: 2.2094 0.1480 sec/batch\n",
      "Epoch 2/10 Iteration: 6800 Avg. Training loss: 2.4527 0.1587 sec/batch\n",
      "Epoch 2/10 Iteration: 6900 Avg. Training loss: 2.4233 0.1534 sec/batch\n",
      "Epoch 2/10 Iteration: 7000 Avg. Training loss: 2.2100 0.1017 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 引见, 交予, 五官, 条理清晰, 中英文, 公关,\n",
      "Nearest to [ppt]: 会计学, 网络资源, 操, 操作, 前期, 词性, 新产品, 调节,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 所需, 缺陷, 记录, 考试, 麻将, 态度,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 坚守, 热爱工作, 建筑, 研发管理, 切入点,\n",
      "Nearest to [能力]: 成交, 宝, 新闻报道, 估值, 读者, 计算机, 人事管理, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 态度端正, 学科, 登录, 主人翁, email, 前台,\n",
      "Nearest to [了解]: 分析方法, 极客, 方向和, 求职, 完整, 专情, 调研, 高强,\n",
      "Epoch 2/10 Iteration: 7100 Avg. Training loss: 2.4302 0.1105 sec/batch\n",
      "Epoch 2/10 Iteration: 7200 Avg. Training loss: 2.4471 0.1101 sec/batch\n",
      "Epoch 2/10 Iteration: 7300 Avg. Training loss: 2.2091 0.1013 sec/batch\n",
      "Epoch 2/10 Iteration: 7400 Avg. Training loss: 2.1250 0.1028 sec/batch\n",
      "Epoch 2/10 Iteration: 7500 Avg. Training loss: 2.3038 0.1096 sec/batch\n",
      "Epoch 2/10 Iteration: 7600 Avg. Training loss: 2.2855 0.1016 sec/batch\n",
      "Epoch 2/10 Iteration: 7700 Avg. Training loss: 2.3064 0.0984 sec/batch\n",
      "Epoch 3/10 Iteration: 7800 Avg. Training loss: 2.2769 0.0361 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Iteration: 7900 Avg. Training loss: 2.1527 0.1104 sec/batch\n",
      "Epoch 3/10 Iteration: 8000 Avg. Training loss: 2.5490 0.1109 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 条理清晰, 中英文, 版主, 交互性, 交予, 公关,\n",
      "Nearest to [ppt]: 会计学, 词性, 操, 网络资源, 新产品, 文字处理, 操作, 前期,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 所需, 缺陷, 记录, 考试, 麻将, jquery,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 建筑, 热爱工作, 研发管理, 坚守, 安全,\n",
      "Nearest to [能力]: 成交, 宝, 新闻报道, 读者, 计算机, 同理, 估值, 人事管理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 学科, 程序设计, 主人翁, 体系结构,\n",
      "Nearest to [了解]: 分析方法, 方向和, 求职, 极客, 完整, 专情, 调研, 高强,\n",
      "Epoch 3/10 Iteration: 8100 Avg. Training loss: 1.8622 0.1001 sec/batch\n",
      "Epoch 3/10 Iteration: 8200 Avg. Training loss: 2.5565 0.0981 sec/batch\n",
      "Epoch 3/10 Iteration: 8300 Avg. Training loss: 2.3739 0.1019 sec/batch\n",
      "Epoch 3/10 Iteration: 8400 Avg. Training loss: 2.3665 0.1049 sec/batch\n",
      "Epoch 3/10 Iteration: 8500 Avg. Training loss: 2.2349 0.1062 sec/batch\n",
      "Epoch 3/10 Iteration: 8600 Avg. Training loss: 2.1831 0.1060 sec/batch\n",
      "Epoch 3/10 Iteration: 8700 Avg. Training loss: 2.6043 0.1035 sec/batch\n",
      "Epoch 3/10 Iteration: 8800 Avg. Training loss: 2.4038 0.1082 sec/batch\n",
      "Epoch 3/10 Iteration: 8900 Avg. Training loss: 2.4426 0.1032 sec/batch\n",
      "Epoch 3/10 Iteration: 9000 Avg. Training loss: 2.3974 0.0974 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 版主, 交互性, 公关, 中英文, 交予, 条理清晰,\n",
      "Nearest to [ppt]: 网络资源, 会计学, 词性, 前期, 文字处理, 操, 官网, 出品,\n",
      "Nearest to [熟悉]: 不拘泥, 格式, 缺陷, 所需, 记录, 麻将, jquery, 考试,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 参照, 热爱工作, 坚守, 融入, 研发管理,\n",
      "Nearest to [能力]: 成交, 宝, 读者, 估值, 计算机, 新闻报道, 同理, 敏锐地,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 态度端正, 登录, 程序设计, 前台, 学科, email,\n",
      "Nearest to [了解]: 分析方法, 方向和, 求职, 极客, 专情, 完整, 调研, 高强,\n",
      "Epoch 3/10 Iteration: 9100 Avg. Training loss: 2.4719 0.0914 sec/batch\n",
      "Epoch 3/10 Iteration: 9200 Avg. Training loss: 2.5180 0.1020 sec/batch\n",
      "Epoch 3/10 Iteration: 9300 Avg. Training loss: 2.4233 0.0942 sec/batch\n",
      "Epoch 3/10 Iteration: 9400 Avg. Training loss: 2.2033 0.0923 sec/batch\n",
      "Epoch 3/10 Iteration: 9500 Avg. Training loss: 2.3508 0.0934 sec/batch\n",
      "Epoch 3/10 Iteration: 9600 Avg. Training loss: 2.1063 0.0915 sec/batch\n",
      "Epoch 3/10 Iteration: 9700 Avg. Training loss: 2.3535 0.0925 sec/batch\n",
      "Epoch 3/10 Iteration: 9800 Avg. Training loss: 2.3526 0.0930 sec/batch\n",
      "Epoch 3/10 Iteration: 9900 Avg. Training loss: 2.4059 0.0941 sec/batch\n",
      "Epoch 3/10 Iteration: 10000 Avg. Training loss: 2.3717 0.0938 sec/batch\n",
      "Nearest to [word]: 熟练应用, 交互性, 诚恳, 交予, 友善, 条理清晰, 版主, office,\n",
      "Nearest to [ppt]: 网络资源, 前期, 新产品, 操, 文字处理, 操作, 会计学, 词性,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 所需, 麻将, 考试, 记录, jquery,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 参照, 热爱工作, 坚守, 建筑, 安全,\n",
      "Nearest to [能力]: 成交, 宝, 估值, 计算机, 敏锐地, 新闻报道, 人事管理, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 易用性, 态度端正, 登录, 学科, 主人翁, 措施,\n",
      "Nearest to [了解]: 分析方法, 方向和, 求职, 极客, 专情, 下级, 高强, 调研,\n",
      "Epoch 3/10 Iteration: 10100 Avg. Training loss: 2.2287 0.0934 sec/batch\n",
      "Epoch 3/10 Iteration: 10200 Avg. Training loss: 2.4028 0.0931 sec/batch\n",
      "Epoch 3/10 Iteration: 10300 Avg. Training loss: 2.3686 0.0925 sec/batch\n",
      "Epoch 3/10 Iteration: 10400 Avg. Training loss: 2.2639 0.0935 sec/batch\n",
      "Epoch 3/10 Iteration: 10500 Avg. Training loss: 2.2041 0.1011 sec/batch\n",
      "Epoch 3/10 Iteration: 10600 Avg. Training loss: 2.0888 0.1087 sec/batch\n",
      "Epoch 3/10 Iteration: 10700 Avg. Training loss: 2.4876 0.0971 sec/batch\n",
      "Epoch 3/10 Iteration: 10800 Avg. Training loss: 2.2807 0.0950 sec/batch\n",
      "Epoch 3/10 Iteration: 10900 Avg. Training loss: 2.0511 0.0932 sec/batch\n",
      "Epoch 3/10 Iteration: 11000 Avg. Training loss: 2.4640 0.0918 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 交予, 友善, 公关, office, 平者让, 五官,\n",
      "Nearest to [ppt]: 网络资源, 词性, 会计学, 操, 前期, 新产品, 文字处理, 操作,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 所需, 记录, 考试, jquery, 老客户,\n",
      "Nearest to [java]: 全力, 坚守, 信用卡, 参照, 热爱工作, 竞争力, 融入, 秉持,\n",
      "Nearest to [能力]: 成交, 宝, 估值, 计算机, 人事管理, 新闻报道, 读者, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 态度端正, 登录, 主人翁, 学科, 有意者, 前台,\n",
      "Nearest to [了解]: 分析方法, 方向和, 求职, 极客, 专情, 完整, 调研, 想要,\n",
      "Epoch 3/10 Iteration: 11100 Avg. Training loss: 2.4339 0.0920 sec/batch\n",
      "Epoch 3/10 Iteration: 11200 Avg. Training loss: 2.1100 0.0940 sec/batch\n",
      "Epoch 3/10 Iteration: 11300 Avg. Training loss: 2.0882 0.0947 sec/batch\n",
      "Epoch 3/10 Iteration: 11400 Avg. Training loss: 2.3160 0.0912 sec/batch\n",
      "Epoch 3/10 Iteration: 11500 Avg. Training loss: 2.2572 0.0933 sec/batch\n",
      "Epoch 3/10 Iteration: 11600 Avg. Training loss: 2.3440 0.0933 sec/batch\n",
      "Epoch 4/10 Iteration: 11700 Avg. Training loss: 2.2492 0.0483 sec/batch\n",
      "Epoch 4/10 Iteration: 11800 Avg. Training loss: 2.1278 0.0983 sec/batch\n",
      "Epoch 4/10 Iteration: 11900 Avg. Training loss: 2.4522 0.1044 sec/batch\n",
      "Epoch 4/10 Iteration: 12000 Avg. Training loss: 1.8461 0.1059 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 友善, 公关, 平者让, 交予, 交互性, 版主,\n",
      "Nearest to [ppt]: 网络资源, 操作, 词性, 会计学, 操, 文字处理, 前期, 新产品,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 所需, 记录, jquery, 考试, 麻将,\n",
      "Nearest to [java]: 全力, 信用卡, 竞争力, 秉持, 坚守, 安全, 融入, 热爱工作,\n",
      "Nearest to [能力]: 成交, 宝, 计算机, 人事管理, 估值, 同理, 新闻报道, 敏锐地,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 程序设计, 学科, 措施, 主人翁,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 极客, 专情, 完整, 调研, 下级,\n",
      "Epoch 4/10 Iteration: 12100 Avg. Training loss: 2.5512 0.1048 sec/batch\n",
      "Epoch 4/10 Iteration: 12200 Avg. Training loss: 2.4090 0.1025 sec/batch\n",
      "Epoch 4/10 Iteration: 12300 Avg. Training loss: 2.3034 0.0949 sec/batch\n",
      "Epoch 4/10 Iteration: 12400 Avg. Training loss: 2.1276 0.0940 sec/batch\n",
      "Epoch 4/10 Iteration: 12500 Avg. Training loss: 2.2052 0.0925 sec/batch\n",
      "Epoch 4/10 Iteration: 12600 Avg. Training loss: 2.5346 0.0937 sec/batch\n",
      "Epoch 4/10 Iteration: 12700 Avg. Training loss: 2.3736 0.0946 sec/batch\n",
      "Epoch 4/10 Iteration: 12800 Avg. Training loss: 2.4165 0.0927 sec/batch\n",
      "Epoch 4/10 Iteration: 12900 Avg. Training loss: 2.3725 0.0934 sec/batch\n",
      "Epoch 4/10 Iteration: 13000 Avg. Training loss: 2.4449 0.0918 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 公关, 平者让, 交互性, 友善, 交予, 版主,\n",
      "Nearest to [ppt]: 网络资源, 词性, 文字处理, 会计学, 操, 前期, 操作, 新产品,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 所需, 记录, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 坚守, 秉持, 融入, 信用卡, 热爱工作, 竞争力, 参照,\n",
      "Nearest to [能力]: 成交, 宝, 计算机, 人事管理, 估值, 敏锐地, 受众, 读者,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 程序设计, email, 有意者, 学科,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 极客, 下级, 调研, 想要,\n",
      "Epoch 4/10 Iteration: 13100 Avg. Training loss: 2.5027 0.0912 sec/batch\n",
      "Epoch 4/10 Iteration: 13200 Avg. Training loss: 2.3627 0.0915 sec/batch\n",
      "Epoch 4/10 Iteration: 13300 Avg. Training loss: 2.1935 0.0909 sec/batch\n",
      "Epoch 4/10 Iteration: 13400 Avg. Training loss: 2.4265 0.0925 sec/batch\n",
      "Epoch 4/10 Iteration: 13500 Avg. Training loss: 1.9420 0.0911 sec/batch\n",
      "Epoch 4/10 Iteration: 13600 Avg. Training loss: 2.3518 0.0945 sec/batch\n",
      "Epoch 4/10 Iteration: 13700 Avg. Training loss: 2.3770 0.0914 sec/batch\n",
      "Epoch 4/10 Iteration: 13800 Avg. Training loss: 2.4162 0.0945 sec/batch\n",
      "Epoch 4/10 Iteration: 13900 Avg. Training loss: 2.3620 0.0935 sec/batch\n",
      "Epoch 4/10 Iteration: 14000 Avg. Training loss: 2.2025 0.0953 sec/batch\n",
      "Nearest to [word]: 熟练应用, 交互性, 诚恳, 友善, 公关, office, 常用工具, 交予,\n",
      "Nearest to [ppt]: 操, 网络资源, project, 操作, 前期, 新产品, 文字处理, 词性,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 记录, 所需, 考试, jquery, 老客户,\n",
      "Nearest to [java]: 全力, 秉持, 坚守, 融入, 热爱工作, 安全, 参照, 信用卡,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 估值, 延伸, 敏锐地, 著名,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 易用性, 主人翁, 态度端正, 精准, 学科,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 极客, 专情, 高强, 下级, 想要,\n",
      "Epoch 4/10 Iteration: 14100 Avg. Training loss: 2.3998 0.0938 sec/batch\n",
      "Epoch 4/10 Iteration: 14200 Avg. Training loss: 2.3610 0.0931 sec/batch\n",
      "Epoch 4/10 Iteration: 14300 Avg. Training loss: 2.1467 0.0943 sec/batch\n",
      "Epoch 4/10 Iteration: 14400 Avg. Training loss: 2.2206 0.0922 sec/batch\n",
      "Epoch 4/10 Iteration: 14500 Avg. Training loss: 2.0382 0.0932 sec/batch\n",
      "Epoch 4/10 Iteration: 14600 Avg. Training loss: 2.3714 0.0925 sec/batch\n",
      "Epoch 4/10 Iteration: 14700 Avg. Training loss: 2.1986 0.0941 sec/batch\n",
      "Epoch 4/10 Iteration: 14800 Avg. Training loss: 2.1062 0.0947 sec/batch\n",
      "Epoch 4/10 Iteration: 14900 Avg. Training loss: 2.4627 0.0927 sec/batch\n",
      "Epoch 4/10 Iteration: 15000 Avg. Training loss: 2.3523 0.0921 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 交互性, 友善, 公关, 平者让, office, 交予,\n",
      "Nearest to [ppt]: 网络资源, 操, project, 文字处理, 前期, 操作, 词性, 新产品,\n",
      "Nearest to [熟悉]: 不拘泥, 缺陷, 格式, 记录, 所需, 老客户, jquery, 考试,\n",
      "Nearest to [java]: 全力, 坚守, 秉持, 融入, 安全, 热爱工作, 信用卡, 研发管理,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 估值, 人事管理, 著名, 敏锐地, 手持,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 主人翁, 有意者, 易用性, 程序设计,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 极客, 高强, 想要, 完整,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Iteration: 15100 Avg. Training loss: 2.1128 0.0945 sec/batch\n",
      "Epoch 4/10 Iteration: 15200 Avg. Training loss: 2.0971 0.0930 sec/batch\n",
      "Epoch 4/10 Iteration: 15300 Avg. Training loss: 2.2563 0.1008 sec/batch\n",
      "Epoch 4/10 Iteration: 15400 Avg. Training loss: 2.2727 0.1037 sec/batch\n",
      "Epoch 4/10 Iteration: 15500 Avg. Training loss: 2.2474 0.1037 sec/batch\n",
      "Epoch 5/10 Iteration: 15600 Avg. Training loss: 2.1207 0.0701 sec/batch\n",
      "Epoch 5/10 Iteration: 15700 Avg. Training loss: 2.2184 0.1021 sec/batch\n",
      "Epoch 5/10 Iteration: 15800 Avg. Training loss: 2.3385 0.1111 sec/batch\n",
      "Epoch 5/10 Iteration: 15900 Avg. Training loss: 1.8494 0.1084 sec/batch\n",
      "Epoch 5/10 Iteration: 16000 Avg. Training loss: 2.5302 0.1034 sec/batch\n",
      "Nearest to [word]: 熟练应用, 诚恳, 平者让, 友善, 公关, 空白, office, 交互性,\n",
      "Nearest to [ppt]: 网络资源, 操, 操作, 文字处理, 透视, 词性, project, 会计学,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, 所需, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 坚守, 融入, 秉持, 安全, 竞争力, 信用卡, 热爱工作,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 估值, 报警, 受众, 敏锐地,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 措施, 主人翁, 有意者, email,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 想要, 极客, 高强, 完整,\n",
      "Epoch 5/10 Iteration: 16100 Avg. Training loss: 2.3598 0.0980 sec/batch\n",
      "Epoch 5/10 Iteration: 16200 Avg. Training loss: 2.2270 0.0954 sec/batch\n",
      "Epoch 5/10 Iteration: 16300 Avg. Training loss: 2.1635 0.1101 sec/batch\n",
      "Epoch 5/10 Iteration: 16400 Avg. Training loss: 2.2837 0.1035 sec/batch\n",
      "Epoch 5/10 Iteration: 16500 Avg. Training loss: 2.5156 0.1030 sec/batch\n",
      "Epoch 5/10 Iteration: 16600 Avg. Training loss: 2.3855 0.1004 sec/batch\n",
      "Epoch 5/10 Iteration: 16700 Avg. Training loss: 2.2802 0.1010 sec/batch\n",
      "Epoch 5/10 Iteration: 16800 Avg. Training loss: 2.3853 0.0998 sec/batch\n",
      "Epoch 5/10 Iteration: 16900 Avg. Training loss: 2.4511 0.1066 sec/batch\n",
      "Epoch 5/10 Iteration: 17000 Avg. Training loss: 2.4028 0.1137 sec/batch\n",
      "Nearest to [word]: 熟练应用, 平者让, 诚恳, 交互性, 友善, office, 公关, 交予,\n",
      "Nearest to [ppt]: 网络资源, 文字处理, 操作, 操, 官网, 词性, 透视, 前期,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, 所需, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 坚守, 安全, 参照, 信用卡, 精美,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 估值, 人事管理, 敏锐地, 著名, 受众,\n",
      "Nearest to [逻辑思维]: 自动控制, 语言表达, 登录, 态度端正, 程序设计, 措施, 有意者, email,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 高强, 极客, 下级, 肯吃苦,\n",
      "Epoch 5/10 Iteration: 17100 Avg. Training loss: 2.3123 0.1121 sec/batch\n",
      "Epoch 5/10 Iteration: 17200 Avg. Training loss: 2.2028 0.1025 sec/batch\n",
      "Epoch 5/10 Iteration: 17300 Avg. Training loss: 2.3430 0.0982 sec/batch\n",
      "Epoch 5/10 Iteration: 17400 Avg. Training loss: 1.9336 0.0954 sec/batch\n",
      "Epoch 5/10 Iteration: 17500 Avg. Training loss: 2.3115 0.1033 sec/batch\n",
      "Epoch 5/10 Iteration: 17600 Avg. Training loss: 2.3637 0.1016 sec/batch\n",
      "Epoch 5/10 Iteration: 17700 Avg. Training loss: 2.3426 0.1025 sec/batch\n",
      "Epoch 5/10 Iteration: 17800 Avg. Training loss: 2.3485 0.1096 sec/batch\n",
      "Epoch 5/10 Iteration: 17900 Avg. Training loss: 2.1628 0.1081 sec/batch\n",
      "Epoch 5/10 Iteration: 18000 Avg. Training loss: 2.4056 0.1082 sec/batch\n",
      "Nearest to [word]: 交互性, 熟练应用, 制造业, 空白, 友善, office, 诚恳, 独到见解,\n",
      "Nearest to [ppt]: 网络资源, project, 操, 操作, 透视, 前期, 文字处理, 产生,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, jquery, 老客户, 考试, 所需,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 坚守, 精美, 热爱工作, 参照, 安全,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 估值, 人事管理, 具体, 延伸, 著名,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 语言表达, 措施, 精准, 态度端正, 主人翁, 易用性,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 高强, 下级, 极客, 想要,\n",
      "Epoch 5/10 Iteration: 18100 Avg. Training loss: 2.1778 0.1058 sec/batch\n",
      "Epoch 5/10 Iteration: 18200 Avg. Training loss: 2.2328 0.1015 sec/batch\n",
      "Epoch 5/10 Iteration: 18300 Avg. Training loss: 2.1771 0.0966 sec/batch\n",
      "Epoch 5/10 Iteration: 18400 Avg. Training loss: 2.1402 0.0990 sec/batch\n",
      "Epoch 5/10 Iteration: 18500 Avg. Training loss: 2.4019 0.1009 sec/batch\n",
      "Epoch 5/10 Iteration: 18600 Avg. Training loss: 2.1150 0.0969 sec/batch\n",
      "Epoch 5/10 Iteration: 18700 Avg. Training loss: 2.1308 0.0953 sec/batch\n",
      "Epoch 5/10 Iteration: 18800 Avg. Training loss: 2.5048 0.0960 sec/batch\n",
      "Epoch 5/10 Iteration: 18900 Avg. Training loss: 2.2860 0.0991 sec/batch\n",
      "Epoch 5/10 Iteration: 19000 Avg. Training loss: 2.0566 0.1011 sec/batch\n",
      "Nearest to [word]: 交互性, 熟练应用, 空白, 制造业, 条理清晰, office, 诚恳, 交予,\n",
      "Nearest to [ppt]: 网络资源, project, 操, 操作, 透视, 文字处理, 会计学, 词性,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 记录, 格式, 所需, 老客户, jquery, 考试,\n",
      "Nearest to [java]: 全力, 融入, 秉持, 坚守, 热爱工作, 精美, 安全, 参照,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 估值, 人事管理, 报警, 同理, 著名,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 语言表达, 程序设计, 措施, 态度端正, 精准, 有意者,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 高强, 极客, 下级, 想要,\n",
      "Epoch 5/10 Iteration: 19100 Avg. Training loss: 2.1146 0.1011 sec/batch\n",
      "Epoch 5/10 Iteration: 19200 Avg. Training loss: 2.1920 0.1005 sec/batch\n",
      "Epoch 5/10 Iteration: 19300 Avg. Training loss: 2.2305 0.1028 sec/batch\n",
      "Epoch 5/10 Iteration: 19400 Avg. Training loss: 2.1495 0.1072 sec/batch\n",
      "Epoch 6/10 Iteration: 19500 Avg. Training loss: 2.1351 0.0889 sec/batch\n",
      "Epoch 6/10 Iteration: 19600 Avg. Training loss: 2.3014 0.1040 sec/batch\n",
      "Epoch 6/10 Iteration: 19700 Avg. Training loss: 2.1156 0.1066 sec/batch\n",
      "Epoch 6/10 Iteration: 19800 Avg. Training loss: 2.0117 0.1070 sec/batch\n",
      "Epoch 6/10 Iteration: 19900 Avg. Training loss: 2.4210 0.1050 sec/batch\n",
      "Epoch 6/10 Iteration: 20000 Avg. Training loss: 2.4317 0.1103 sec/batch\n",
      "Nearest to [word]: 空白, 平者让, 熟练应用, 制造业, 交互性, 友善, 诚恳, 公关,\n",
      "Nearest to [ppt]: 网络资源, 透视, 操作, 操, project, 文字处理, 会计学, 产生,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 记录, 格式, 所需, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 坚守, 安全, 精美, 热爱工作, 信用卡,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 估值, 手持, 受众,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 态度端正, 语言表达, 程序设计, 有意者, 精准,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 专情, 下级, 高强, 管理学, 极客,\n",
      "Epoch 6/10 Iteration: 20100 Avg. Training loss: 2.2712 0.1109 sec/batch\n",
      "Epoch 6/10 Iteration: 20200 Avg. Training loss: 2.1117 0.0997 sec/batch\n",
      "Epoch 6/10 Iteration: 20300 Avg. Training loss: 2.2535 0.1017 sec/batch\n",
      "Epoch 6/10 Iteration: 20400 Avg. Training loss: 2.4832 0.1017 sec/batch\n",
      "Epoch 6/10 Iteration: 20500 Avg. Training loss: 2.4362 0.1013 sec/batch\n",
      "Epoch 6/10 Iteration: 20600 Avg. Training loss: 2.2475 0.0996 sec/batch\n",
      "Epoch 6/10 Iteration: 20700 Avg. Training loss: 2.3193 0.1011 sec/batch\n",
      "Epoch 6/10 Iteration: 20800 Avg. Training loss: 2.4749 0.0972 sec/batch\n",
      "Epoch 6/10 Iteration: 20900 Avg. Training loss: 2.3957 0.0986 sec/batch\n",
      "Epoch 6/10 Iteration: 21000 Avg. Training loss: 2.3104 0.1044 sec/batch\n",
      "Nearest to [word]: 交互性, 熟练应用, 平者让, 诚恳, office, 交予, 空白, 友善,\n",
      "Nearest to [ppt]: 网络资源, 操, 操作, 透视, project, 官网, 文字处理, 会计学,\n",
      "Nearest to [熟悉]: 缺陷, 记录, 不拘泥, 格式, 所需, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 精美, 坚守, 热爱工作, 信用卡, 参照,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 估值, 受众, 报警, 同理,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 精准, 语言表达, 有意者, 态度端正, 程序设计,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 专情, 高强, 下级, 肯吃苦, 管理学,\n",
      "Epoch 6/10 Iteration: 21100 Avg. Training loss: 2.1976 0.1020 sec/batch\n",
      "Epoch 6/10 Iteration: 21200 Avg. Training loss: 2.3077 0.1123 sec/batch\n",
      "Epoch 6/10 Iteration: 21300 Avg. Training loss: 2.0863 0.1067 sec/batch\n",
      "Epoch 6/10 Iteration: 21400 Avg. Training loss: 2.2313 0.0973 sec/batch\n",
      "Epoch 6/10 Iteration: 21500 Avg. Training loss: 2.3771 0.0978 sec/batch\n",
      "Epoch 6/10 Iteration: 21600 Avg. Training loss: 2.2891 0.0978 sec/batch\n",
      "Epoch 6/10 Iteration: 21700 Avg. Training loss: 2.2351 0.1001 sec/batch\n",
      "Epoch 6/10 Iteration: 21800 Avg. Training loss: 2.2454 0.0998 sec/batch\n",
      "Epoch 6/10 Iteration: 21900 Avg. Training loss: 2.3491 0.0992 sec/batch\n",
      "Epoch 6/10 Iteration: 22000 Avg. Training loss: 2.2118 0.1105 sec/batch\n",
      "Nearest to [word]: 交互性, 制造业, 熟练应用, 空白, 平者让, 常用工具, 优劣势, 软件应用,\n",
      "Nearest to [ppt]: 网络资源, project, 操, 操作, 透视, 官网, 前期, 产生,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, jquery, 老客户, 考试, 所需,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 精美, 坚守, 热爱工作, 参照, 启动,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 具体, 估值, 人事管理, 报警, 说明书,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 精准, 措施, 语言表达, 易用性, 有意者, 态度端正,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 专情, 高强, 下级, 肯吃苦, 管理学,\n",
      "Epoch 6/10 Iteration: 22100 Avg. Training loss: 2.1714 0.1039 sec/batch\n",
      "Epoch 6/10 Iteration: 22200 Avg. Training loss: 2.1703 0.1103 sec/batch\n",
      "Epoch 6/10 Iteration: 22300 Avg. Training loss: 2.1512 0.1068 sec/batch\n",
      "Epoch 6/10 Iteration: 22400 Avg. Training loss: 2.3306 0.1097 sec/batch\n",
      "Epoch 6/10 Iteration: 22500 Avg. Training loss: 2.0630 0.1071 sec/batch\n",
      "Epoch 6/10 Iteration: 22600 Avg. Training loss: 2.1512 0.0963 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Iteration: 22700 Avg. Training loss: 2.4528 0.0962 sec/batch\n",
      "Epoch 6/10 Iteration: 22800 Avg. Training loss: 2.1565 0.0930 sec/batch\n",
      "Epoch 6/10 Iteration: 22900 Avg. Training loss: 1.9977 0.0989 sec/batch\n",
      "Epoch 6/10 Iteration: 23000 Avg. Training loss: 2.1165 0.0948 sec/batch\n",
      "Nearest to [word]: 交互性, 空白, 熟练应用, 制造业, 交予, 友善, 平者让, 软件应用,\n",
      "Nearest to [ppt]: 网络资源, 操, project, 操作, 透视, 文字处理, 官网, 出品,\n",
      "Nearest to [熟悉]: 缺陷, 记录, 不拘泥, 格式, 所需, jquery, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 融入, 秉持, 精美, 坚守, 参照, 热爱工作, 安全,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 估值, 著名, 抓,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 程序设计, 精准, 语言表达, 态度端正, 有意者,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 专情, 高强, 下级, 肯吃苦, 函数,\n",
      "Epoch 6/10 Iteration: 23100 Avg. Training loss: 2.1464 0.0925 sec/batch\n",
      "Epoch 6/10 Iteration: 23200 Avg. Training loss: 2.2254 0.0935 sec/batch\n",
      "Epoch 7/10 Iteration: 23300 Avg. Training loss: 2.2035 0.0022 sec/batch\n",
      "Epoch 7/10 Iteration: 23400 Avg. Training loss: 2.1513 0.1039 sec/batch\n",
      "Epoch 7/10 Iteration: 23500 Avg. Training loss: 2.2907 0.0996 sec/batch\n",
      "Epoch 7/10 Iteration: 23600 Avg. Training loss: 1.9360 0.1016 sec/batch\n",
      "Epoch 7/10 Iteration: 23700 Avg. Training loss: 2.1563 0.1009 sec/batch\n",
      "Epoch 7/10 Iteration: 23800 Avg. Training loss: 2.4494 0.0954 sec/batch\n",
      "Epoch 7/10 Iteration: 23900 Avg. Training loss: 2.3448 0.0964 sec/batch\n",
      "Epoch 7/10 Iteration: 24000 Avg. Training loss: 2.1663 0.0988 sec/batch\n",
      "Nearest to [word]: 空白, 平者让, 制造业, 软件应用, 友善, 交互性, 熟练应用, office,\n",
      "Nearest to [ppt]: 网络资源, 透视, 操, 操作, 文字处理, project, 会计学, 官网,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 记录, 格式, jquery, 所需, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 精美, 安全, 坚守, 参照, 互联,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 报警, 人事管理, 手持, 估值, 优化设计,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 程序设计, 措施, 态度端正, 有意者, 精准, 语言表达,\n",
      "Nearest to [了解]: 方向和, 分析方法, 求职, 下级, 专情, 高强, 肯吃苦, 管理学,\n",
      "Epoch 7/10 Iteration: 24100 Avg. Training loss: 2.0497 0.0987 sec/batch\n",
      "Epoch 7/10 Iteration: 24200 Avg. Training loss: 2.3725 0.1009 sec/batch\n",
      "Epoch 7/10 Iteration: 24300 Avg. Training loss: 2.4348 0.0980 sec/batch\n",
      "Epoch 7/10 Iteration: 24400 Avg. Training loss: 2.3997 0.0994 sec/batch\n",
      "Epoch 7/10 Iteration: 24500 Avg. Training loss: 2.2300 0.0942 sec/batch\n",
      "Epoch 7/10 Iteration: 24600 Avg. Training loss: 2.3675 0.0955 sec/batch\n",
      "Epoch 7/10 Iteration: 24700 Avg. Training loss: 2.4810 0.0964 sec/batch\n",
      "Epoch 7/10 Iteration: 24800 Avg. Training loss: 2.3347 0.0951 sec/batch\n",
      "Epoch 7/10 Iteration: 24900 Avg. Training loss: 2.2733 0.1044 sec/batch\n",
      "Epoch 7/10 Iteration: 25000 Avg. Training loss: 2.1771 0.1064 sec/batch\n",
      "Nearest to [word]: 空白, office, excel, 熟练应用, 交予, 交互性, 软件应用, 友善,\n",
      "Nearest to [ppt]: 网络资源, 操, 透视, 官网, 文字处理, 操作, 出品, project,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, jquery, 记录, 所需, 考试, 老客户,\n",
      "Nearest to [java]: 全力, 秉持, 精美, 融入, 坚守, 参照, 信用卡, 安全,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 估值, 受众, 具体,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 精准, 语言表达, 程序设计, 有意者, 态度端正,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 专情, 下级, 高强, 管理学, 肯吃苦,\n",
      "Epoch 7/10 Iteration: 25100 Avg. Training loss: 2.2368 0.1051 sec/batch\n",
      "Epoch 7/10 Iteration: 25200 Avg. Training loss: 2.1567 0.1009 sec/batch\n",
      "Epoch 7/10 Iteration: 25300 Avg. Training loss: 2.2784 0.0943 sec/batch\n",
      "Epoch 7/10 Iteration: 25400 Avg. Training loss: 2.4157 0.0997 sec/batch\n",
      "Epoch 7/10 Iteration: 25500 Avg. Training loss: 2.2624 0.0979 sec/batch\n",
      "Epoch 7/10 Iteration: 25600 Avg. Training loss: 2.2988 0.0989 sec/batch\n",
      "Epoch 7/10 Iteration: 25700 Avg. Training loss: 2.2415 0.0997 sec/batch\n",
      "Epoch 7/10 Iteration: 25800 Avg. Training loss: 2.4021 0.0944 sec/batch\n",
      "Epoch 7/10 Iteration: 25900 Avg. Training loss: 2.2073 0.0994 sec/batch\n",
      "Epoch 7/10 Iteration: 26000 Avg. Training loss: 2.1205 0.0977 sec/batch\n",
      "Nearest to [word]: 制造业, 交互性, 熟练应用, 软件应用, excel, office, rp, 空白,\n",
      "Nearest to [ppt]: 操, 网络资源, project, 透视, 操作, 官网, 文字处理, mindmanager,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, jquery, 老客户, 考试, 所需,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 精美, 坚守, 安全, 参照, 启动,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 具体, 说明书, 估值, 人事管理, 手持,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 语言表达, 易用性, 程序设计, 主人翁,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 专情, 肯吃苦, 高强,\n",
      "Epoch 7/10 Iteration: 26100 Avg. Training loss: 2.1046 0.1025 sec/batch\n",
      "Epoch 7/10 Iteration: 26200 Avg. Training loss: 2.2357 0.0989 sec/batch\n",
      "Epoch 7/10 Iteration: 26300 Avg. Training loss: 2.2377 0.0983 sec/batch\n",
      "Epoch 7/10 Iteration: 26400 Avg. Training loss: 2.0611 0.0977 sec/batch\n",
      "Epoch 7/10 Iteration: 26500 Avg. Training loss: 2.2973 0.1032 sec/batch\n",
      "Epoch 7/10 Iteration: 26600 Avg. Training loss: 2.4598 0.1002 sec/batch\n",
      "Epoch 7/10 Iteration: 26700 Avg. Training loss: 2.0567 0.1045 sec/batch\n",
      "Epoch 7/10 Iteration: 26800 Avg. Training loss: 2.0570 0.1073 sec/batch\n",
      "Epoch 7/10 Iteration: 26900 Avg. Training loss: 2.1176 0.1117 sec/batch\n",
      "Epoch 7/10 Iteration: 27000 Avg. Training loss: 2.1586 0.1062 sec/batch\n",
      "Nearest to [word]: 软件应用, 熟练应用, 制造业, 空白, 交互性, 友善, 交予, excel,\n",
      "Nearest to [ppt]: 网络资源, 操, 透视, 文字处理, project, 官网, 操作, 课件,\n",
      "Nearest to [熟悉]: 缺陷, 记录, 不拘泥, 格式, jquery, 所需, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 秉持, 融入, 精美, 安全, 坚守, 参照, 高速成长,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 估值, 手持, 受众,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 程序设计, 精准, 有意者, 态度端正, 语言表达,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 下级, 管理学, 高强, 专情, 肯吃苦,\n",
      "Epoch 7/10 Iteration: 27100 Avg. Training loss: 2.2596 0.1101 sec/batch\n",
      "Epoch 8/10 Iteration: 27200 Avg. Training loss: 2.1067 0.0215 sec/batch\n",
      "Epoch 8/10 Iteration: 27300 Avg. Training loss: 2.0519 0.1017 sec/batch\n",
      "Epoch 8/10 Iteration: 27400 Avg. Training loss: 2.3472 0.0995 sec/batch\n",
      "Epoch 8/10 Iteration: 27500 Avg. Training loss: 1.7908 0.0989 sec/batch\n",
      "Epoch 8/10 Iteration: 27600 Avg. Training loss: 2.3212 0.0999 sec/batch\n",
      "Epoch 8/10 Iteration: 27700 Avg. Training loss: 2.3748 0.0974 sec/batch\n",
      "Epoch 8/10 Iteration: 27800 Avg. Training loss: 2.2507 0.1022 sec/batch\n",
      "Epoch 8/10 Iteration: 27900 Avg. Training loss: 2.1438 0.1071 sec/batch\n",
      "Epoch 8/10 Iteration: 28000 Avg. Training loss: 2.1245 0.1012 sec/batch\n",
      "Nearest to [word]: 制造业, 空白, 平者让, 熟练应用, excel, office, 友善, 交予,\n",
      "Nearest to [ppt]: 网络资源, 操, 透视, 文字处理, 操作, 官网, project, 会计学,\n",
      "Nearest to [熟悉]: 缺陷, 记录, 不拘泥, 格式, jquery, 所需, 老客户, 法律法规,\n",
      "Nearest to [java]: 全力, 秉持, 精美, 融入, 安全, 坚守, 参照, 启动,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 估值, 受众, 棒,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 程序设计, 精准, 有意者, 主人翁, 态度端正,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 肯吃苦, 高强, 函数,\n",
      "Epoch 8/10 Iteration: 28100 Avg. Training loss: 2.5016 0.1041 sec/batch\n",
      "Epoch 8/10 Iteration: 28200 Avg. Training loss: 2.3510 0.1054 sec/batch\n",
      "Epoch 8/10 Iteration: 28300 Avg. Training loss: 2.3778 0.1078 sec/batch\n",
      "Epoch 8/10 Iteration: 28400 Avg. Training loss: 2.2598 0.1060 sec/batch\n",
      "Epoch 8/10 Iteration: 28500 Avg. Training loss: 2.3226 0.1064 sec/batch\n",
      "Epoch 8/10 Iteration: 28600 Avg. Training loss: 2.4359 0.1060 sec/batch\n",
      "Epoch 8/10 Iteration: 28700 Avg. Training loss: 2.3550 0.1083 sec/batch\n",
      "Epoch 8/10 Iteration: 28800 Avg. Training loss: 2.1609 0.0998 sec/batch\n",
      "Epoch 8/10 Iteration: 28900 Avg. Training loss: 2.2648 0.1029 sec/batch\n",
      "Epoch 8/10 Iteration: 29000 Avg. Training loss: 2.1607 0.0998 sec/batch\n",
      "Nearest to [word]: excel, 熟练应用, 制造业, 空白, 交互性, office, 网上, 交予,\n",
      "Nearest to [ppt]: 网络资源, 操, 透视, 官网, 文字处理, project, 出品, 会计学,\n",
      "Nearest to [熟悉]: 缺陷, 不拘泥, 格式, 记录, jquery, 老客户, 考试, 法律法规,\n",
      "Nearest to [java]: 全力, 精美, 秉持, 融入, 参照, 高速成长, 安全, 启动,\n",
      "Nearest to [能力]: 宝, 成交, 人事管理, 计算机, 具体, 棒, 手持, 报警,\n",
      "Nearest to [逻辑思维]: 自动控制, 登录, 措施, 精准, 程序设计, 有意者, 主人翁, 语言表达,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 高强, 肯吃苦, socket,\n",
      "Epoch 8/10 Iteration: 29100 Avg. Training loss: 2.2222 0.1020 sec/batch\n",
      "Epoch 8/10 Iteration: 29200 Avg. Training loss: 2.2993 0.1035 sec/batch\n",
      "Epoch 8/10 Iteration: 29300 Avg. Training loss: 2.2595 0.1022 sec/batch\n",
      "Epoch 8/10 Iteration: 29400 Avg. Training loss: 2.2479 0.0938 sec/batch\n",
      "Epoch 8/10 Iteration: 29500 Avg. Training loss: 2.1933 0.0956 sec/batch\n",
      "Epoch 8/10 Iteration: 29600 Avg. Training loss: 2.1881 0.0982 sec/batch\n",
      "Epoch 8/10 Iteration: 29700 Avg. Training loss: 2.4140 0.1051 sec/batch\n",
      "Epoch 8/10 Iteration: 29800 Avg. Training loss: 2.1331 0.1095 sec/batch\n",
      "Epoch 8/10 Iteration: 29900 Avg. Training loss: 2.1133 0.1061 sec/batch\n",
      "Epoch 8/10 Iteration: 30000 Avg. Training loss: 2.0567 0.1073 sec/batch\n",
      "Nearest to [word]: 制造业, 交互性, 软件应用, 熟练应用, 空白, 平者让, 交予, excel,\n",
      "Nearest to [ppt]: 操, 网络资源, project, 官网, 透视, 文字处理, 操作, 产生,\n",
      "Nearest to [熟悉]: 缺陷, 格式, 不拘泥, 记录, jquery, 老客户, 法律法规, 考试,\n",
      "Nearest to [java]: 全力, 精美, 秉持, 融入, 参照, 安全, 录入, 高速成长,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 说明书, 手持, 估值, 具体,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 程序设计, 易用性, 有意者, 语言表达,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 肯吃苦, 高强, 函数,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Iteration: 30100 Avg. Training loss: 2.3232 0.1058 sec/batch\n",
      "Epoch 8/10 Iteration: 30200 Avg. Training loss: 2.1217 0.1073 sec/batch\n",
      "Epoch 8/10 Iteration: 30300 Avg. Training loss: 1.9782 0.1065 sec/batch\n",
      "Epoch 8/10 Iteration: 30400 Avg. Training loss: 2.3834 0.1061 sec/batch\n",
      "Epoch 8/10 Iteration: 30500 Avg. Training loss: 2.4111 0.1055 sec/batch\n",
      "Epoch 8/10 Iteration: 30600 Avg. Training loss: 2.0591 0.1050 sec/batch\n",
      "Epoch 8/10 Iteration: 30700 Avg. Training loss: 2.0199 0.1065 sec/batch\n",
      "Epoch 8/10 Iteration: 30800 Avg. Training loss: 2.1791 0.1037 sec/batch\n",
      "Epoch 8/10 Iteration: 30900 Avg. Training loss: 2.1995 0.1136 sec/batch\n",
      "Epoch 8/10 Iteration: 31000 Avg. Training loss: 2.2319 0.1045 sec/batch\n",
      "Nearest to [word]: 制造业, 熟练应用, 软件应用, excel, 交予, 平者让, 空白, 交互性,\n",
      "Nearest to [ppt]: 透视, 操, 文字处理, 网络资源, project, 操作, 官网, 会计学,\n",
      "Nearest to [熟悉]: 缺陷, 记录, 不拘泥, 格式, jquery, 法律法规, 老客户, 考试,\n",
      "Nearest to [java]: 全力, 融入, 精美, 秉持, 启动, 安全, 参照, 信用卡,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 棒, 手持, 估值,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 程序设计, 异常, 有意者, 主人翁,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 函数, 肯吃苦, 音频,\n",
      "Epoch 9/10 Iteration: 31100 Avg. Training loss: 2.0952 0.0394 sec/batch\n",
      "Epoch 9/10 Iteration: 31200 Avg. Training loss: 2.1282 0.1049 sec/batch\n",
      "Epoch 9/10 Iteration: 31300 Avg. Training loss: 2.4307 0.1048 sec/batch\n",
      "Epoch 9/10 Iteration: 31400 Avg. Training loss: 1.6281 0.1045 sec/batch\n",
      "Epoch 9/10 Iteration: 31500 Avg. Training loss: 2.5071 0.1015 sec/batch\n",
      "Epoch 9/10 Iteration: 31600 Avg. Training loss: 2.4129 0.1060 sec/batch\n",
      "Epoch 9/10 Iteration: 31700 Avg. Training loss: 2.2440 0.1063 sec/batch\n",
      "Epoch 9/10 Iteration: 31800 Avg. Training loss: 2.1855 0.1104 sec/batch\n",
      "Epoch 9/10 Iteration: 31900 Avg. Training loss: 2.1499 0.1058 sec/batch\n",
      "Epoch 9/10 Iteration: 32000 Avg. Training loss: 2.4534 0.1003 sec/batch\n",
      "Nearest to [word]: 制造业, 交予, 软件应用, excel, 平者让, 空白, office, 熟练应用,\n",
      "Nearest to [ppt]: 网络资源, 透视, 操, 官网, 文字处理, 出品, project, 操作,\n",
      "Nearest to [熟悉]: 缺陷, 记录, jquery, 不拘泥, 格式, 法律法规, 老客户, 所需,\n",
      "Nearest to [java]: 全力, 精美, 融入, 秉持, 安全, 参照, 启动, 高速成长,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 具体, 报警, 估值, 手持,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 程序设计, 态度端正, 主人翁, 有意者,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 函数, 高强, 肯吃苦,\n",
      "Epoch 9/10 Iteration: 32100 Avg. Training loss: 2.3472 0.0974 sec/batch\n",
      "Epoch 9/10 Iteration: 32200 Avg. Training loss: 2.3479 0.1000 sec/batch\n",
      "Epoch 9/10 Iteration: 32300 Avg. Training loss: 2.2687 0.1082 sec/batch\n",
      "Epoch 9/10 Iteration: 32400 Avg. Training loss: 2.3728 0.1201 sec/batch\n",
      "Epoch 9/10 Iteration: 32500 Avg. Training loss: 2.4470 0.1093 sec/batch\n",
      "Epoch 9/10 Iteration: 32600 Avg. Training loss: 2.2983 0.1046 sec/batch\n",
      "Epoch 9/10 Iteration: 32700 Avg. Training loss: 2.1596 0.1046 sec/batch\n",
      "Epoch 9/10 Iteration: 32800 Avg. Training loss: 2.3782 0.1046 sec/batch\n",
      "Epoch 9/10 Iteration: 32900 Avg. Training loss: 2.0325 0.0983 sec/batch\n",
      "Epoch 9/10 Iteration: 33000 Avg. Training loss: 2.2460 0.1013 sec/batch\n",
      "Nearest to [word]: 制造业, excel, 熟练应用, office, 交予, 软件应用, 网上, 空白,\n",
      "Nearest to [ppt]: 网络资源, 透视, 操, 官网, 文字处理, project, 操作, 出品,\n",
      "Nearest to [熟悉]: 缺陷, jquery, 格式, 记录, 不拘泥, 老客户, 考试, 组织,\n",
      "Nearest to [java]: 全力, 精美, 融入, 秉持, 参照, 启动, 录入, 安全,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 手持, 优化设计, 棒, 具体,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 程序设计, 主人翁, 易用性, 态度端正,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 下级, 管理学, 高强, 肯吃苦, socket,\n",
      "Epoch 9/10 Iteration: 33100 Avg. Training loss: 2.2281 0.1011 sec/batch\n",
      "Epoch 9/10 Iteration: 33200 Avg. Training loss: 2.3413 0.0923 sec/batch\n",
      "Epoch 9/10 Iteration: 33300 Avg. Training loss: 2.3486 0.0924 sec/batch\n",
      "Epoch 9/10 Iteration: 33400 Avg. Training loss: 2.1907 0.1005 sec/batch\n",
      "Epoch 9/10 Iteration: 33500 Avg. Training loss: 2.1882 0.1011 sec/batch\n",
      "Epoch 9/10 Iteration: 33600 Avg. Training loss: 2.2834 0.1001 sec/batch\n",
      "Epoch 9/10 Iteration: 33700 Avg. Training loss: 2.1387 0.1102 sec/batch\n",
      "Epoch 9/10 Iteration: 33800 Avg. Training loss: 2.1238 0.1090 sec/batch\n",
      "Epoch 9/10 Iteration: 33900 Avg. Training loss: 1.9946 0.1091 sec/batch\n",
      "Epoch 9/10 Iteration: 34000 Avg. Training loss: 2.4326 0.1072 sec/batch\n",
      "Nearest to [word]: 制造业, 软件应用, excel, 交互性, 空白, 交予, 平者让, 网上,\n",
      "Nearest to [ppt]: 网络资源, 官网, 操, project, 文字处理, 透视, 出品, 操作,\n",
      "Nearest to [熟悉]: 缺陷, 格式, 记录, jquery, 不拘泥, 考试, 组织, 法律法规,\n",
      "Nearest to [java]: 全力, 精美, 融入, 秉持, 参照, 启动, 录入, 高速成长,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 具体, 包含, 手持, 棒,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 主人翁, 异常, 态度端正, 产品设计,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 函数, 高强, 肯吃苦,\n",
      "Epoch 9/10 Iteration: 34100 Avg. Training loss: 2.1470 0.1011 sec/batch\n",
      "Epoch 9/10 Iteration: 34200 Avg. Training loss: 1.9768 0.1016 sec/batch\n",
      "Epoch 9/10 Iteration: 34300 Avg. Training loss: 2.3689 0.0992 sec/batch\n",
      "Epoch 9/10 Iteration: 34400 Avg. Training loss: 2.3140 0.0982 sec/batch\n",
      "Epoch 9/10 Iteration: 34500 Avg. Training loss: 1.9673 0.1005 sec/batch\n",
      "Epoch 9/10 Iteration: 34600 Avg. Training loss: 2.0376 0.1017 sec/batch\n",
      "Epoch 9/10 Iteration: 34700 Avg. Training loss: 2.2059 0.0969 sec/batch\n",
      "Epoch 9/10 Iteration: 34800 Avg. Training loss: 2.1676 0.0962 sec/batch\n",
      "Epoch 9/10 Iteration: 34900 Avg. Training loss: 2.2223 0.0974 sec/batch\n",
      "Epoch 10/10 Iteration: 35000 Avg. Training loss: 2.1347 0.0532 sec/batch\n",
      "Nearest to [word]: 软件应用, 制造业, excel, 熟练应用, 平者让, 交予, 空白, 相对,\n",
      "Nearest to [ppt]: 透视, project, 文字处理, 官网, 操, 网络资源, 操作, 出品,\n",
      "Nearest to [熟悉]: 缺陷, 记录, jquery, 格式, 不拘泥, 法律法规, 考试, 组织,\n",
      "Nearest to [java]: 全力, 融入, 精美, 秉持, 启动, 参照, 安全, 高速成长,\n",
      "Nearest to [能力]: 宝, 成交, 计算机, 人事管理, 报警, 手持, 棒, 告知,\n",
      "Nearest to [逻辑思维]: 自动控制, 措施, 登录, 精准, 程序设计, 异常, 主人翁, 态度端正,\n",
      "Nearest to [了解]: 方向和, 求职, 分析方法, 管理学, 下级, 函数, 肯吃苦, 音频,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dee015d5bcbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             feed = {inputs: x,\n\u001b[1;32m     20\u001b[0m                     labels: np.array(y)[:, None]}\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nelson/anaconda3/envs/tflearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nelson/anaconda3/envs/tflearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nelson/anaconda3/envs/tflearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Nelson/anaconda3/envs/tflearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nelson/anaconda3/envs/tflearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10 # 迭代轮数\n",
    "batch_size = 1000 # batch大小\n",
    "window_size = 10 # 窗口大小\n",
    "\n",
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver() # 文件存储\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    iteration = 1\n",
    "    loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        batches = get_batches(train_words, batch_size, window_size)\n",
    "        start = time.time()\n",
    "        # \n",
    "        for x, y in batches:\n",
    "            \n",
    "            feed = {inputs: x,\n",
    "                    labels: np.array(y)[:, None]}\n",
    "            train_loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            \n",
    "            loss += train_loss\n",
    "            \n",
    "            if iteration % 100 == 0: \n",
    "                end = time.time()\n",
    "                print(\"Epoch {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Avg. Training loss: {:.4f}\".format(loss/100),\n",
    "                      \"{:.4f} sec/batch\".format((end-start)/100))\n",
    "                loss = 0\n",
    "                start = time.time()\n",
    "            \n",
    "            # 计算相似的词\n",
    "            if iteration % 1000 == 0:\n",
    "                # 计算similarity\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = int_to_vocab[valid_examples[i]]\n",
    "                    top_k = 8 # 取最相似单词的前8个\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log = 'Nearest to [%s]:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = int_to_vocab[nearest[k]]\n",
    "                        log = '%s %s,' % (log, close_word)\n",
    "                    print(log)\n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "    save_path = saver.save(sess, \"checkpoints/text8.ckpt\")\n",
    "    embed_mat = sess.run(normalized_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
